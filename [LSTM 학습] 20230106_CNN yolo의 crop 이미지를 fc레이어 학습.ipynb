{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e8e67a",
   "metadata": {},
   "source": [
    "### 저장된 Yolo 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288762f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\nyan/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-9-15 Python-3.8.15 torch-1.10.1 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11264MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 322 layers, 86173414 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path = './yolov5-master/exp3/weights/best.pt')\n",
    "def net_yolo(img):\n",
    "    h, w, c = img.shape\n",
    "    pred_list = model(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    pred_list = pred_list.pandas().xyxy[0]\n",
    "    result_list = []\n",
    "    for cnt in range(len(pred_list)):\n",
    "        x1 = int(pred_list.loc[cnt]['xmin'])\n",
    "        y1 = int(pred_list.loc[cnt]['ymin'])\n",
    "        x2 = int(pred_list.loc[cnt]['xmax'])\n",
    "        y2 = int(pred_list.loc[cnt]['ymax'])\n",
    "        x1_nor = max(1, int(pred_list.loc[cnt]['xmin'])) / w\n",
    "        y1_nor = max(1, int(pred_list.loc[cnt]['ymin'])) / h\n",
    "        x2_nor = max(1, int(pred_list.loc[cnt]['xmax'])) / w\n",
    "        y2_nor = max(1, int(pred_list.loc[cnt]['ymax'])) / h\n",
    "        conf = round(float(pred_list.loc[cnt]['confidence']), 3)\n",
    "        pred = {'bbox' : [x1, y1, x2, y2], 'conf' : conf, 'bbox_nor' : [x1_nor, y1_nor, x2_nor, y2_nor]}\n",
    "        result_list.append(pred)\n",
    "    if len(result_list) > 0:\n",
    "        result_list.sort(key = lambda x:x['conf'], reverse = True)\n",
    "        result = result_list[0]                    \n",
    "        crop_img = img[result['bbox'][1]:result['bbox'][3], result['bbox'][0]:result['bbox'][2]]\n",
    "        return result['bbox_nor'], crop_img\n",
    "    else:\n",
    "        return [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b091862a",
   "metadata": {},
   "source": [
    "### 저장된 Resnet 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4ab25ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 가상환경 GPU 사용 가능상태\n"
     ]
    }
   ],
   "source": [
    "def seed(seed = 1234):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda:0'\n",
    "    print('현재 가상환경 GPU 사용 가능상태')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('GPU 사용 불가능 상태')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae8e225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-80          [-1, 128, 28, 28]             256\n",
      "             ReLU-81          [-1, 128, 28, 28]               0\n",
      "           Conv2d-82          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-83          [-1, 128, 28, 28]             256\n",
      "             ReLU-84          [-1, 128, 28, 28]               0\n",
      "           Conv2d-85          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-86          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-87          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-88          [-1, 512, 28, 28]               0\n",
      "           Conv2d-89          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-90          [-1, 128, 28, 28]             256\n",
      "             ReLU-91          [-1, 128, 28, 28]               0\n",
      "           Conv2d-92          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-93          [-1, 128, 28, 28]             256\n",
      "             ReLU-94          [-1, 128, 28, 28]               0\n",
      "           Conv2d-95          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-96          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-97          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-98          [-1, 512, 28, 28]               0\n",
      "           Conv2d-99          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-100          [-1, 128, 28, 28]             256\n",
      "            ReLU-101          [-1, 128, 28, 28]               0\n",
      "          Conv2d-102          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
      "            ReLU-104          [-1, 128, 28, 28]               0\n",
      "          Conv2d-105          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-106          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-107          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-108          [-1, 512, 28, 28]               0\n",
      "          Conv2d-109          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-110          [-1, 128, 28, 28]             256\n",
      "            ReLU-111          [-1, 128, 28, 28]               0\n",
      "          Conv2d-112          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-113          [-1, 128, 28, 28]             256\n",
      "            ReLU-114          [-1, 128, 28, 28]               0\n",
      "          Conv2d-115          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-116          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-117          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-118          [-1, 512, 28, 28]               0\n",
      "          Conv2d-119          [-1, 256, 28, 28]         131,072\n",
      "     BatchNorm2d-120          [-1, 256, 28, 28]             512\n",
      "            ReLU-121          [-1, 256, 28, 28]               0\n",
      "          Conv2d-122          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-123          [-1, 256, 14, 14]             512\n",
      "            ReLU-124          [-1, 256, 14, 14]               0\n",
      "          Conv2d-125         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-126         [-1, 1024, 14, 14]           2,048\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-142          [-1, 256, 14, 14]             512\n",
      "            ReLU-143          [-1, 256, 14, 14]               0\n",
      "          Conv2d-144          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-145          [-1, 256, 14, 14]             512\n",
      "            ReLU-146          [-1, 256, 14, 14]               0\n",
      "          Conv2d-147         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-149         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-150         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-151          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-152          [-1, 256, 14, 14]             512\n",
      "            ReLU-153          [-1, 256, 14, 14]               0\n",
      "          Conv2d-154          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-155          [-1, 256, 14, 14]             512\n",
      "            ReLU-156          [-1, 256, 14, 14]               0\n",
      "          Conv2d-157         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-159         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-160         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-161          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-162          [-1, 256, 14, 14]             512\n",
      "            ReLU-163          [-1, 256, 14, 14]               0\n",
      "          Conv2d-164          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-165          [-1, 256, 14, 14]             512\n",
      "            ReLU-166          [-1, 256, 14, 14]               0\n",
      "          Conv2d-167         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-169         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-170         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-171          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-172          [-1, 256, 14, 14]             512\n",
      "            ReLU-173          [-1, 256, 14, 14]               0\n",
      "          Conv2d-174          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-175          [-1, 256, 14, 14]             512\n",
      "            ReLU-176          [-1, 256, 14, 14]               0\n",
      "          Conv2d-177         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-179         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-180         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-181          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-182          [-1, 256, 14, 14]             512\n",
      "            ReLU-183          [-1, 256, 14, 14]               0\n",
      "          Conv2d-184          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-185          [-1, 256, 14, 14]             512\n",
      "            ReLU-186          [-1, 256, 14, 14]               0\n",
      "          Conv2d-187         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-189         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-190         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-191          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-192          [-1, 256, 14, 14]             512\n",
      "            ReLU-193          [-1, 256, 14, 14]               0\n",
      "          Conv2d-194          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-195          [-1, 256, 14, 14]             512\n",
      "            ReLU-196          [-1, 256, 14, 14]               0\n",
      "          Conv2d-197         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-199         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-200         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-201          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-202          [-1, 256, 14, 14]             512\n",
      "            ReLU-203          [-1, 256, 14, 14]               0\n",
      "          Conv2d-204          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-205          [-1, 256, 14, 14]             512\n",
      "            ReLU-206          [-1, 256, 14, 14]               0\n",
      "          Conv2d-207         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-209         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-210         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-211          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-212          [-1, 256, 14, 14]             512\n",
      "            ReLU-213          [-1, 256, 14, 14]               0\n",
      "          Conv2d-214          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-215          [-1, 256, 14, 14]             512\n",
      "            ReLU-216          [-1, 256, 14, 14]               0\n",
      "          Conv2d-217         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-219         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-220         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-221          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-222          [-1, 256, 14, 14]             512\n",
      "            ReLU-223          [-1, 256, 14, 14]               0\n",
      "          Conv2d-224          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-225          [-1, 256, 14, 14]             512\n",
      "            ReLU-226          [-1, 256, 14, 14]               0\n",
      "          Conv2d-227         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-229         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-230         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-231          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 14, 14]             512\n",
      "            ReLU-233          [-1, 256, 14, 14]               0\n",
      "          Conv2d-234          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 14, 14]             512\n",
      "            ReLU-236          [-1, 256, 14, 14]               0\n",
      "          Conv2d-237         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-240         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-241          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-242          [-1, 256, 14, 14]             512\n",
      "            ReLU-243          [-1, 256, 14, 14]               0\n",
      "          Conv2d-244          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-245          [-1, 256, 14, 14]             512\n",
      "            ReLU-246          [-1, 256, 14, 14]               0\n",
      "          Conv2d-247         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-249         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-250         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-251          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-252          [-1, 256, 14, 14]             512\n",
      "            ReLU-253          [-1, 256, 14, 14]               0\n",
      "          Conv2d-254          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-255          [-1, 256, 14, 14]             512\n",
      "            ReLU-256          [-1, 256, 14, 14]               0\n",
      "          Conv2d-257         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-259         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-260         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-261          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-262          [-1, 256, 14, 14]             512\n",
      "            ReLU-263          [-1, 256, 14, 14]               0\n",
      "          Conv2d-264          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-265          [-1, 256, 14, 14]             512\n",
      "            ReLU-266          [-1, 256, 14, 14]               0\n",
      "          Conv2d-267         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-269         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-270         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-271          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-272          [-1, 256, 14, 14]             512\n",
      "            ReLU-273          [-1, 256, 14, 14]               0\n",
      "          Conv2d-274          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-275          [-1, 256, 14, 14]             512\n",
      "            ReLU-276          [-1, 256, 14, 14]               0\n",
      "          Conv2d-277         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-279         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-280         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-281          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-282          [-1, 256, 14, 14]             512\n",
      "            ReLU-283          [-1, 256, 14, 14]               0\n",
      "          Conv2d-284          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-285          [-1, 256, 14, 14]             512\n",
      "            ReLU-286          [-1, 256, 14, 14]               0\n",
      "          Conv2d-287         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-289         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-290         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-291          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-292          [-1, 256, 14, 14]             512\n",
      "            ReLU-293          [-1, 256, 14, 14]               0\n",
      "          Conv2d-294          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-295          [-1, 256, 14, 14]             512\n",
      "            ReLU-296          [-1, 256, 14, 14]               0\n",
      "          Conv2d-297         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-299         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-300         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-301          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-302          [-1, 256, 14, 14]             512\n",
      "            ReLU-303          [-1, 256, 14, 14]               0\n",
      "          Conv2d-304          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-305          [-1, 256, 14, 14]             512\n",
      "            ReLU-306          [-1, 256, 14, 14]               0\n",
      "          Conv2d-307         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-309         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-310         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-311          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-312          [-1, 256, 14, 14]             512\n",
      "            ReLU-313          [-1, 256, 14, 14]               0\n",
      "          Conv2d-314          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-315          [-1, 256, 14, 14]             512\n",
      "            ReLU-316          [-1, 256, 14, 14]               0\n",
      "          Conv2d-317         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-318         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-319         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-320         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-321          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-322          [-1, 256, 14, 14]             512\n",
      "            ReLU-323          [-1, 256, 14, 14]               0\n",
      "          Conv2d-324          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-325          [-1, 256, 14, 14]             512\n",
      "            ReLU-326          [-1, 256, 14, 14]               0\n",
      "          Conv2d-327         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-328         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-329         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-330         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-331          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-332          [-1, 256, 14, 14]             512\n",
      "            ReLU-333          [-1, 256, 14, 14]               0\n",
      "          Conv2d-334          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-335          [-1, 256, 14, 14]             512\n",
      "            ReLU-336          [-1, 256, 14, 14]               0\n",
      "          Conv2d-337         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-338         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-339         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-340         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-341          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-342          [-1, 256, 14, 14]             512\n",
      "            ReLU-343          [-1, 256, 14, 14]               0\n",
      "          Conv2d-344          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-345          [-1, 256, 14, 14]             512\n",
      "            ReLU-346          [-1, 256, 14, 14]               0\n",
      "          Conv2d-347         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-348         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-349         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-350         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-351          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-352          [-1, 256, 14, 14]             512\n",
      "            ReLU-353          [-1, 256, 14, 14]               0\n",
      "          Conv2d-354          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-355          [-1, 256, 14, 14]             512\n",
      "            ReLU-356          [-1, 256, 14, 14]               0\n",
      "          Conv2d-357         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-358         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-359         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-360         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-361          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-362          [-1, 256, 14, 14]             512\n",
      "            ReLU-363          [-1, 256, 14, 14]               0\n",
      "          Conv2d-364          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-365          [-1, 256, 14, 14]             512\n",
      "            ReLU-366          [-1, 256, 14, 14]               0\n",
      "          Conv2d-367         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-368         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-369         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-370         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-371          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-372          [-1, 256, 14, 14]             512\n",
      "            ReLU-373          [-1, 256, 14, 14]               0\n",
      "          Conv2d-374          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-375          [-1, 256, 14, 14]             512\n",
      "            ReLU-376          [-1, 256, 14, 14]               0\n",
      "          Conv2d-377         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-378         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-379         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-380         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-381          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-382          [-1, 256, 14, 14]             512\n",
      "            ReLU-383          [-1, 256, 14, 14]               0\n",
      "          Conv2d-384          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-385          [-1, 256, 14, 14]             512\n",
      "            ReLU-386          [-1, 256, 14, 14]               0\n",
      "          Conv2d-387         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-388         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-389         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-390         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-391          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-392          [-1, 256, 14, 14]             512\n",
      "            ReLU-393          [-1, 256, 14, 14]               0\n",
      "          Conv2d-394          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-395          [-1, 256, 14, 14]             512\n",
      "            ReLU-396          [-1, 256, 14, 14]               0\n",
      "          Conv2d-397         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-398         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-399         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-400         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-401          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-402          [-1, 256, 14, 14]             512\n",
      "            ReLU-403          [-1, 256, 14, 14]               0\n",
      "          Conv2d-404          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-405          [-1, 256, 14, 14]             512\n",
      "            ReLU-406          [-1, 256, 14, 14]               0\n",
      "          Conv2d-407         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-408         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-409         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-410         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-411          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-412          [-1, 256, 14, 14]             512\n",
      "            ReLU-413          [-1, 256, 14, 14]               0\n",
      "          Conv2d-414          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-415          [-1, 256, 14, 14]             512\n",
      "            ReLU-416          [-1, 256, 14, 14]               0\n",
      "          Conv2d-417         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-418         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-419         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-420         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-421          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-422          [-1, 256, 14, 14]             512\n",
      "            ReLU-423          [-1, 256, 14, 14]               0\n",
      "          Conv2d-424          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-425          [-1, 256, 14, 14]             512\n",
      "            ReLU-426          [-1, 256, 14, 14]               0\n",
      "          Conv2d-427         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-428         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-429         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-430         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-431          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-432          [-1, 256, 14, 14]             512\n",
      "            ReLU-433          [-1, 256, 14, 14]               0\n",
      "          Conv2d-434          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-435          [-1, 256, 14, 14]             512\n",
      "            ReLU-436          [-1, 256, 14, 14]               0\n",
      "          Conv2d-437         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-438         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-439         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-440         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-441          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-442          [-1, 256, 14, 14]             512\n",
      "            ReLU-443          [-1, 256, 14, 14]               0\n",
      "          Conv2d-444          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-445          [-1, 256, 14, 14]             512\n",
      "            ReLU-446          [-1, 256, 14, 14]               0\n",
      "          Conv2d-447         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-448         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-449         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-450         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-451          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-452          [-1, 256, 14, 14]             512\n",
      "            ReLU-453          [-1, 256, 14, 14]               0\n",
      "          Conv2d-454          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-455          [-1, 256, 14, 14]             512\n",
      "            ReLU-456          [-1, 256, 14, 14]               0\n",
      "          Conv2d-457         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-458         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-459         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-460         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-461          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-462          [-1, 256, 14, 14]             512\n",
      "            ReLU-463          [-1, 256, 14, 14]               0\n",
      "          Conv2d-464          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-465          [-1, 256, 14, 14]             512\n",
      "            ReLU-466          [-1, 256, 14, 14]               0\n",
      "          Conv2d-467         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-468         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-469         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-470         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-471          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-472          [-1, 256, 14, 14]             512\n",
      "            ReLU-473          [-1, 256, 14, 14]               0\n",
      "          Conv2d-474          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-475          [-1, 256, 14, 14]             512\n",
      "            ReLU-476          [-1, 256, 14, 14]               0\n",
      "          Conv2d-477         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-478         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-479         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-480         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-481          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-482          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-483          [-1, 512, 14, 14]               0\n",
      "          Conv2d-484            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-485            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-486            [-1, 512, 7, 7]               0\n",
      "          Conv2d-487           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-488           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-489           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-490           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-491           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-492           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-493            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-494            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-495            [-1, 512, 7, 7]               0\n",
      "          Conv2d-496            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-497            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-498            [-1, 512, 7, 7]               0\n",
      "          Conv2d-499           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-500           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-501           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-502           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-503            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-504            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-505            [-1, 512, 7, 7]               0\n",
      "          Conv2d-506            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-507            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-508            [-1, 512, 7, 7]               0\n",
      "          Conv2d-509           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-510           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-511           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-512           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n",
      "          Linear-514                    [-1, 4]           8,196\n",
      "================================================================\n",
      "Total params: 58,152,004\n",
      "Trainable params: 58,152,004\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 606.58\n",
      "Params size (MB): 221.83\n",
      "Estimated Total Size (MB): 828.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary as Summary\n",
    "\n",
    "seed()\n",
    "model_resnet = models.resnet152(pretrained = True)\n",
    "num_ftrs = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(num_ftrs, 4)\n",
    "model_resnet.load_state_dict(torch.load('./best_model_cnn.pth'))\n",
    "net_cnn = model_resnet.to(device)\n",
    "net_cnn.eval()\n",
    "Summary(net_cnn.to(device), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c1a4f8",
   "metadata": {},
   "source": [
    "### MediaPipe 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47a2b693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "hands =  mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.3)\n",
    "def net_mediapipe(img):\n",
    "    results = hands.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    if not results.multi_hand_landmarks: return []\n",
    "    xy_list = []\n",
    "    for one_hand in results.multi_hand_landmarks:\n",
    "        for xy in one_hand.landmark:\n",
    "            xy_list.append(xy.x)\n",
    "            xy_list.append(xy.y)        \n",
    "    return xy_list # 42개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932bde7f",
   "metadata": {},
   "source": [
    "### LSTM을 위한 데이터 만들기(Yolo + Resnet + MediaPipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9136a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import natsort\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "seed()\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "data_transforms = transforms.Compose([ToTensor(), Resize((224,224)), Normalize(mean, std)])\n",
    "class dataset_cnn(Dataset):\n",
    "    def __init__(self, img, label):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = data_transforms(img)\n",
    "        self.img = [img]\n",
    "        self.label = [label]\n",
    "    def __getitem__(self, index):\n",
    "        data = self.img[index]\n",
    "        label = self.label[index]\n",
    "        return data, label\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "def list_augmentation(input_list, goal_len):\n",
    "    need_aug = goal_len - len(input_list)\n",
    "    aug_tempo = need_aug / len(input_list)\n",
    "    full_list, cnt = [], 0\n",
    "    for _input in input_list:\n",
    "        cnt += aug_tempo\n",
    "        full_list.append(_input)\n",
    "        while True:\n",
    "            if cnt < 1: break\n",
    "            full_list.append(_input)\n",
    "            cnt -= 1\n",
    "    while True:\n",
    "        if len(full_list) == goal_len: break\n",
    "        if len(full_list) > goal_len: del full_list[-1]\n",
    "        else: full_list.append(full_list[-1])    \n",
    "    return full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad39a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 113/113 [06:40<00:00,  3.54s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 129/129 [07:34<00:00,  3.52s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [07:02<00:00,  3.49s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 133/133 [07:44<00:00,  3.49s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [06:56<00:00,  3.65s/it]\n"
     ]
    }
   ],
   "source": [
    "last_mp_result = []\n",
    "for i in range(42):\n",
    "    last_mp_result.append(0.0)\n",
    "train_video_path = './train_video'\n",
    "folder_list = os.listdir(train_video_path)\n",
    "folder_list = natsort.natsorted(folder_list)\n",
    "dataset_dict_list = []\n",
    "for folder in folder_list:\n",
    "    video_list = os.listdir('{}/{}'.format(train_video_path, folder))\n",
    "    video_list = natsort.natsorted(video_list)\n",
    "    for video_name in tqdm(video_list):\n",
    "        logit_bbox_mp_list = []\n",
    "        cap = cv2.VideoCapture('{}/{}/{}'.format(train_video_path, folder, video_name))\n",
    "        if cap.isOpened():\n",
    "            while True:\n",
    "                ret, img = cap.read()\n",
    "                if ret == True:\n",
    "                    bbox, crop_img = net_yolo(img)\n",
    "                    if len(crop_img) == 0: continue\n",
    "                    flatten_img = cv2.resize(crop_img, (56, 56))\n",
    "                    flatten_img = cv2.cvtColor(flatten_img, cv2.COLOR_BGR2GRAY)\n",
    "                    flatten_img = flatten_img.reshape(56*56)\n",
    "                    flatten_img = list(minmax_scale(flatten_img, axis=0, copy=True))\n",
    "                    dataset = dataset_cnn(crop_img, int(folder))\n",
    "                    dataset = DataLoader(dataset)\n",
    "                    for data, label in dataset:\n",
    "                        data = data.to(device)\n",
    "                    with torch.no_grad():\n",
    "                        cnn_result = net_cnn(data)\n",
    "                    cnn_logits = []\n",
    "                    for logit in cnn_result[0]:\n",
    "                        cnn_logits.append(logit.item())\n",
    "                    mp_result = net_mediapipe(img)\n",
    "                    if len(mp_result) == 0: mp_result = last_mp_result + []\n",
    "                    last_mp_result = mp_result + []\n",
    "                    logit_bbox_mp_flatten = cnn_logits + bbox + last_mp_result + flatten_img\n",
    "                    logit_bbox_mp_list.append(logit_bbox_mp_flatten)\n",
    "                else: break\n",
    "        logit_bbox_mp_list = list_augmentation(logit_bbox_mp_list, 30)\n",
    "        dataset_dict_list.append({'key':int(folder), 'value':logit_bbox_mp_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6292cfb4",
   "metadata": {},
   "source": [
    "### LSTM 설계 후 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f50f94ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 549, val: 61\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "import gc\n",
    "from torch.cuda import memory_allocated, empty_cache\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class dataset_lstm(Dataset):\n",
    "    def __init__(self, seq_list):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for dic in seq_list :\n",
    "            self.y.append(dic['key'])\n",
    "            self.X.append(dic['value'])\n",
    "    def __getitem__(self, index):\n",
    "        data = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "split_ratio = [0.9, 0.1]\n",
    "train_len = int(len(dataset_dict_list) * split_ratio[0])\n",
    "val_len = len(dataset_dict_list) - train_len\n",
    "print('train: {}, val: {}'.format(train_len, val_len))\n",
    "\n",
    "train_dataset = dataset_lstm(dataset_dict_list)\n",
    "train_data, valid_data = random_split(train_dataset, [train_len, val_len])\n",
    "train_loader = DataLoader(train_data, batch_size=32)\n",
    "val_loader = DataLoader(valid_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5808c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class skeleton_LSTM(nn.Module) :\n",
    "    def __init__(self):\n",
    "        super(skeleton_LSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=3186, hidden_size=4096, num_layers=1, batch_first=True)\n",
    "        self.batch1 = nn.BatchNorm1d(30)\n",
    "        self.lstm2 = nn.LSTM(input_size=4096, hidden_size=2048, num_layers=1, batch_first=True)\n",
    "        self.batch2 = nn.BatchNorm1d(30)\n",
    "        self.lstm3 = nn.LSTM(input_size=2048, hidden_size=1024, num_layers=1, batch_first=True)\n",
    "        self.batch3 = nn.BatchNorm1d(30)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.lstm4 = nn.LSTM(input_size=1024, hidden_size=512, num_layers=1, batch_first=True)\n",
    "        self.batch4 = nn.BatchNorm1d(30)\n",
    "        self.lstm5 = nn.LSTM(input_size=512, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.batch5 = nn.BatchNorm1d(30)\n",
    "        self.lstm6 = nn.LSTM(input_size=128, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.batch6 = nn.BatchNorm1d(30)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.lstm7 = nn.LSTM(input_size=64, hidden_size=32, num_layers=1, batch_first=True)\n",
    "        self.batch7 = nn.BatchNorm1d(30)\n",
    "        self.fc = nn.Linear(32,5)\n",
    "    def forward(self, x) :\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.batch1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.batch2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.batch3(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x = self.batch4(x)\n",
    "        x, _ = self.lstm5(x)\n",
    "        x = self.batch5(x)\n",
    "        x, _ = self.lstm6(x)\n",
    "        x = self.batch6(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, _ = self.lstm7(x)\n",
    "        x = self.batch7(x)\n",
    "        x = self.fc(x[:,-1,:])\n",
    "        return x\n",
    "    \n",
    "def init_model():\n",
    "    plt.rc('font', size = 10)\n",
    "    global net_lstm, loss_fn, optim\n",
    "    net_lstm = skeleton_LSTM().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = Adam(net_lstm.parameters(), lr=0.0001)\n",
    "    \n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "    \n",
    "def init_log():\n",
    "    plt.rc('font', size = 10)\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []\n",
    "    \n",
    "def clear_memory():\n",
    "    if device != 'cpu':\n",
    "        empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "def epoch(data_loader, mode = 'train'):\n",
    "    global epoch_cnt\n",
    "    iter_loss, iter_acc, last_grad_performed = [], [], False\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.type(torch.LongTensor).to(device)\n",
    "        if mode == 'train':\n",
    "            net_lstm.train()\n",
    "        else:\n",
    "            net_lstm.eval()\n",
    "        result = net_lstm(data)\n",
    "        _, out = torch.max(result, 1)\n",
    "        loss = loss_fn(result, label)\n",
    "        iter_loss.append(loss.item())\n",
    "        if mode == 'train':\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            last_grad_performed = True\n",
    "        acc_partial = (out == label).float().sum()\n",
    "        acc_partial = acc_partial / len(label) \n",
    "        iter_acc.append(acc_partial.item())\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "    clear_memory()\n",
    "    return np.average(iter_loss), np.average(iter_acc)\n",
    "\n",
    "def epoch_not_finished():\n",
    "    return epoch_cnt < maximum_epoch\n",
    "\n",
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "    \n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "    \n",
    "def last(log_list):\n",
    "    if len(log_list) > 0:\n",
    "        return log_list[len(log_list) - 1]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def print_log():\n",
    "    train_loss = round(float(last(tloss_log)), 8)\n",
    "    train_acc = round(float(last(tacc_log)), 3)\n",
    "    val_loss = round(float(last(vloss_log)), 8)\n",
    "    val_acc = round(float(last(vacc_log)), 3)\n",
    "    time_spent = round(float(last(time_log)), 3)\n",
    "    log_str = 'Epoch: {:3} | T_Loss {:5} | T_acc {:5} | V_Loss {:5} | V_acc. {:5} | \\\n",
    "🕒 {:5}'.format(last(iter_log), train_loss, train_acc, val_loss, val_acc, time_spent)\n",
    "    log_stack.append(log_str)\n",
    "    hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99) # 그래프 사이즈 설정\n",
    "    hist_fig.patch.set_facecolor('white') # 그래프 배경색 설정\n",
    "    loss_t_line = plt.plot(iter_log, tloss_log, label='Train Loss', color='red', marker='o')\n",
    "    loss_v_line = plt.plot(iter_log, vloss_log, label='Valid Loss', color='blue', marker='s')\n",
    "    loss_axis.set_xlabel('epoch')\n",
    "    loss_axis.set_ylabel('loss')\n",
    "    acc_axis = loss_axis.twinx()\n",
    "    acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train Acc.', color='red', marker='+')\n",
    "    acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid Acc.', color='blue', marker='x')\n",
    "    acc_axis.set_ylabel('accuracy')\n",
    "    hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line # 위에서 선언한 plt정보들 통합\n",
    "    loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines]) # 순서대로 그려주기\n",
    "    loss_axis.grid() # 격자 설정\n",
    "    plt.title('Learning history until epoch {}'.format(last(iter_log)))\n",
    "    plt.draw()\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n",
    "    for idx in reversed(range(len(log_stack))): # 반대로 sort 시켜서 출력\n",
    "        print(log_stack[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aafb0fd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 200 | T_Loss 0.00343298 | T_acc   1.0 | V_Loss 0.00239734 | V_acc.   1.0 | 🕒 9.215\n",
      "Epoch: 199 | T_Loss 0.00342423 | T_acc   1.0 | V_Loss 0.00235536 | V_acc.   1.0 | 🕒  9.25\n",
      "Epoch: 198 | T_Loss 0.0035023 | T_acc   1.0 | V_Loss 0.00234596 | V_acc.   1.0 | 🕒 9.128\n",
      "Epoch: 197 | T_Loss 0.00349966 | T_acc   1.0 | V_Loss 0.00237814 | V_acc.   1.0 | 🕒 9.112\n",
      "Epoch: 196 | T_Loss 0.00356035 | T_acc   1.0 | V_Loss 0.00243967 | V_acc.   1.0 | 🕒 9.122\n",
      "Epoch: 195 | T_Loss 0.00363044 | T_acc   1.0 | V_Loss 0.00243693 | V_acc.   1.0 | 🕒 9.046\n",
      "Epoch: 194 | T_Loss 0.003657 | T_acc   1.0 | V_Loss 0.00242872 | V_acc.   1.0 | 🕒 9.233\n",
      "Epoch: 193 | T_Loss 0.00371934 | T_acc   1.0 | V_Loss 0.00235432 | V_acc.   1.0 | 🕒 9.351\n",
      "Epoch: 192 | T_Loss 0.00375376 | T_acc   1.0 | V_Loss 0.0024508 | V_acc.   1.0 | 🕒 9.134\n",
      "Epoch: 191 | T_Loss 0.00383085 | T_acc   1.0 | V_Loss 0.00249151 | V_acc.   1.0 | 🕒 9.044\n",
      "Epoch: 190 | T_Loss 0.00386353 | T_acc   1.0 | V_Loss 0.00248588 | V_acc.   1.0 | 🕒 9.166\n",
      "Epoch: 189 | T_Loss 0.0039206 | T_acc   1.0 | V_Loss 0.00251614 | V_acc.   1.0 | 🕒 9.272\n",
      "Epoch: 188 | T_Loss 0.00394819 | T_acc   1.0 | V_Loss 0.00257913 | V_acc.   1.0 | 🕒 9.241\n",
      "Epoch: 187 | T_Loss 0.00398664 | T_acc   1.0 | V_Loss 0.00266145 | V_acc.   1.0 | 🕒 9.047\n",
      "Epoch: 186 | T_Loss 0.00403277 | T_acc   1.0 | V_Loss 0.00265383 | V_acc.   1.0 | 🕒 9.102\n",
      "Epoch: 185 | T_Loss 0.00411566 | T_acc   1.0 | V_Loss 0.00260288 | V_acc.   1.0 | 🕒 9.109\n",
      "Epoch: 184 | T_Loss 0.00416253 | T_acc   1.0 | V_Loss 0.00267478 | V_acc.   1.0 | 🕒 9.167\n",
      "Epoch: 183 | T_Loss 0.00421569 | T_acc   1.0 | V_Loss 0.00264345 | V_acc.   1.0 | 🕒 9.177\n",
      "Epoch: 182 | T_Loss 0.00423085 | T_acc   1.0 | V_Loss 0.00273235 | V_acc.   1.0 | 🕒 9.153\n",
      "Epoch: 181 | T_Loss 0.00437052 | T_acc   1.0 | V_Loss 0.00274103 | V_acc.   1.0 | 🕒 9.174\n",
      "Epoch: 180 | T_Loss 0.00437948 | T_acc   1.0 | V_Loss 0.00281307 | V_acc.   1.0 | 🕒 9.146\n",
      "Epoch: 179 | T_Loss 0.00444161 | T_acc   1.0 | V_Loss 0.00282968 | V_acc.   1.0 | 🕒 9.473\n",
      "Epoch: 178 | T_Loss 0.00447163 | T_acc   1.0 | V_Loss 0.00281206 | V_acc.   1.0 | 🕒 9.134\n",
      "Epoch: 177 | T_Loss 0.00453194 | T_acc   1.0 | V_Loss 0.00295721 | V_acc.   1.0 | 🕒 9.249\n",
      "Epoch: 176 | T_Loss 0.00462252 | T_acc   1.0 | V_Loss 0.00292477 | V_acc.   1.0 | 🕒 9.135\n",
      "Epoch: 175 | T_Loss 0.00468096 | T_acc   1.0 | V_Loss 0.00292399 | V_acc.   1.0 | 🕒 9.139\n",
      "Epoch: 174 | T_Loss 0.00471428 | T_acc   1.0 | V_Loss 0.00299566 | V_acc.   1.0 | 🕒 9.226\n",
      "Epoch: 173 | T_Loss 0.00479825 | T_acc   1.0 | V_Loss 0.00297285 | V_acc.   1.0 | 🕒 9.154\n",
      "Epoch: 172 | T_Loss 0.00484395 | T_acc   1.0 | V_Loss 0.00318604 | V_acc.   1.0 | 🕒 9.295\n",
      "Epoch: 171 | T_Loss 0.00495124 | T_acc   1.0 | V_Loss 0.00313665 | V_acc.   1.0 | 🕒 9.124\n",
      "Epoch: 170 | T_Loss 0.00494047 | T_acc   1.0 | V_Loss 0.00332044 | V_acc.   1.0 | 🕒 9.209\n",
      "Epoch: 169 | T_Loss 0.00502742 | T_acc   1.0 | V_Loss 0.00334195 | V_acc.   1.0 | 🕒 9.221\n",
      "Epoch: 168 | T_Loss 0.00511537 | T_acc   1.0 | V_Loss 0.0034796 | V_acc.   1.0 | 🕒 8.997\n",
      "Epoch: 167 | T_Loss 0.00518431 | T_acc   1.0 | V_Loss 0.00341503 | V_acc.   1.0 | 🕒 9.098\n",
      "Epoch: 166 | T_Loss 0.00529664 | T_acc   1.0 | V_Loss 0.0034121 | V_acc.   1.0 | 🕒 9.171\n",
      "Epoch: 165 | T_Loss 0.00534178 | T_acc   1.0 | V_Loss 0.00344382 | V_acc.   1.0 | 🕒 9.018\n",
      "Epoch: 164 | T_Loss 0.0054173 | T_acc   1.0 | V_Loss 0.00353561 | V_acc.   1.0 | 🕒  9.27\n",
      "Epoch: 163 | T_Loss 0.00545629 | T_acc   1.0 | V_Loss 0.00343784 | V_acc.   1.0 | 🕒 9.141\n",
      "Epoch: 162 | T_Loss 0.0054781 | T_acc   1.0 | V_Loss 0.00356931 | V_acc.   1.0 | 🕒 9.158\n",
      "Epoch: 161 | T_Loss 0.00563005 | T_acc   1.0 | V_Loss 0.00354204 | V_acc.   1.0 | 🕒 9.286\n",
      "Epoch: 160 | T_Loss 0.0056961 | T_acc   1.0 | V_Loss 0.00366784 | V_acc.   1.0 | 🕒 9.099\n",
      "Epoch: 159 | T_Loss 0.00575686 | T_acc   1.0 | V_Loss 0.00378219 | V_acc.   1.0 | 🕒 9.274\n",
      "Epoch: 158 | T_Loss 0.00587293 | T_acc   1.0 | V_Loss 0.00382742 | V_acc.   1.0 | 🕒 9.271\n",
      "Epoch: 157 | T_Loss 0.0059215 | T_acc   1.0 | V_Loss 0.00396527 | V_acc.   1.0 | 🕒 9.275\n",
      "Epoch: 156 | T_Loss 0.00599731 | T_acc   1.0 | V_Loss 0.00386204 | V_acc.   1.0 | 🕒   9.2\n",
      "Epoch: 155 | T_Loss 0.00602013 | T_acc   1.0 | V_Loss 0.00394545 | V_acc.   1.0 | 🕒 9.171\n",
      "Epoch: 154 | T_Loss 0.00622626 | T_acc   1.0 | V_Loss 0.00386644 | V_acc.   1.0 | 🕒 9.364\n",
      "Epoch: 153 | T_Loss 0.00632205 | T_acc   1.0 | V_Loss 0.00399563 | V_acc.   1.0 | 🕒 9.134\n",
      "Epoch: 152 | T_Loss 0.00639041 | T_acc   1.0 | V_Loss 0.00402484 | V_acc.   1.0 | 🕒 9.066\n",
      "Epoch: 151 | T_Loss 0.00651179 | T_acc   1.0 | V_Loss 0.00419433 | V_acc.   1.0 | 🕒 9.052\n",
      "Epoch: 150 | T_Loss 0.00647666 | T_acc   1.0 | V_Loss 0.00424477 | V_acc.   1.0 | 🕒 9.115\n",
      "Epoch: 149 | T_Loss 0.00669898 | T_acc   1.0 | V_Loss 0.00421364 | V_acc.   1.0 | 🕒 9.074\n",
      "Epoch: 148 | T_Loss 0.00678771 | T_acc   1.0 | V_Loss 0.00439841 | V_acc.   1.0 | 🕒  9.11\n",
      "Epoch: 147 | T_Loss 0.00681896 | T_acc   1.0 | V_Loss 0.00436572 | V_acc.   1.0 | 🕒 9.364\n",
      "Epoch: 146 | T_Loss 0.00686179 | T_acc   1.0 | V_Loss 0.00451246 | V_acc.   1.0 | 🕒 9.443\n",
      "Epoch: 145 | T_Loss 0.00703525 | T_acc   1.0 | V_Loss 0.00448722 | V_acc.   1.0 | 🕒 9.111\n",
      "Epoch: 144 | T_Loss 0.0071564 | T_acc   1.0 | V_Loss 0.00456481 | V_acc.   1.0 | 🕒 9.277\n",
      "Epoch: 143 | T_Loss 0.00723202 | T_acc   1.0 | V_Loss 0.00459318 | V_acc.   1.0 | 🕒 9.279\n",
      "Epoch: 142 | T_Loss 0.00749131 | T_acc   1.0 | V_Loss 0.00460944 | V_acc.   1.0 | 🕒 9.397\n",
      "Epoch: 141 | T_Loss 0.00751448 | T_acc   1.0 | V_Loss 0.00469157 | V_acc.   1.0 | 🕒 9.343\n",
      "Epoch: 140 | T_Loss 0.00761325 | T_acc   1.0 | V_Loss 0.00488551 | V_acc.   1.0 | 🕒 10.381\n",
      "Epoch: 139 | T_Loss 0.00781078 | T_acc   1.0 | V_Loss 0.00477415 | V_acc.   1.0 | 🕒 9.305\n",
      "Epoch: 138 | T_Loss 0.00786271 | T_acc   1.0 | V_Loss 0.00490623 | V_acc.   1.0 | 🕒 9.404\n",
      "Epoch: 137 | T_Loss 0.00799936 | T_acc   1.0 | V_Loss 0.00490484 | V_acc.   1.0 | 🕒 9.152\n",
      "Epoch: 136 | T_Loss 0.00813349 | T_acc   1.0 | V_Loss 0.00513912 | V_acc.   1.0 | 🕒 9.297\n",
      "Epoch: 135 | T_Loss 0.00824073 | T_acc   1.0 | V_Loss 0.00501995 | V_acc.   1.0 | 🕒 9.261\n",
      "Epoch: 134 | T_Loss 0.00840265 | T_acc   1.0 | V_Loss 0.00521997 | V_acc.   1.0 | 🕒 9.432\n",
      "Epoch: 133 | T_Loss 0.00849806 | T_acc   1.0 | V_Loss 0.00535955 | V_acc.   1.0 | 🕒 17.763\n",
      "Epoch: 132 | T_Loss 0.00856938 | T_acc   1.0 | V_Loss 0.00544569 | V_acc.   1.0 | 🕒 19.157\n",
      "Epoch: 131 | T_Loss 0.00873615 | T_acc   1.0 | V_Loss 0.00538989 | V_acc.   1.0 | 🕒 19.269\n",
      "Epoch: 130 | T_Loss 0.00885154 | T_acc   1.0 | V_Loss 0.00562499 | V_acc.   1.0 | 🕒 19.387\n",
      "Epoch: 129 | T_Loss 0.00900279 | T_acc   1.0 | V_Loss 0.00577667 | V_acc.   1.0 | 🕒 19.315\n",
      "Epoch: 128 | T_Loss 0.00919275 | T_acc   1.0 | V_Loss 0.00551023 | V_acc.   1.0 | 🕒 19.323\n",
      "Epoch: 127 | T_Loss 0.00932407 | T_acc   1.0 | V_Loss 0.00581759 | V_acc.   1.0 | 🕒 19.238\n",
      "Epoch: 126 | T_Loss 0.00937895 | T_acc   1.0 | V_Loss 0.0060318 | V_acc.   1.0 | 🕒 17.738\n",
      "Epoch: 125 | T_Loss 0.00955376 | T_acc   1.0 | V_Loss 0.00604516 | V_acc.   1.0 | 🕒 19.559\n",
      "Epoch: 124 | T_Loss 0.00977863 | T_acc   1.0 | V_Loss 0.00613323 | V_acc.   1.0 | 🕒 19.257\n",
      "Epoch: 123 | T_Loss 0.0100193 | T_acc   1.0 | V_Loss 0.00612199 | V_acc.   1.0 | 🕒 19.399\n",
      "Epoch: 122 | T_Loss 0.01018454 | T_acc   1.0 | V_Loss 0.00617447 | V_acc.   1.0 | 🕒 19.123\n",
      "Epoch: 121 | T_Loss 0.01026538 | T_acc   1.0 | V_Loss 0.00646819 | V_acc.   1.0 | 🕒 19.288\n",
      "Epoch: 120 | T_Loss 0.01056352 | T_acc   1.0 | V_Loss 0.00647782 | V_acc.   1.0 | 🕒 19.334\n",
      "Epoch: 119 | T_Loss 0.01076362 | T_acc   1.0 | V_Loss 0.00667269 | V_acc.   1.0 | 🕒 19.454\n",
      "Epoch: 118 | T_Loss 0.01094887 | T_acc   1.0 | V_Loss 0.00675773 | V_acc.   1.0 | 🕒 19.502\n",
      "Epoch: 117 | T_Loss 0.01105221 | T_acc   1.0 | V_Loss 0.00677462 | V_acc.   1.0 | 🕒 19.297\n",
      "Epoch: 116 | T_Loss 0.01113561 | T_acc   1.0 | V_Loss 0.00720815 | V_acc.   1.0 | 🕒 19.076\n",
      "Epoch: 115 | T_Loss 0.01140036 | T_acc   1.0 | V_Loss 0.00714941 | V_acc.   1.0 | 🕒 19.186\n",
      "Epoch: 114 | T_Loss 0.01151804 | T_acc   1.0 | V_Loss 0.00699722 | V_acc.   1.0 | 🕒 19.33\n",
      "Epoch: 113 | T_Loss 0.01176357 | T_acc   1.0 | V_Loss 0.00720058 | V_acc.   1.0 | 🕒 17.774\n",
      "Epoch: 112 | T_Loss 0.01216955 | T_acc   1.0 | V_Loss 0.00721562 | V_acc.   1.0 | 🕒 17.719\n",
      "Epoch: 111 | T_Loss 0.01230529 | T_acc   1.0 | V_Loss 0.00748383 | V_acc.   1.0 | 🕒 19.324\n",
      "Epoch: 110 | T_Loss 0.0125563 | T_acc   1.0 | V_Loss 0.00778101 | V_acc.   1.0 | 🕒 19.247\n",
      "Epoch: 109 | T_Loss 0.01260382 | T_acc   1.0 | V_Loss 0.00806875 | V_acc.   1.0 | 🕒 19.238\n",
      "Epoch: 108 | T_Loss 0.01292968 | T_acc   1.0 | V_Loss 0.00797425 | V_acc.   1.0 | 🕒 19.671\n",
      "Epoch: 107 | T_Loss 0.01311193 | T_acc   1.0 | V_Loss 0.0083493 | V_acc.   1.0 | 🕒 19.193\n",
      "Epoch: 106 | T_Loss 0.01330997 | T_acc   1.0 | V_Loss 0.00845753 | V_acc.   1.0 | 🕒 18.922\n",
      "Epoch: 105 | T_Loss 0.01356374 | T_acc   1.0 | V_Loss 0.00843239 | V_acc.   1.0 | 🕒 19.373\n",
      "Epoch: 104 | T_Loss 0.0139632 | T_acc   1.0 | V_Loss 0.00860156 | V_acc.   1.0 | 🕒 17.516\n",
      "Epoch: 103 | T_Loss 0.01410655 | T_acc   1.0 | V_Loss 0.00906463 | V_acc.   1.0 | 🕒 17.641\n",
      "Epoch: 102 | T_Loss 0.01429018 | T_acc   1.0 | V_Loss 0.00880658 | V_acc.   1.0 | 🕒 18.941\n",
      "Epoch: 101 | T_Loss 0.01467984 | T_acc   1.0 | V_Loss 0.00907788 | V_acc.   1.0 | 🕒 19.145\n",
      "Epoch: 100 | T_Loss 0.01481128 | T_acc   1.0 | V_Loss 0.00940672 | V_acc.   1.0 | 🕒 19.087\n",
      "Epoch:  99 | T_Loss 0.01525016 | T_acc   1.0 | V_Loss 0.0096792 | V_acc.   1.0 | 🕒 19.305\n",
      "Epoch:  98 | T_Loss 0.01535798 | T_acc   1.0 | V_Loss 0.00980315 | V_acc.   1.0 | 🕒 18.962\n",
      "Epoch:  97 | T_Loss 0.0158723 | T_acc   1.0 | V_Loss 0.00982769 | V_acc.   1.0 | 🕒 18.837\n",
      "Epoch:  96 | T_Loss 0.01610114 | T_acc   1.0 | V_Loss 0.00974513 | V_acc.   1.0 | 🕒 18.751\n",
      "Epoch:  95 | T_Loss 0.01661205 | T_acc   1.0 | V_Loss 0.01022494 | V_acc.   1.0 | 🕒 18.836\n",
      "Epoch:  94 | T_Loss 0.01665314 | T_acc   1.0 | V_Loss 0.01062354 | V_acc.   1.0 | 🕒 18.909\n",
      "Epoch:  93 | T_Loss 0.01709542 | T_acc   1.0 | V_Loss 0.01075562 | V_acc.   1.0 | 🕒 18.958\n",
      "Epoch:  92 | T_Loss 0.01723317 | T_acc   1.0 | V_Loss 0.01105566 | V_acc.   1.0 | 🕒 18.896\n",
      "Epoch:  91 | T_Loss 0.0177848 | T_acc   1.0 | V_Loss 0.01106055 | V_acc.   1.0 | 🕒 18.977\n",
      "Epoch:  90 | T_Loss 0.01806327 | T_acc   1.0 | V_Loss 0.01104743 | V_acc.   1.0 | 🕒  9.32\n",
      "Epoch:  89 | T_Loss 0.01850786 | T_acc   1.0 | V_Loss 0.01180573 | V_acc.   1.0 | 🕒 10.681\n",
      "Epoch:  88 | T_Loss 0.01885213 | T_acc   1.0 | V_Loss 0.01201903 | V_acc.   1.0 | 🕒 9.921\n",
      "Epoch:  87 | T_Loss 0.0195328 | T_acc   1.0 | V_Loss 0.0123113 | V_acc.   1.0 | 🕒 8.997\n",
      "Epoch:  86 | T_Loss 0.01965131 | T_acc   1.0 | V_Loss 0.01270753 | V_acc.   1.0 | 🕒 9.048\n",
      "Epoch:  85 | T_Loss 0.0200783 | T_acc   1.0 | V_Loss 0.01265953 | V_acc.   1.0 | 🕒 9.122\n",
      "Epoch:  84 | T_Loss 0.02059261 | T_acc   1.0 | V_Loss 0.01258828 | V_acc.   1.0 | 🕒 9.048\n",
      "Epoch:  83 | T_Loss 0.02087132 | T_acc   1.0 | V_Loss 0.01294311 | V_acc.   1.0 | 🕒  9.21\n",
      "Epoch:  82 | T_Loss 0.02159749 | T_acc   1.0 | V_Loss 0.01304379 | V_acc.   1.0 | 🕒 9.282\n",
      "Epoch:  81 | T_Loss 0.02200186 | T_acc   1.0 | V_Loss 0.01376197 | V_acc.   1.0 | 🕒 9.201\n",
      "Epoch:  80 | T_Loss 0.02249451 | T_acc   1.0 | V_Loss 0.01394374 | V_acc.   1.0 | 🕒 9.183\n",
      "Epoch:  79 | T_Loss 0.02306689 | T_acc   1.0 | V_Loss 0.01393461 | V_acc.   1.0 | 🕒  9.14\n",
      "Epoch:  78 | T_Loss 0.02357464 | T_acc   1.0 | V_Loss 0.01465836 | V_acc.   1.0 | 🕒 8.848\n",
      "Epoch:  77 | T_Loss 0.02399598 | T_acc   1.0 | V_Loss 0.01531586 | V_acc.   1.0 | 🕒 8.895\n",
      "Epoch:  76 | T_Loss 0.02475835 | T_acc   1.0 | V_Loss 0.01529791 | V_acc.   1.0 | 🕒 8.834\n",
      "Epoch:  75 | T_Loss 0.02543899 | T_acc   1.0 | V_Loss 0.01545257 | V_acc.   1.0 | 🕒 8.846\n",
      "Epoch:  74 | T_Loss 0.02627303 | T_acc   1.0 | V_Loss 0.01601051 | V_acc.   1.0 | 🕒 9.024\n",
      "Epoch:  73 | T_Loss 0.02779885 | T_acc   1.0 | V_Loss 0.01648931 | V_acc.   1.0 | 🕒 9.014\n",
      "Epoch:  72 | T_Loss 0.0344679 | T_acc 0.998 | V_Loss 0.07943746 | V_acc. 0.983 | 🕒 9.103\n",
      "Epoch:  71 | T_Loss 0.04145386 | T_acc 0.997 | V_Loss 0.33546703 | V_acc. 0.933 | 🕒  9.01\n",
      "Epoch:  70 | T_Loss 0.05131514 | T_acc  0.99 | V_Loss 0.02104875 | V_acc.   1.0 | 🕒  8.86\n",
      "Epoch:  69 | T_Loss 0.06595309 | T_acc 0.988 | V_Loss 0.08101222 | V_acc. 0.983 | 🕒  8.98\n",
      "Epoch:  68 | T_Loss 0.04480028 | T_acc 0.998 | V_Loss 0.02184771 | V_acc.   1.0 | 🕒 8.827\n",
      "Epoch:  67 | T_Loss 0.09033066 | T_acc 0.984 | V_Loss 0.03095655 | V_acc.   1.0 | 🕒  9.19\n",
      "Epoch:  66 | T_Loss 0.06364262 | T_acc 0.991 | V_Loss 0.07806358 | V_acc. 0.967 | 🕒 9.048\n",
      "Epoch:  65 | T_Loss 0.06286019 | T_acc 0.993 | V_Loss 0.05486174 | V_acc. 0.984 | 🕒 8.845\n",
      "Epoch:  64 | T_Loss 0.10779032 | T_acc  0.97 | V_Loss 0.04990621 | V_acc.   1.0 | 🕒 8.783\n",
      "Epoch:  63 | T_Loss 0.03679822 | T_acc   1.0 | V_Loss 0.04186091 | V_acc. 0.984 | 🕒 8.794\n",
      "Epoch:  62 | T_Loss 0.04981548 | T_acc 0.991 | V_Loss 0.04720926 | V_acc.   1.0 | 🕒 8.735\n",
      "Epoch:  61 | T_Loss 0.05400648 | T_acc 0.995 | V_Loss 0.04401661 | V_acc. 0.983 | 🕒 8.813\n",
      "Epoch:  60 | T_Loss 0.04494496 | T_acc 0.998 | V_Loss 0.03028632 | V_acc.   1.0 | 🕒 8.854\n",
      "Epoch:  59 | T_Loss 0.05084541 | T_acc 0.993 | V_Loss 0.07032946 | V_acc. 0.969 | 🕒 8.796\n",
      "Epoch:  58 | T_Loss 0.04360086 | T_acc   1.0 | V_Loss 0.02890059 | V_acc.   1.0 | 🕒 8.796\n",
      "Epoch:  57 | T_Loss 0.04931973 | T_acc 0.997 | V_Loss 0.03081114 | V_acc.   1.0 | 🕒 8.939\n",
      "Epoch:  56 | T_Loss 0.07015551 | T_acc  0.99 | V_Loss 0.03383889 | V_acc.   1.0 | 🕒 9.159\n",
      "Epoch:  55 | T_Loss 0.10942537 | T_acc 0.981 | V_Loss 0.07876265 | V_acc. 0.967 | 🕒 8.767\n",
      "Epoch:  54 | T_Loss 0.29772374 | T_acc 0.903 | V_Loss 0.08085043 | V_acc. 0.969 | 🕒 8.781\n",
      "Epoch:  53 | T_Loss 0.14293386 | T_acc 0.977 | V_Loss 0.44894646 | V_acc.  0.87 | 🕒 8.781\n",
      "Epoch:  52 | T_Loss 0.25024993 | T_acc 0.939 | V_Loss 0.34031881 | V_acc.   0.9 | 🕒  8.72\n",
      "Epoch:  51 | T_Loss 0.44690278 | T_acc 0.793 | V_Loss 0.24064168 | V_acc. 0.967 | 🕒 8.843\n",
      "Epoch:  50 | T_Loss 0.41283909 | T_acc 0.869 | V_Loss 0.62083927 | V_acc. 0.684 | 🕒 8.672\n",
      "Epoch:  49 | T_Loss 0.35167998 | T_acc 0.903 | V_Loss 0.32563801 | V_acc. 0.884 | 🕒 10.538\n",
      "Epoch:  48 | T_Loss 0.39541062 | T_acc 0.881 | V_Loss 0.40712866 | V_acc. 0.836 | 🕒 10.585\n",
      "Epoch:  47 | T_Loss 0.06866822 | T_acc 0.993 | V_Loss 0.11699137 | V_acc. 0.966 | 🕒 10.71\n",
      "Epoch:  46 | T_Loss 0.1010847 | T_acc 0.979 | V_Loss 0.41257864 | V_acc. 0.898 | 🕒 10.522\n",
      "Epoch:  45 | T_Loss 0.09485978 | T_acc 0.977 | V_Loss 0.14179458 | V_acc. 0.966 | 🕒 10.742\n",
      "Epoch:  44 | T_Loss 0.09178643 | T_acc 0.984 | V_Loss 0.10359567 | V_acc. 0.967 | 🕒  10.6\n",
      "Epoch:  43 | T_Loss 0.07225644 | T_acc 0.993 | V_Loss 0.07073588 | V_acc. 0.983 | 🕒 10.538\n",
      "Epoch:  42 | T_Loss 0.08211384 | T_acc 0.993 | V_Loss 0.11853121 | V_acc. 0.967 | 🕒 10.71\n",
      "Epoch:  41 | T_Loss 0.173788 | T_acc 0.953 | V_Loss 0.14299833 | V_acc. 0.983 | 🕒 10.663\n",
      "Epoch:  40 | T_Loss 0.10244901 | T_acc 0.981 | V_Loss 0.0584142 | V_acc. 0.983 | 🕒 10.527\n",
      "Epoch:  39 | T_Loss 0.11138479 | T_acc 0.981 | V_Loss 0.15517798 | V_acc. 0.966 | 🕒 10.749\n",
      "Epoch:  38 | T_Loss 0.24410241 | T_acc 0.939 | V_Loss 0.05424922 | V_acc.   1.0 | 🕒 10.521\n",
      "Epoch:  37 | T_Loss 0.25451615 | T_acc 0.929 | V_Loss 0.21948602 | V_acc. 0.934 | 🕒 10.475\n",
      "Epoch:  36 | T_Loss 0.09338908 | T_acc 0.981 | V_Loss 0.11401864 | V_acc. 0.966 | 🕒  10.6\n",
      "Epoch:  35 | T_Loss 0.07573057 | T_acc 0.995 | V_Loss 0.08729897 | V_acc. 0.983 | 🕒 10.725\n",
      "Epoch:  34 | T_Loss 0.07731295 | T_acc 0.995 | V_Loss 0.0942326 | V_acc. 0.983 | 🕒 10.599\n",
      "Epoch:  33 | T_Loss 0.09638913 | T_acc 0.988 | V_Loss 0.09315646 | V_acc. 0.983 | 🕒 10.566\n",
      "Epoch:  32 | T_Loss 0.09019763 | T_acc 0.988 | V_Loss 0.09484656 | V_acc. 0.966 | 🕒 10.682\n",
      "Epoch:  31 | T_Loss 0.10948524 | T_acc 0.983 | V_Loss 0.0864024 | V_acc. 0.983 | 🕒 10.647\n",
      "Epoch:  30 | T_Loss 0.14053805 | T_acc 0.969 | V_Loss 0.08763086 | V_acc.   1.0 | 🕒 10.585\n",
      "Epoch:  29 | T_Loss 0.13845207 | T_acc 0.974 | V_Loss 0.10753746 | V_acc. 0.983 | 🕒 10.534\n",
      "Epoch:  28 | T_Loss 0.18033184 | T_acc 0.951 | V_Loss 0.11324518 | V_acc. 0.983 | 🕒 10.726\n",
      "Epoch:  27 | T_Loss 0.2367651 | T_acc 0.936 | V_Loss 0.08608936 | V_acc.   1.0 | 🕒 10.46\n",
      "Epoch:  26 | T_Loss 0.32135364 | T_acc 0.899 | V_Loss 0.25376266 | V_acc. 0.901 | 🕒 10.647\n",
      "Epoch:  25 | T_Loss 0.22581453 | T_acc 0.941 | V_Loss 0.22237669 | V_acc. 0.901 | 🕒 10.585\n",
      "Epoch:  24 | T_Loss 0.25242229 | T_acc 0.925 | V_Loss 0.25946786 | V_acc. 0.901 | 🕒 10.538\n",
      "Epoch:  23 | T_Loss 0.22510079 | T_acc 0.931 | V_Loss 0.21771999 | V_acc.  0.95 | 🕒 10.663\n",
      "Epoch:  22 | T_Loss 0.25402408 | T_acc 0.936 | V_Loss 0.34837836 | V_acc. 0.837 | 🕒  10.6\n",
      "Epoch:  21 | T_Loss 0.2827119 | T_acc 0.908 | V_Loss 0.36061174 | V_acc. 0.884 | 🕒 10.554\n",
      "Epoch:  20 | T_Loss 0.29928113 | T_acc 0.887 | V_Loss 0.17328515 | V_acc. 0.933 | 🕒 10.645\n",
      "Epoch:  19 | T_Loss 0.27834293 | T_acc 0.913 | V_Loss 0.35907294 | V_acc.  0.85 | 🕒 10.537\n",
      "Epoch:  18 | T_Loss 0.33188829 | T_acc 0.892 | V_Loss 0.23208455 | V_acc. 0.919 | 🕒 10.538\n",
      "Epoch:  17 | T_Loss 0.33777829 | T_acc 0.855 | V_Loss 0.27889624 | V_acc. 0.869 | 🕒 10.569\n",
      "Epoch:  16 | T_Loss 0.29028472 | T_acc 0.905 | V_Loss 0.23371254 | V_acc. 0.915 | 🕒 10.663\n",
      "Epoch:  15 | T_Loss 0.2953176 | T_acc 0.915 | V_Loss 0.22711121 | V_acc. 0.917 | 🕒 10.569\n",
      "Epoch:  14 | T_Loss 0.33054049 | T_acc 0.887 | V_Loss 0.26752786 | V_acc. 0.884 | 🕒 10.444\n",
      "Epoch:  13 | T_Loss 0.35501167 | T_acc 0.841 | V_Loss 0.27567868 | V_acc. 0.886 | 🕒  10.6\n",
      "Epoch:  12 | T_Loss 0.3831986 | T_acc 0.814 | V_Loss 0.29191574 | V_acc.   0.9 | 🕒 10.506\n",
      "Epoch:  11 | T_Loss 0.39887099 | T_acc 0.832 | V_Loss 0.40922301 | V_acc. 0.753 | 🕒 10.396\n",
      "Epoch:  10 | T_Loss 0.40884411 | T_acc 0.847 | V_Loss 0.32367972 | V_acc. 0.865 | 🕒 10.632\n",
      "Epoch:   9 | T_Loss 0.44300739 | T_acc  0.81 | V_Loss 0.39526337 | V_acc. 0.851 | 🕒 10.625\n",
      "Epoch:   8 | T_Loss 0.5051311 | T_acc 0.793 | V_Loss 0.48320356 | V_acc. 0.801 | 🕒 10.633\n",
      "Epoch:   7 | T_Loss 0.46154421 | T_acc 0.792 | V_Loss 0.35121717 | V_acc. 0.869 | 🕒 10.71\n",
      "Epoch:   6 | T_Loss 0.50981053 | T_acc 0.765 | V_Loss 0.39946061 | V_acc. 0.818 | 🕒 10.537\n",
      "Epoch:   5 | T_Loss 0.67568291 | T_acc 0.716 | V_Loss 0.40527843 | V_acc. 0.851 | 🕒 10.397\n",
      "Epoch:   4 | T_Loss 0.76378694 | T_acc 0.675 | V_Loss 0.98480931 | V_acc. 0.634 | 🕒 10.542\n",
      "Epoch:   3 | T_Loss 0.68328006 | T_acc 0.771 | V_Loss 0.93632114 | V_acc. 0.618 | 🕒 10.663\n",
      "Epoch:   2 | T_Loss 0.97080613 | T_acc 0.603 | V_Loss 0.70800886 | V_acc.  0.82 | 🕒 10.692\n",
      "Epoch:   1 | T_Loss 1.43236372 | T_acc 0.378 | V_Loss 1.35779953 | V_acc. 0.739 | 🕒 10.873\n",
      "\n",
      " Training completed!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "clear_memory()\n",
    "init_model()\n",
    "init_epoch()\n",
    "init_log()\n",
    "maximum_epoch = 200\n",
    "min_loss = 1\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "    tloss, tacc = epoch(train_loader, mode = 'train')\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = epoch(val_loader, mode = 'val')\n",
    "        record_valid_log(vloss, vacc)\n",
    "        if vloss < min_loss:\n",
    "            print('최소 Loss 달성. 모델 저장: {}'.format(epoch_cnt))\n",
    "            min_loss = vloss\n",
    "            torch.save(net_lstm.state_dict(), './model_lstm_yolo_cnn_mediapipe_flatten.pth')\n",
    "    print_log()\n",
    "print('\\n Training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52dc7ad8",
   "metadata": {},
   "source": [
    "### Validation 없이 정해진 epoch 만큼 무대포 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8b918af7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                 | 1/200 [00:12<41:51, 12.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.5562722027301787 | Train Acc.: 0.3015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                                 | 2/200 [00:24<41:09, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.609740573167801 | Train Acc.: 0.2734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▏                                                                                | 3/200 [00:36<40:09, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.3824373602867126 | Train Acc.: 0.4015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▋                                                                                | 4/200 [00:48<39:37, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1053228229284286 | Train Acc.: 0.5234375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██                                                                                | 5/200 [01:00<39:14, 12.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4448714971542358 | Train Acc.: 0.340625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                               | 6/200 [01:13<39:11, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.0205936074256896 | Train Acc.: 0.571875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▊                                                                               | 7/200 [01:25<38:52, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.9370588600635529 | Train Acc.: 0.68125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▎                                                                              | 8/200 [01:37<38:44, 12.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6613143354654312 | Train Acc.: 0.74375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▋                                                                              | 9/200 [01:49<38:30, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.776952576637268 | Train Acc.: 0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████                                                                             | 10/200 [02:01<38:38, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7065513581037521 | Train Acc.: 0.725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▍                                                                            | 11/200 [02:14<38:31, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.481808640062809 | Train Acc.: 0.790625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▊                                                                            | 12/200 [02:26<38:31, 12.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5357461620122195 | Train Acc.: 0.753125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████▎                                                                           | 13/200 [02:38<38:10, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4340649411082268 | Train Acc.: 0.784375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▋                                                                           | 14/200 [02:50<37:54, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.48817544132471086 | Train Acc.: 0.7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████                                                                           | 15/200 [03:03<37:41, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.246781387925148 | Train Acc.: 0.4875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▍                                                                          | 16/200 [03:15<37:26, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7749904811382293 | Train Acc.: 0.6640625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▉                                                                          | 17/200 [03:27<37:14, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.5600910440087319 | Train Acc.: 0.7625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▎                                                                         | 18/200 [03:39<37:01, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4221699424088001 | Train Acc.: 0.8140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▋                                                                         | 19/200 [03:51<36:37, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4140020221471786 | Train Acc.: 0.809375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                         | 20/200 [04:03<36:22, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4730842486023903 | Train Acc.: 0.778125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▌                                                                        | 21/200 [04:15<36:15, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4340644083917141 | Train Acc.: 0.790625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▉                                                                        | 22/200 [04:28<36:07, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.4130070053040981 | Train Acc.: 0.8046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▎                                                                       | 23/200 [04:40<35:45, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.38622174970805645 | Train Acc.: 0.7984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▋                                                                       | 24/200 [04:52<35:39, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.40837560296058656 | Train Acc.: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████▏                                                                      | 25/200 [05:04<35:28, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3669027552008629 | Train Acc.: 0.8203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▌                                                                      | 26/200 [05:16<35:17, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.40705479085445406 | Train Acc.: 0.821875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|██████████▉                                                                      | 27/200 [05:28<35:02, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3450966689735651 | Train Acc.: 0.840625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▎                                                                     | 28/200 [05:41<34:54, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3388488177210093 | Train Acc.: 0.8390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▋                                                                     | 29/200 [05:53<34:38, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3207618944346905 | Train Acc.: 0.8703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▏                                                                    | 30/200 [06:05<34:23, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2980787131935358 | Train Acc.: 0.8953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▌                                                                    | 31/200 [06:17<34:10, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.266800906509161 | Train Acc.: 0.9140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▉                                                                    | 32/200 [06:29<34:04, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.24623051211237906 | Train Acc.: 0.93125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                   | 33/200 [06:41<33:45, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.23677500411868097 | Train Acc.: 0.925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▊                                                                   | 34/200 [06:54<33:51, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1920301079750061 | Train Acc.: 0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▏                                                                  | 35/200 [07:06<33:30, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.18892292268574237 | Train Acc.: 0.959375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▌                                                                  | 36/200 [07:18<33:12, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1761402938514948 | Train Acc.: 0.953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▉                                                                  | 37/200 [07:30<32:59, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.21405744105577468 | Train Acc.: 0.953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▍                                                                 | 38/200 [07:42<32:42, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.20108128972351552 | Train Acc.: 0.9375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▊                                                                 | 39/200 [07:54<32:31, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.13825453147292138 | Train Acc.: 0.978125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▏                                                                | 40/200 [08:06<32:24, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.19409255757927896 | Train Acc.: 0.9359375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                | 41/200 [08:19<32:11, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.22668616157025098 | Train Acc.: 0.9390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████                                                                | 42/200 [08:31<32:11, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2854135125875473 | Train Acc.: 0.915625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▍                                                               | 43/200 [08:43<32:03, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.16754995472729206 | Train Acc.: 0.9609375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▊                                                               | 44/200 [08:55<31:47, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.12045861594378948 | Train Acc.: 0.9796875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▏                                                              | 45/200 [09:08<31:31, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.09761974420398474 | Train Acc.: 0.990625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▋                                                              | 46/200 [09:20<31:18, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.09647665806114673 | Train Acc.: 0.9859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████                                                              | 47/200 [09:32<30:59, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07687714248895645 | Train Acc.: 0.996875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▍                                                             | 48/200 [09:44<30:57, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06525951158255339 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▊                                                             | 49/200 [09:56<30:44, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.09046789165586233 | Train Acc.: 0.9828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▎                                                            | 50/200 [10:09<30:31, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.08382844068109989 | Train Acc.: 0.9828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▋                                                            | 51/200 [10:21<30:19, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06285282485187053 | Train Acc.: 0.9984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████                                                            | 52/200 [10:33<30:12, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0587196808308363 | Train Acc.: 0.9984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▍                                                           | 53/200 [10:45<29:56, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.05651854481548071 | Train Acc.: 0.9984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▊                                                           | 54/200 [10:57<29:38, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06460223887115717 | Train Acc.: 0.990625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▎                                                          | 55/200 [11:09<29:23, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.050677483342587946 | Train Acc.: 0.9984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▋                                                          | 56/200 [11:22<29:10, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.047531753219664095 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████                                                          | 57/200 [11:34<28:56, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.04472337421029806 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▍                                                         | 58/200 [11:46<28:46, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0431828036904335 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████▉                                                         | 59/200 [11:58<28:38, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.04202999658882618 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▎                                                        | 60/200 [12:10<28:20, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.04075381550937891 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▋                                                        | 61/200 [12:22<28:04, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03923599794507027 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████                                                        | 62/200 [12:34<27:55, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03839589608833194 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▌                                                       | 63/200 [12:47<27:55, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0378752252086997 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▉                                                       | 64/200 [12:59<27:46, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03661515414714813 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▎                                                      | 65/200 [13:11<27:34, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03542623091489076 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▋                                                      | 66/200 [13:24<27:20, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03449692949652672 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▏                                                     | 67/200 [13:36<27:23, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03365311222150922 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▌                                                     | 68/200 [13:49<27:15, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03261800883337855 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▉                                                     | 69/200 [14:01<27:08, 12.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03196633430197835 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▎                                                    | 70/200 [14:14<26:47, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03148672692477703 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████████▊                                                    | 71/200 [14:26<26:39, 12.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.030639569275081158 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▏                                                   | 72/200 [14:38<26:24, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.029807573091238736 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▌                                                   | 73/200 [14:51<26:17, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.029105077404528855 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▉                                                   | 74/200 [15:03<25:56, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.028596260119229555 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▍                                                  | 75/200 [15:16<25:51, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.02773111527785659 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▊                                                  | 76/200 [15:28<25:31, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.027409136667847632 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████▏                                                 | 77/200 [15:40<25:16, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.026325554959475993 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▌                                                 | 78/200 [15:53<25:11, 12.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.026079139951616526 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████▉                                                 | 79/200 [16:05<25:06, 12.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.02543097548186779 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▍                                                | 80/200 [16:17<24:48, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.025113501865416766 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                | 81/200 [16:30<24:45, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.024399411864578724 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▏                                               | 82/200 [16:43<24:32, 12.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.02364073246717453 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▌                                               | 83/200 [16:55<24:13, 12.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.023349911905825138 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████                                               | 84/200 [17:07<23:54, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.022912856098264454 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████▍                                              | 85/200 [17:19<23:36, 12.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.022415821440517902 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▊                                              | 86/200 [17:32<23:20, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.022043856605887414 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▏                                             | 87/200 [17:44<23:13, 12.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.021299674827605485 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▋                                             | 88/200 [17:56<22:58, 12.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.021103970520198346 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████                                             | 89/200 [18:08<22:37, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.020625346060842275 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▍                                            | 90/200 [18:20<22:15, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.020404841750860214 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▊                                            | 91/200 [18:33<22:17, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.019862208049744368 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▎                                           | 92/200 [18:45<21:59, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.019361413549631834 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▋                                           | 93/200 [18:57<21:44, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.018863930320367216 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████                                           | 94/200 [19:09<21:33, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.018680054368451236 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▍                                          | 95/200 [19:22<21:27, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.018269384186714886 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▉                                          | 96/200 [19:34<21:13, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.018069696426391602 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▎                                         | 97/200 [19:46<21:03, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.017658210545778274 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▋                                         | 98/200 [19:58<20:44, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.017263082275167107 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████                                         | 99/200 [20:10<20:31, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.017032346967607737 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████                                        | 100/200 [20:22<20:14, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01670285053551197 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▍                                       | 101/200 [20:35<20:01, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.016545497067272662 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▊                                       | 102/200 [20:47<19:47, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.016118993004783987 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▏                                      | 103/200 [20:59<19:44, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01585315531119704 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▌                                      | 104/200 [21:11<19:26, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.015560863632708788 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████                                      | 105/200 [21:23<19:17, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.015273001976311207 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▍                                     | 106/200 [21:35<19:03, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01483508450910449 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████████████████████████▊                                     | 107/200 [21:48<18:54, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.014784100791439414 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▏                                    | 108/200 [22:00<18:40, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.014445903478190303 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████████████████████████▌                                    | 109/200 [22:12<18:27, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.014251694781705737 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████                                    | 110/200 [22:24<18:14, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.013909528451040386 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▍                                   | 111/200 [22:37<18:07, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.013700911216437817 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▊                                   | 112/200 [22:49<17:54, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.013611599523574113 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▏                                  | 113/200 [23:01<17:42, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01328115831129253 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▌                                  | 114/200 [23:13<17:34, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01304667117074132 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████                                  | 115/200 [23:26<17:30, 12.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.012802087143063546 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▍                                 | 116/200 [23:38<17:22, 12.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.012533469451591372 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▊                                 | 117/200 [23:51<17:03, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01228162283077836 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████▏                                | 118/200 [24:03<16:46, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.012150818621739745 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████▌                                | 119/200 [24:15<16:32, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.011842952482402325 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████                                | 120/200 [24:27<16:15, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.011717319674789905 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▍                               | 121/200 [24:39<16:03, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.011522178817540408 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▊                               | 122/200 [24:51<15:49, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.011267818044871092 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▏                              | 123/200 [25:04<15:40, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.011148675670847296 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▌                              | 124/200 [25:16<15:25, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01089322785846889 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████                              | 125/200 [25:28<15:14, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.010706146340817213 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▍                             | 126/200 [25:40<14:59, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.010482265148311853 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████████████████████████████▊                             | 127/200 [25:52<14:49, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.010475456528365613 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▏                            | 128/200 [26:04<14:35, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.010239867167547346 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▌                            | 129/200 [26:16<14:21, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.00998320858925581 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████                            | 130/200 [26:28<14:07, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.009842725563794374 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▍                           | 131/200 [26:41<13:58, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.009723876090720295 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▊                           | 132/200 [26:53<13:46, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.009511759271845222 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████▏                          | 133/200 [27:05<13:35, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.00936130601912737 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▌                          | 134/200 [27:17<13:23, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.00927501511760056 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████                          | 135/200 [27:30<13:15, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.009222152130678295 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▍                         | 136/200 [27:42<13:00, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.008922016946598887 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▊                         | 137/200 [27:54<12:46, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.008914366248063743 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████▏                        | 138/200 [28:06<12:32, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.008728046598844231 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▌                        | 139/200 [28:18<12:24, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.008635942684486508 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████                        | 140/200 [28:30<12:10, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.008436326077207923 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████▍                       | 141/200 [28:42<11:54, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.008306362945586444 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▊                       | 142/200 [28:55<11:43, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.008188414364121854 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▏                      | 143/200 [29:07<11:33, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.008115340163931251 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▌                      | 144/200 [29:19<11:19, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.007969657727517187 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|██████████████████████████████████████████████████████████                      | 145/200 [29:31<11:06, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.007856496260501444 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▍                     | 146/200 [29:43<10:52, 12.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.007720725261606276 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████████████████████████████▊                     | 147/200 [29:55<10:42, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.007588904397562146 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▏                    | 148/200 [30:07<10:29, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.007513595814816654 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▌                    | 149/200 [30:19<10:19, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.007340808585286141 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████████████████████████                    | 150/200 [30:32<10:06, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.007250930927693844 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▍                   | 151/200 [30:44<09:54, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0071320292772725224 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▊                   | 152/200 [30:56<09:42, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006984920660033822 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|█████████████████████████████████████████████████████████████▏                  | 153/200 [31:08<09:31, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006988476449623704 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▌                  | 154/200 [31:20<09:17, 12.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006901055504567921 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████                  | 155/200 [31:32<09:09, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006752000679261983 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▍                 | 156/200 [31:45<09:02, 12.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006596947647631168 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▊                 | 157/200 [31:57<08:46, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006504785013385117 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████▏                | 158/200 [32:09<08:33, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006457323138602078 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▌                | 159/200 [32:22<08:24, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006368579901754856 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████                | 160/200 [32:34<08:11, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006267222482711077 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████▍               | 161/200 [32:46<07:56, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0061708326451480385 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▊               | 162/200 [32:58<07:45, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006125635490752757 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▏              | 163/200 [33:11<07:33, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005983716831542552 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▌              | 164/200 [33:23<07:20, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005868861102499068 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|██████████████████████████████████████████████████████████████████              | 165/200 [33:35<07:07, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005781250377185643 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▍             | 166/200 [33:47<06:56, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0057388409739360215 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████████████████████████████████████▊             | 167/200 [34:00<06:44, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005605166568420828 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▏            | 168/200 [34:12<06:30, 12.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005704467394389212 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▌            | 169/200 [34:24<06:18, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.00550792443100363 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████████            | 170/200 [34:36<06:05, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005396402371115982 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▍           | 171/200 [34:49<05:55, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0053421646589413285 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▊           | 172/200 [35:00<05:40, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005218225787393749 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|█████████████████████████████████████████████████████████████████████▏          | 173/200 [35:13<05:28, 12.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005172522063367069 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▌          | 174/200 [35:25<05:15, 12.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005058585898950696 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████          | 175/200 [35:37<05:03, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005034128832630813 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▍         | 176/200 [35:49<04:52, 12.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005024228245019913 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▊         | 177/200 [36:01<04:39, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0049758859444409605 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████▏        | 178/200 [36:13<04:27, 12.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.00485047921538353 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████▌        | 179/200 [36:26<04:17, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.00478313046041876 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████        | 180/200 [36:38<04:04, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004666205472312867 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████▍       | 181/200 [36:50<03:52, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004643229162320494 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▊       | 182/200 [37:02<03:39, 12.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004553440259769559 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▏      | 183/200 [37:15<03:28, 12.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004508231591898948 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▌      | 184/200 [37:27<03:15, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004445636353921145 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|██████████████████████████████████████████████████████████████████████████      | 185/200 [37:39<03:03, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004393591929692775 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▍     | 186/200 [37:52<02:51, 12.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004294405074324459 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|██████████████████████████████████████████████████████████████████████████▊     | 187/200 [38:04<02:40, 12.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004280638042837381 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▏    | 188/200 [38:16<02:27, 12.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004216029774397612 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 189/200 [38:29<02:14, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004124440893065184 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████████████████████████████████████████    | 190/200 [38:41<02:02, 12.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.00410918693523854 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▍   | 191/200 [38:53<01:50, 12.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004070170084014535 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▊   | 192/200 [39:05<01:37, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004015956714283675 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████████████████████████████████████████████████████████████████████████▏  | 193/200 [39:17<01:25, 12.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0039269485976547005 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▌  | 194/200 [39:29<01:12, 12.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0038937511155381797 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████  | 195/200 [39:41<01:00, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0037929059588350357 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▍ | 196/200 [39:53<00:48, 12.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0038128949468955397 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▊ | 197/200 [40:06<00:36, 12.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.003752652951516211 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|███████████████████████████████████████████████████████████████████████████████▏| 198/200 [40:18<00:24, 12.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0036997174145653846 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████████████████████████████████████████▌| 199/200 [40:30<00:12, 12.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0036767597193829715 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [40:43<00:00, 12.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0036361247999593615 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training completed!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import copy\n",
    "clear_memory()\n",
    "\n",
    "only_train = copy.deepcopy(dataset_dict_list)\n",
    "random.shuffle(only_train)\n",
    "train_dataset = dataset_lstm(only_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "init_model()\n",
    "maximum_epoch = 200\n",
    "for i in tqdm(range(maximum_epoch)):\n",
    "    tloss, tacc = epoch(train_loader, mode = 'train')\n",
    "    print('Train Loss: {} | Train Acc.: {}'.format(tloss, tacc))\n",
    "torch.save(net_lstm.state_dict(), './model_lstm_yolo_cnn_mediapipe_flatten_wholetrain.pth')\n",
    "print('\\n Training completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02848b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1ef6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313bbf1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182982d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c0167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57e069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0111c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
