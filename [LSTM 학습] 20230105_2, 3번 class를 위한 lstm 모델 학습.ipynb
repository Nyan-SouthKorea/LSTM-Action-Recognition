{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b091862a",
   "metadata": {},
   "source": [
    "### 2, 3ë²ˆ classë§Œ LSTM í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fbe71f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\nyan/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-9-15 Python-3.8.15 torch-1.10.1 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11264MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 322 layers, 86173414 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 121/121 [02:54<00:00,  1.44s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133/133 [03:11<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# ëª¨ë“  ë™ì˜ìƒ frameì˜ bbox x1, y1, x2, y2ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë ˆì´ë¸”ë§ í•´ì„œ ì €ì¥\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path = './yolov5-master/exp3/weights/best.pt')\n",
    "def yolo_to_lstm(video_path, frame_ea):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if cap.isOpened():\n",
    "        bbox_list = []\n",
    "        while True:\n",
    "            ret, img = cap.read()\n",
    "            if ret == True:\n",
    "                # yoloì— ì´ë¯¸ì§€ ë„£ì–´ì„œ ê²°ê³¼ ë°›ê¸°\n",
    "                h, w, c = img.shape\n",
    "                pred_list = model(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                pred_list = pred_list.pandas().xyxy[0]\n",
    "                result_list = []\n",
    "                for cnt in range(len(pred_list)):\n",
    "                    x1 = int(pred_list.loc[cnt]['xmin']) / w\n",
    "                    y1 = int(pred_list.loc[cnt]['ymin']) / h\n",
    "                    x2 = int(pred_list.loc[cnt]['xmax']) / w\n",
    "                    y2 = int(pred_list.loc[cnt]['ymax']) / h\n",
    "                    conf = round(float(pred_list.loc[cnt]['confidence']), 3)\n",
    "                    pred = {'bbox' : [x1, y1, x2, y2], 'conf' : conf}\n",
    "                    result_list.append(pred)\n",
    "                # yoloì— ê²€ì¶œëœ ê²ƒì´ ìˆë‹¤ë©´ bbox_listì— x1, y1, x2, y2ë¥¼ ì¶”ê°€í•˜ê¸°\n",
    "                if len(result_list) > 0:\n",
    "                    result_list.sort(key = lambda x:x['conf'], reverse = True)\n",
    "                    result = result_list[0]\n",
    "                    bbox_list.append(result['bbox'])\n",
    "                else: continue\n",
    "                # bbox_listì˜ ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ frame_eaì˜ ê°œìˆ˜ì— ë§ê²Œ ì¦ê°•í•´ì£¼ê¸°\n",
    "                need_aug = frame_ea - len(bbox_list)\n",
    "                aug_tempo = need_aug / len(bbox_list)\n",
    "                aug_bbox_list = []\n",
    "                cnt = 0\n",
    "                for bbox in bbox_list:\n",
    "                    aug_bbox_list.append(bbox)\n",
    "                    cnt += aug_tempo\n",
    "                    while True:\n",
    "                        if cnt < 1: break\n",
    "                        aug_bbox_list.append(bbox)\n",
    "                        cnt -= 1\n",
    "            else: break\n",
    "    # ë°ì´í„° ê¸¸ì´ê°€ ì•Œê³ ë¦¬ì¦˜ íŠ¹ì„± ìƒ 29 or 30ì´ê¸° ë•Œë¬¸ì— ê°•ì œë¡œ 29ë¡œ ë§ì¶˜ë‹¤\n",
    "    while True:\n",
    "        if len(aug_bbox_list) == 29 or len(aug_bbox_list) == 0: break\n",
    "        del aug_bbox_list[-1]\n",
    "    return aug_bbox_list\n",
    "\n",
    "# LSTMì— ë„£ì„ ë°ì´í„°ì…‹ ìƒì„±\n",
    "dataset = []\n",
    "path_2 = './train_video/2'\n",
    "path_3 = './train_video/3'\n",
    "# 2ë²ˆ classì— ëŒ€ë‹¹í•˜ëŠ” ë°ì´í„°ì…‹ì„ ë§Œë“¬\n",
    "video_list = os.listdir(path_2)\n",
    "for video_name in tqdm(video_list):\n",
    "    bbox_list = yolo_to_lstm('{}/{}'.format(path_2, video_name), 29)\n",
    "    if len(bbox_list) > 0:\n",
    "        dataset.append({'key': 2, 'value': bbox_list})\n",
    "\n",
    "# 3ë²ˆ classì— ëŒ€ë‹¹í•˜ëŠ” ë°ì´í„°ì…‹ì„ ë§Œë“¬        \n",
    "video_list = os.listdir(path_3)\n",
    "for video_name in tqdm(video_list):\n",
    "    bbox_list = yolo_to_lstm('{}/{}'.format(path_3, video_name), 29)\n",
    "    if len(bbox_list) > 0:\n",
    "        dataset.append({'key': 3, 'value': bbox_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e62464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, seq_list):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for dic in seq_list :\n",
    "            if dic['key'] == 2: self.y.append(0)\n",
    "            else: self.y.append(1)\n",
    "            self.X.append(dic['value'])\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        data = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061c212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213, 23, 1\n"
     ]
    }
   ],
   "source": [
    "split_ratio = [0.9, 0.1, 0.0]\n",
    "train_len = int(len(dataset) * split_ratio[0])\n",
    "val_len = int(len(dataset) * split_ratio[1])\n",
    "test_len = len(dataset) - train_len - val_len\n",
    "print('{}, {}, {}'.format(train_len, val_len, test_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f0bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "train_dataset = LSTMDataset(dataset)\n",
    "train_data, valid_data, test_data = random_split(train_dataset, [train_len, val_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8)\n",
    "val_loader = DataLoader(valid_data, batch_size=8)\n",
    "test_loader = DataLoader(test_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b442ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class skeleton_LSTM(nn.Module) :\n",
    "    def __init__(self):\n",
    "        super(skeleton_LSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=4, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=128, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=256, hidden_size=512, num_layers=1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.lstm4 = nn.LSTM(input_size=512, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.lstm5 = nn.LSTM(input_size=256, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm6 = nn.LSTM(input_size=128, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.lstm7 = nn.LSTM(input_size=64, hidden_size=32, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(32,2)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x, _ = self.lstm5(x)\n",
    "        x, _ = self.lstm6(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, _ = self.lstm7(x)\n",
    "        x = self.fc(x[:,-1,:])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd85e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í˜„ì¬ ê°€ìƒí™˜ê²½ GPU ì‚¬ìš© ê°€ëŠ¥ìƒíƒœ\n"
     ]
    }
   ],
   "source": [
    "def seed(seed = 1234):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda:0'\n",
    "    print('í˜„ì¬ ê°€ìƒí™˜ê²½ GPU ì‚¬ìš© ê°€ëŠ¥ìƒíƒœ')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('GPU ì‚¬ìš© ë¶ˆê°€ëŠ¥ ìƒíƒœ')\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "def init_model():\n",
    "    plt.rc('font', size = 10)\n",
    "    global net_lstm, loss_fn, optim\n",
    "    net_lstm = skeleton_LSTM().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = Adam(net_lstm.parameters(), lr=0.0001)\n",
    "    \n",
    "# epoch ì¹´ìš´í„° ì´ˆê¸°í™”\n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "    \n",
    "def init_log():\n",
    "    plt.rc('font', size = 10)\n",
    "    # ëª¨ë“  Logë¥¼ ì´ˆê¸°í™”\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []\n",
    "    \n",
    "import gc\n",
    "from torch.cuda import memory_allocated, empty_cache\n",
    "def clear_memory():\n",
    "    if device != 'cpu':\n",
    "        empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# í•™ìŠµ ì•Œê³ ë¦¬ì¦˜\n",
    "import numpy as np\n",
    "def epoch(data_loader, mode = 'train'):\n",
    "    global epoch_cnt\n",
    "    \n",
    "    # ì‚¬ìš©ë˜ëŠ” ë³€ìˆ˜ ì´ˆê¸°í™”\n",
    "    iter_loss, iter_acc, last_grad_performed = [], [], False\n",
    "    \n",
    "    # 1 iteration í•™ìŠµ ì•Œê³ ë¦¬ì¦˜(forë¬¸ì„ ë‚˜ì˜¤ë©´ 1 epoch ì™„ë£Œ)\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.type(torch.LongTensor).to(device)\n",
    "\n",
    "        # 1. Feed-forward\n",
    "        if mode == 'train':\n",
    "            net_lstm.train()\n",
    "        else:\n",
    "            # í•™ìŠµë•Œë§Œ ì“°ì´ëŠ” Dropout, Batch Mormalizationì„ ë¯¸ì‚¬ìš©\n",
    "            net_lstm.eval()\n",
    "\n",
    "        result = net_lstm(data) # 1 Batchì— ëŒ€í•œ ê²°ê³¼ê°€ ëª¨ë“  Classì— ëŒ€í•œ í™•ë¥ ê°’ìœ¼ë¡œ\n",
    "        _, out = torch.max(result, 1) # resultì—ì„œ ìµœëŒ€ í™•ë¥ ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ ì˜ˆì¸¡ class ë„ì¶œ\n",
    "        \n",
    "        # 2. Loss ê³„ì‚°\n",
    "        loss = loss_fn(result, label) # GT ì™€ Label ë¹„êµí•˜ì—¬ Loss ì‚°ì •\n",
    "        iter_loss.append(loss.item()) # í•™ìŠµ ì¶”ì´ë¥¼ ìœ„í•˜ì—¬ Lossë¥¼ ê¸°ë¡\n",
    "        \n",
    "        # 3. ì—­ì „íŒŒ í•™ìŠµ í›„ Gradient Descent\n",
    "        if mode == 'train':\n",
    "            optim.zero_grad() # ë¯¸ë¶„ì„ í†µí•´ ì–»ì€ ê¸°ìš¸ê¸°ë¥´ ì´ˆê¸°í™” for ë‹¤ìŒ epoch\n",
    "            loss.backward() # ì—­ì „íŒŒ í•™ìŠµ\n",
    "            optim.step() # Gradient Descent ìˆ˜í–‰\n",
    "            last_grad_performed = True # forë¬¸ ë‚˜ê°€ë©´ epoch ì¹´ìš´í„° += 1\n",
    "            \n",
    "        # 4. ì •í™•ë„ ê³„ì‚°\n",
    "        acc_partial = (out == label).float().sum() # GT == Label ì¸ ê°œìˆ˜\n",
    "        acc_partial = acc_partial / len(label) # ( TP / (TP + TN)) í•´ì„œ ì •í™•ë„ ì‚°ì¶œ\n",
    "        iter_acc.append(acc_partial.item()) # í•™ìŠµ ì¶”ì´ë¥¼ ìœ„í•˜ì—¬ Acc. ê¸°ë¡\n",
    "        \n",
    "    # ì—­ì „íŒŒ í•™ìŠµ í›„ Epoch ì¹´ìš´í„° += 1\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    # lossì™€ accì˜ í‰ê· ê°’ for í•™ìŠµì¶”ì´ ê·¸ë˜í”„, ëª¨ë“  GTì™€ Labelê°’ for ì»¨í“¨ì „ ë§¤íŠ¸ë¦­ìŠ¤\n",
    "    return np.average(iter_loss), np.average(iter_acc)\n",
    "\n",
    "def epoch_not_finished():\n",
    "    # ì—í­ì´ ëë‚¨ì„ ì•Œë¦¼\n",
    "    return epoch_cnt < maximum_epoch\n",
    "\n",
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    # Train Log ê¸°ë¡ìš©\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "    \n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    # Validation Log ê¸°ë¡ìš©\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "\n",
    "def last(log_list):\n",
    "    # ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ ë§ˆì§€ë§‰ ìˆ«ìë¥¼ ë°˜í™˜(print_log í•¨ìˆ˜ì—ì„œ ì‚¬ìš©)\n",
    "    if len(log_list) > 0:\n",
    "        return log_list[len(log_list) - 1]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "from IPython.display import clear_output\n",
    "def print_log():\n",
    "    # í•™ìŠµ ì¶”ì´ ì¶œë ¥\n",
    "    \n",
    "    # ì†Œìˆ«ì  3ìë¦¬ ìˆ˜ê¹Œì§€ ì¡°ì ˆ\n",
    "    train_loss = round(float(last(tloss_log)), 3)\n",
    "    train_acc = round(float(last(tacc_log)), 3)\n",
    "    val_loss = round(float(last(vloss_log)), 3)\n",
    "    val_acc = round(float(last(vacc_log)), 3)\n",
    "    time_spent = round(float(last(time_log)), 3)\n",
    "    \n",
    "    log_str = 'Epoch: {:3} | T_Loss {:5} | T_acc {:5} | V_Loss {:5} | V_acc. {:5} | \\\n",
    "ğŸ•’ {:5}'.format(last(iter_log), train_loss, train_acc, val_loss, val_acc, time_spent)\n",
    "    \n",
    "    log_stack.append(log_str) # í”„ë¦°íŠ¸ ì¤€ë¹„\n",
    "    \n",
    "    # í•™ìŠµ ì¶”ì´ ê·¸ë˜í”„ ì¶œë ¥\n",
    "    hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99) # ê·¸ë˜í”„ ì‚¬ì´ì¦ˆ ì„¤ì •\n",
    "    hist_fig.patch.set_facecolor('white') # ê·¸ë˜í”„ ë°°ê²½ìƒ‰ ì„¤ì •\n",
    "    \n",
    "    # Loss Line êµ¬ì„±\n",
    "    loss_t_line = plt.plot(iter_log, tloss_log, label='Train Loss', color='red', marker='o')\n",
    "    loss_v_line = plt.plot(iter_log, vloss_log, label='Valid Loss', color='blue', marker='s')\n",
    "    loss_axis.set_xlabel('epoch')\n",
    "    loss_axis.set_ylabel('loss')\n",
    "    \n",
    "    # Acc. Line êµ¬ì„±\n",
    "    acc_axis = loss_axis.twinx()\n",
    "    acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train Acc.', color='red', marker='+')\n",
    "    acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid Acc.', color='blue', marker='x')\n",
    "    acc_axis.set_ylabel('accuracy')\n",
    "    \n",
    "    # ê·¸ë˜í”„ ì¶œë ¥\n",
    "    hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line # ìœ„ì—ì„œ ì„ ì–¸í•œ pltì •ë³´ë“¤ í†µí•©\n",
    "    loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines]) # ìˆœì„œëŒ€ë¡œ ê·¸ë ¤ì£¼ê¸°\n",
    "    loss_axis.grid() # ê²©ì ì„¤ì •\n",
    "    plt.title('Learning history until epoch {}'.format(last(iter_log)))\n",
    "    plt.draw()\n",
    "    \n",
    "    # í…ìŠ¤íŠ¸ ë¡œê·¸ ì¶œë ¥\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n",
    "    for idx in reversed(range(len(log_stack))): # ë°˜ëŒ€ë¡œ sort ì‹œì¼œì„œ ì¶œë ¥\n",
    "        print(log_stack[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9624d121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  30 | T_Loss 0.007 | T_acc   1.0 | V_Loss 0.006 | V_acc.   1.0 | ğŸ•’ 0.508\n",
      "Epoch:  29 | T_Loss 0.007 | T_acc   1.0 | V_Loss 0.007 | V_acc.   1.0 | ğŸ•’ 0.501\n",
      "Epoch:  28 | T_Loss 0.008 | T_acc   1.0 | V_Loss 0.007 | V_acc.   1.0 | ğŸ•’ 0.511\n",
      "Epoch:  27 | T_Loss 0.008 | T_acc   1.0 | V_Loss 0.008 | V_acc.   1.0 | ğŸ•’ 0.498\n",
      "Epoch:  26 | T_Loss 0.009 | T_acc   1.0 | V_Loss 0.008 | V_acc.   1.0 | ğŸ•’ 0.549\n",
      "Epoch:  25 | T_Loss  0.01 | T_acc   1.0 | V_Loss 0.009 | V_acc.   1.0 | ğŸ•’ 0.503\n",
      "Epoch:  24 | T_Loss 0.011 | T_acc   1.0 | V_Loss 0.009 | V_acc.   1.0 | ğŸ•’ 0.579\n",
      "Epoch:  23 | T_Loss 0.012 | T_acc   1.0 | V_Loss  0.01 | V_acc.   1.0 | ğŸ•’ 0.501\n",
      "Epoch:  22 | T_Loss 0.013 | T_acc   1.0 | V_Loss 0.011 | V_acc.   1.0 | ğŸ•’ 0.508\n",
      "Epoch:  21 | T_Loss 0.014 | T_acc   1.0 | V_Loss 0.012 | V_acc.   1.0 | ğŸ•’ 0.558\n",
      "Epoch:  20 | T_Loss 0.015 | T_acc   1.0 | V_Loss 0.014 | V_acc.   1.0 | ğŸ•’ 0.487\n",
      "Epoch:  19 | T_Loss 0.017 | T_acc   1.0 | V_Loss 0.015 | V_acc.   1.0 | ğŸ•’ 0.517\n",
      "Epoch:  18 | T_Loss  0.02 | T_acc   1.0 | V_Loss 0.017 | V_acc.   1.0 | ğŸ•’ 0.484\n",
      "Epoch:  17 | T_Loss 0.023 | T_acc   1.0 | V_Loss 0.019 | V_acc.   1.0 | ğŸ•’ 0.521\n",
      "Epoch:  16 | T_Loss 0.026 | T_acc   1.0 | V_Loss 0.022 | V_acc.   1.0 | ğŸ•’ 0.466\n",
      "Epoch:  15 | T_Loss  0.03 | T_acc   1.0 | V_Loss 0.026 | V_acc.   1.0 | ğŸ•’ 0.497\n",
      "Epoch:  14 | T_Loss 0.038 | T_acc   1.0 | V_Loss 0.032 | V_acc.   1.0 | ğŸ•’ 0.473\n",
      "Epoch:  13 | T_Loss 0.046 | T_acc   1.0 | V_Loss 0.039 | V_acc.   1.0 | ğŸ•’ 0.476\n",
      "Epoch:  12 | T_Loss 0.081 | T_acc 0.991 | V_Loss 0.049 | V_acc.   1.0 | ğŸ•’ 0.473\n",
      "Epoch:  11 | T_Loss 0.103 | T_acc 0.986 | V_Loss 0.161 | V_acc. 0.958 | ğŸ•’ 0.455\n",
      "Epoch:  10 | T_Loss 0.128 | T_acc 0.986 | V_Loss 0.168 | V_acc. 0.958 | ğŸ•’ 0.456\n",
      "Epoch:   9 | T_Loss 0.161 | T_acc 0.986 | V_Loss 0.185 | V_acc. 0.958 | ğŸ•’  0.47\n",
      "Epoch:   8 | T_Loss 0.216 | T_acc 0.986 | V_Loss 0.221 | V_acc. 0.958 | ğŸ•’ 0.481\n",
      "Epoch:   7 | T_Loss 0.278 | T_acc 0.995 | V_Loss 0.275 | V_acc. 0.958 | ğŸ•’ 0.452\n",
      "Epoch:   6 | T_Loss 0.406 | T_acc 0.963 | V_Loss 0.347 | V_acc. 0.958 | ğŸ•’ 0.502\n",
      "Epoch:   5 | T_Loss 0.604 | T_acc 0.527 | V_Loss 0.496 | V_acc. 0.696 | ğŸ•’ 0.466\n",
      "Epoch:   4 | T_Loss 0.691 | T_acc 0.527 | V_Loss 0.684 | V_acc. 0.518 | ğŸ•’ 0.488\n",
      "Epoch:   3 | T_Loss 0.692 | T_acc 0.527 | V_Loss 0.692 | V_acc. 0.518 | ğŸ•’ 0.446\n",
      "Epoch:   2 | T_Loss 0.692 | T_acc 0.527 | V_Loss 0.693 | V_acc. 0.518 | ğŸ•’ 0.503\n",
      "Epoch:   1 | T_Loss 0.693 | T_acc 0.527 | V_Loss 0.693 | V_acc. 0.518 | ğŸ•’ 0.846\n",
      "\n",
      " Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training Initialization\n",
    "init_model()\n",
    "init_epoch()\n",
    "init_log()\n",
    "maximum_epoch = 30\n",
    "\n",
    "# Training Iteration\n",
    "import time\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "    tloss, tacc = epoch(train_loader, mode = 'train')\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = epoch(val_loader, mode = 'val')\n",
    "        record_valid_log(vloss, vacc)\n",
    "    print_log()\n",
    "\n",
    "print('\\n Training completed!')\n",
    "torch.save(net_lstm.state_dict(), './best_model_lstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182982d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c0167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57e069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0111c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
