{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b091862a",
   "metadata": {},
   "source": [
    "### 2, 3번 class만 LSTM 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fbe71f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\nyan/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-9-15 Python-3.8.15 torch-1.10.1 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11264MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 322 layers, 86173414 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [02:54<00:00,  1.44s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 133/133 [03:11<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# 모든 동영상 frame의 bbox x1, y1, x2, y2를 리스트로 레이블링 해서 저장\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path = './yolov5-master/exp3/weights/best.pt')\n",
    "def yolo_to_lstm(video_path, frame_ea):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if cap.isOpened():\n",
    "        bbox_list = []\n",
    "        while True:\n",
    "            ret, img = cap.read()\n",
    "            if ret == True:\n",
    "                # yolo에 이미지 넣어서 결과 받기\n",
    "                h, w, c = img.shape\n",
    "                pred_list = model(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "                pred_list = pred_list.pandas().xyxy[0]\n",
    "                result_list = []\n",
    "                for cnt in range(len(pred_list)):\n",
    "                    x1 = int(pred_list.loc[cnt]['xmin']) / w\n",
    "                    y1 = int(pred_list.loc[cnt]['ymin']) / h\n",
    "                    x2 = int(pred_list.loc[cnt]['xmax']) / w\n",
    "                    y2 = int(pred_list.loc[cnt]['ymax']) / h\n",
    "                    conf = round(float(pred_list.loc[cnt]['confidence']), 3)\n",
    "                    pred = {'bbox' : [x1, y1, x2, y2], 'conf' : conf}\n",
    "                    result_list.append(pred)\n",
    "                # yolo에 검출된 것이 있다면 bbox_list에 x1, y1, x2, y2를 추가하기\n",
    "                if len(result_list) > 0:\n",
    "                    result_list.sort(key = lambda x:x['conf'], reverse = True)\n",
    "                    result = result_list[0]\n",
    "                    bbox_list.append(result['bbox'])\n",
    "                else: continue\n",
    "                # bbox_list의 길이를 기준으로 frame_ea의 개수에 맞게 증강해주기\n",
    "                need_aug = frame_ea - len(bbox_list)\n",
    "                aug_tempo = need_aug / len(bbox_list)\n",
    "                aug_bbox_list = []\n",
    "                cnt = 0\n",
    "                for bbox in bbox_list:\n",
    "                    aug_bbox_list.append(bbox)\n",
    "                    cnt += aug_tempo\n",
    "                    while True:\n",
    "                        if cnt < 1: break\n",
    "                        aug_bbox_list.append(bbox)\n",
    "                        cnt -= 1\n",
    "            else: break\n",
    "    # 데이터 길이가 알고리즘 특성 상 29 or 30이기 때문에 강제로 29로 맞춘다\n",
    "    while True:\n",
    "        if len(aug_bbox_list) == 29 or len(aug_bbox_list) == 0: break\n",
    "        del aug_bbox_list[-1]\n",
    "    return aug_bbox_list\n",
    "\n",
    "# LSTM에 넣을 데이터셋 생성\n",
    "dataset = []\n",
    "path_2 = './train_video/2'\n",
    "path_3 = './train_video/3'\n",
    "# 2번 class에 대당하는 데이터셋을 만듬\n",
    "video_list = os.listdir(path_2)\n",
    "for video_name in tqdm(video_list):\n",
    "    bbox_list = yolo_to_lstm('{}/{}'.format(path_2, video_name), 29)\n",
    "    if len(bbox_list) > 0:\n",
    "        dataset.append({'key': 2, 'value': bbox_list})\n",
    "\n",
    "# 3번 class에 대당하는 데이터셋을 만듬        \n",
    "video_list = os.listdir(path_3)\n",
    "for video_name in tqdm(video_list):\n",
    "    bbox_list = yolo_to_lstm('{}/{}'.format(path_3, video_name), 29)\n",
    "    if len(bbox_list) > 0:\n",
    "        dataset.append({'key': 3, 'value': bbox_list})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e62464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class LSTMDataset(Dataset):\n",
    "    def __init__(self, seq_list):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for dic in seq_list :\n",
    "            if dic['key'] == 2: self.y.append(0)\n",
    "            else: self.y.append(1)\n",
    "            self.X.append(dic['value'])\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        data = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "061c212d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213, 23, 1\n"
     ]
    }
   ],
   "source": [
    "split_ratio = [0.9, 0.1, 0.0]\n",
    "train_len = int(len(dataset) * split_ratio[0])\n",
    "val_len = int(len(dataset) * split_ratio[1])\n",
    "test_len = len(dataset) - train_len - val_len\n",
    "print('{}, {}, {}'.format(train_len, val_len, test_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85f0bc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "train_dataset = LSTMDataset(dataset)\n",
    "train_data, valid_data, test_data = random_split(train_dataset, [train_len, val_len, test_len])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=8)\n",
    "val_loader = DataLoader(valid_data, batch_size=8)\n",
    "test_loader = DataLoader(test_data, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b442ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class skeleton_LSTM(nn.Module) :\n",
    "    def __init__(self):\n",
    "        super(skeleton_LSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=4, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=128, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=256, hidden_size=512, num_layers=1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.lstm4 = nn.LSTM(input_size=512, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.lstm5 = nn.LSTM(input_size=256, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm6 = nn.LSTM(input_size=128, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.lstm7 = nn.LSTM(input_size=64, hidden_size=32, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(32,2)\n",
    "\n",
    "    def forward(self, x) :\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x, _ = self.lstm5(x)\n",
    "        x, _ = self.lstm6(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, _ = self.lstm7(x)\n",
    "        x = self.fc(x[:,-1,:])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7bd85e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 가상환경 GPU 사용 가능상태\n"
     ]
    }
   ],
   "source": [
    "def seed(seed = 1234):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda:0'\n",
    "    print('현재 가상환경 GPU 사용 가능상태')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('GPU 사용 불가능 상태')\n",
    "\n",
    "# 모델 초기화\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "def init_model():\n",
    "    plt.rc('font', size = 10)\n",
    "    global net_lstm, loss_fn, optim\n",
    "    net_lstm = skeleton_LSTM().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = Adam(net_lstm.parameters(), lr=0.0001)\n",
    "    \n",
    "# epoch 카운터 초기화\n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "    \n",
    "def init_log():\n",
    "    plt.rc('font', size = 10)\n",
    "    # 모든 Log를 초기화\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []\n",
    "    \n",
    "import gc\n",
    "from torch.cuda import memory_allocated, empty_cache\n",
    "def clear_memory():\n",
    "    if device != 'cpu':\n",
    "        empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "# 학습 알고리즘\n",
    "import numpy as np\n",
    "def epoch(data_loader, mode = 'train'):\n",
    "    global epoch_cnt\n",
    "    \n",
    "    # 사용되는 변수 초기화\n",
    "    iter_loss, iter_acc, last_grad_performed = [], [], False\n",
    "    \n",
    "    # 1 iteration 학습 알고리즘(for문을 나오면 1 epoch 완료)\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.type(torch.LongTensor).to(device)\n",
    "\n",
    "        # 1. Feed-forward\n",
    "        if mode == 'train':\n",
    "            net_lstm.train()\n",
    "        else:\n",
    "            # 학습때만 쓰이는 Dropout, Batch Mormalization을 미사용\n",
    "            net_lstm.eval()\n",
    "\n",
    "        result = net_lstm(data) # 1 Batch에 대한 결과가 모든 Class에 대한 확률값으로\n",
    "        _, out = torch.max(result, 1) # result에서 최대 확률값을 기준으로 예측 class 도출\n",
    "        \n",
    "        # 2. Loss 계산\n",
    "        loss = loss_fn(result, label) # GT 와 Label 비교하여 Loss 산정\n",
    "        iter_loss.append(loss.item()) # 학습 추이를 위하여 Loss를 기록\n",
    "        \n",
    "        # 3. 역전파 학습 후 Gradient Descent\n",
    "        if mode == 'train':\n",
    "            optim.zero_grad() # 미분을 통해 얻은 기울기르 초기화 for 다음 epoch\n",
    "            loss.backward() # 역전파 학습\n",
    "            optim.step() # Gradient Descent 수행\n",
    "            last_grad_performed = True # for문 나가면 epoch 카운터 += 1\n",
    "            \n",
    "        # 4. 정확도 계산\n",
    "        acc_partial = (out == label).float().sum() # GT == Label 인 개수\n",
    "        acc_partial = acc_partial / len(label) # ( TP / (TP + TN)) 해서 정확도 산출\n",
    "        iter_acc.append(acc_partial.item()) # 학습 추이를 위하여 Acc. 기록\n",
    "        \n",
    "    # 역전파 학습 후 Epoch 카운터 += 1\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "    \n",
    "    clear_memory()\n",
    "    \n",
    "    # loss와 acc의 평균값 for 학습추이 그래프, 모든 GT와 Label값 for 컨퓨전 매트릭스\n",
    "    return np.average(iter_loss), np.average(iter_acc)\n",
    "\n",
    "def epoch_not_finished():\n",
    "    # 에폭이 끝남을 알림\n",
    "    return epoch_cnt < maximum_epoch\n",
    "\n",
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    # Train Log 기록용\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "    \n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    # Validation Log 기록용\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "\n",
    "def last(log_list):\n",
    "    # 리스트 안의 마지막 숫자를 반환(print_log 함수에서 사용)\n",
    "    if len(log_list) > 0:\n",
    "        return log_list[len(log_list) - 1]\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "from IPython.display import clear_output\n",
    "def print_log():\n",
    "    # 학습 추이 출력\n",
    "    \n",
    "    # 소숫점 3자리 수까지 조절\n",
    "    train_loss = round(float(last(tloss_log)), 3)\n",
    "    train_acc = round(float(last(tacc_log)), 3)\n",
    "    val_loss = round(float(last(vloss_log)), 3)\n",
    "    val_acc = round(float(last(vacc_log)), 3)\n",
    "    time_spent = round(float(last(time_log)), 3)\n",
    "    \n",
    "    log_str = 'Epoch: {:3} | T_Loss {:5} | T_acc {:5} | V_Loss {:5} | V_acc. {:5} | \\\n",
    "🕒 {:5}'.format(last(iter_log), train_loss, train_acc, val_loss, val_acc, time_spent)\n",
    "    \n",
    "    log_stack.append(log_str) # 프린트 준비\n",
    "    \n",
    "    # 학습 추이 그래프 출력\n",
    "    hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99) # 그래프 사이즈 설정\n",
    "    hist_fig.patch.set_facecolor('white') # 그래프 배경색 설정\n",
    "    \n",
    "    # Loss Line 구성\n",
    "    loss_t_line = plt.plot(iter_log, tloss_log, label='Train Loss', color='red', marker='o')\n",
    "    loss_v_line = plt.plot(iter_log, vloss_log, label='Valid Loss', color='blue', marker='s')\n",
    "    loss_axis.set_xlabel('epoch')\n",
    "    loss_axis.set_ylabel('loss')\n",
    "    \n",
    "    # Acc. Line 구성\n",
    "    acc_axis = loss_axis.twinx()\n",
    "    acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train Acc.', color='red', marker='+')\n",
    "    acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid Acc.', color='blue', marker='x')\n",
    "    acc_axis.set_ylabel('accuracy')\n",
    "    \n",
    "    # 그래프 출력\n",
    "    hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line # 위에서 선언한 plt정보들 통합\n",
    "    loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines]) # 순서대로 그려주기\n",
    "    loss_axis.grid() # 격자 설정\n",
    "    plt.title('Learning history until epoch {}'.format(last(iter_log)))\n",
    "    plt.draw()\n",
    "    \n",
    "    # 텍스트 로그 출력\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n",
    "    for idx in reversed(range(len(log_stack))): # 반대로 sort 시켜서 출력\n",
    "        print(log_stack[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9624d121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  30 | T_Loss 0.007 | T_acc   1.0 | V_Loss 0.006 | V_acc.   1.0 | 🕒 0.508\n",
      "Epoch:  29 | T_Loss 0.007 | T_acc   1.0 | V_Loss 0.007 | V_acc.   1.0 | 🕒 0.501\n",
      "Epoch:  28 | T_Loss 0.008 | T_acc   1.0 | V_Loss 0.007 | V_acc.   1.0 | 🕒 0.511\n",
      "Epoch:  27 | T_Loss 0.008 | T_acc   1.0 | V_Loss 0.008 | V_acc.   1.0 | 🕒 0.498\n",
      "Epoch:  26 | T_Loss 0.009 | T_acc   1.0 | V_Loss 0.008 | V_acc.   1.0 | 🕒 0.549\n",
      "Epoch:  25 | T_Loss  0.01 | T_acc   1.0 | V_Loss 0.009 | V_acc.   1.0 | 🕒 0.503\n",
      "Epoch:  24 | T_Loss 0.011 | T_acc   1.0 | V_Loss 0.009 | V_acc.   1.0 | 🕒 0.579\n",
      "Epoch:  23 | T_Loss 0.012 | T_acc   1.0 | V_Loss  0.01 | V_acc.   1.0 | 🕒 0.501\n",
      "Epoch:  22 | T_Loss 0.013 | T_acc   1.0 | V_Loss 0.011 | V_acc.   1.0 | 🕒 0.508\n",
      "Epoch:  21 | T_Loss 0.014 | T_acc   1.0 | V_Loss 0.012 | V_acc.   1.0 | 🕒 0.558\n",
      "Epoch:  20 | T_Loss 0.015 | T_acc   1.0 | V_Loss 0.014 | V_acc.   1.0 | 🕒 0.487\n",
      "Epoch:  19 | T_Loss 0.017 | T_acc   1.0 | V_Loss 0.015 | V_acc.   1.0 | 🕒 0.517\n",
      "Epoch:  18 | T_Loss  0.02 | T_acc   1.0 | V_Loss 0.017 | V_acc.   1.0 | 🕒 0.484\n",
      "Epoch:  17 | T_Loss 0.023 | T_acc   1.0 | V_Loss 0.019 | V_acc.   1.0 | 🕒 0.521\n",
      "Epoch:  16 | T_Loss 0.026 | T_acc   1.0 | V_Loss 0.022 | V_acc.   1.0 | 🕒 0.466\n",
      "Epoch:  15 | T_Loss  0.03 | T_acc   1.0 | V_Loss 0.026 | V_acc.   1.0 | 🕒 0.497\n",
      "Epoch:  14 | T_Loss 0.038 | T_acc   1.0 | V_Loss 0.032 | V_acc.   1.0 | 🕒 0.473\n",
      "Epoch:  13 | T_Loss 0.046 | T_acc   1.0 | V_Loss 0.039 | V_acc.   1.0 | 🕒 0.476\n",
      "Epoch:  12 | T_Loss 0.081 | T_acc 0.991 | V_Loss 0.049 | V_acc.   1.0 | 🕒 0.473\n",
      "Epoch:  11 | T_Loss 0.103 | T_acc 0.986 | V_Loss 0.161 | V_acc. 0.958 | 🕒 0.455\n",
      "Epoch:  10 | T_Loss 0.128 | T_acc 0.986 | V_Loss 0.168 | V_acc. 0.958 | 🕒 0.456\n",
      "Epoch:   9 | T_Loss 0.161 | T_acc 0.986 | V_Loss 0.185 | V_acc. 0.958 | 🕒  0.47\n",
      "Epoch:   8 | T_Loss 0.216 | T_acc 0.986 | V_Loss 0.221 | V_acc. 0.958 | 🕒 0.481\n",
      "Epoch:   7 | T_Loss 0.278 | T_acc 0.995 | V_Loss 0.275 | V_acc. 0.958 | 🕒 0.452\n",
      "Epoch:   6 | T_Loss 0.406 | T_acc 0.963 | V_Loss 0.347 | V_acc. 0.958 | 🕒 0.502\n",
      "Epoch:   5 | T_Loss 0.604 | T_acc 0.527 | V_Loss 0.496 | V_acc. 0.696 | 🕒 0.466\n",
      "Epoch:   4 | T_Loss 0.691 | T_acc 0.527 | V_Loss 0.684 | V_acc. 0.518 | 🕒 0.488\n",
      "Epoch:   3 | T_Loss 0.692 | T_acc 0.527 | V_Loss 0.692 | V_acc. 0.518 | 🕒 0.446\n",
      "Epoch:   2 | T_Loss 0.692 | T_acc 0.527 | V_Loss 0.693 | V_acc. 0.518 | 🕒 0.503\n",
      "Epoch:   1 | T_Loss 0.693 | T_acc 0.527 | V_Loss 0.693 | V_acc. 0.518 | 🕒 0.846\n",
      "\n",
      " Training completed!\n"
     ]
    }
   ],
   "source": [
    "# Training Initialization\n",
    "init_model()\n",
    "init_epoch()\n",
    "init_log()\n",
    "maximum_epoch = 30\n",
    "\n",
    "# Training Iteration\n",
    "import time\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "    tloss, tacc = epoch(train_loader, mode = 'train')\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = epoch(val_loader, mode = 'val')\n",
    "        record_valid_log(vloss, vacc)\n",
    "    print_log()\n",
    "\n",
    "print('\\n Training completed!')\n",
    "torch.save(net_lstm.state_dict(), './best_model_lstm.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182982d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c0167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57e069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0111c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
