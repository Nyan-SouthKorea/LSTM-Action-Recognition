{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e8e67a",
   "metadata": {},
   "source": [
    "### 저장된 Yolo 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288762f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\nyan/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-9-15 Python-3.8.15 torch-1.10.1 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11264MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 322 layers, 86173414 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path = './yolov5-master/exp3/weights/best.pt')\n",
    "def net_yolo(img):\n",
    "    h, w, c = img.shape\n",
    "    pred_list = model(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    pred_list = pred_list.pandas().xyxy[0]\n",
    "    result_list = []\n",
    "    for cnt in range(len(pred_list)):\n",
    "        x1 = int(pred_list.loc[cnt]['xmin'])\n",
    "        y1 = int(pred_list.loc[cnt]['ymin'])\n",
    "        x2 = int(pred_list.loc[cnt]['xmax'])\n",
    "        y2 = int(pred_list.loc[cnt]['ymax'])\n",
    "        x1_nor = max(1, int(pred_list.loc[cnt]['xmin'])) / w\n",
    "        y1_nor = max(1, int(pred_list.loc[cnt]['ymin'])) / h\n",
    "        x2_nor = max(1, int(pred_list.loc[cnt]['xmax'])) / w\n",
    "        y2_nor = max(1, int(pred_list.loc[cnt]['ymax'])) / h\n",
    "        conf = round(float(pred_list.loc[cnt]['confidence']), 3)\n",
    "        pred = {'bbox' : [x1, y1, x2, y2], 'conf' : conf, 'bbox_nor' : [x1_nor, y1_nor, x2_nor, y2_nor]}\n",
    "        result_list.append(pred)\n",
    "    if len(result_list) > 0:\n",
    "        result_list.sort(key = lambda x:x['conf'], reverse = True)\n",
    "        result = result_list[0]                    \n",
    "        crop_img = img[result['bbox'][1]:result['bbox'][3], result['bbox'][0]:result['bbox'][2]]\n",
    "        return result['bbox_nor'], crop_img\n",
    "    else:\n",
    "        return [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b091862a",
   "metadata": {},
   "source": [
    "### 저장된 Resnet 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4ab25ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 가상환경 GPU 사용 가능상태\n"
     ]
    }
   ],
   "source": [
    "def seed(seed = 1234):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda:0'\n",
    "    print('현재 가상환경 GPU 사용 가능상태')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('GPU 사용 불가능 상태')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae8e225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-80          [-1, 128, 28, 28]             256\n",
      "             ReLU-81          [-1, 128, 28, 28]               0\n",
      "           Conv2d-82          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-83          [-1, 128, 28, 28]             256\n",
      "             ReLU-84          [-1, 128, 28, 28]               0\n",
      "           Conv2d-85          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-86          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-87          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-88          [-1, 512, 28, 28]               0\n",
      "           Conv2d-89          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-90          [-1, 128, 28, 28]             256\n",
      "             ReLU-91          [-1, 128, 28, 28]               0\n",
      "           Conv2d-92          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-93          [-1, 128, 28, 28]             256\n",
      "             ReLU-94          [-1, 128, 28, 28]               0\n",
      "           Conv2d-95          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-96          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-97          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-98          [-1, 512, 28, 28]               0\n",
      "           Conv2d-99          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-100          [-1, 128, 28, 28]             256\n",
      "            ReLU-101          [-1, 128, 28, 28]               0\n",
      "          Conv2d-102          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
      "            ReLU-104          [-1, 128, 28, 28]               0\n",
      "          Conv2d-105          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-106          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-107          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-108          [-1, 512, 28, 28]               0\n",
      "          Conv2d-109          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-110          [-1, 128, 28, 28]             256\n",
      "            ReLU-111          [-1, 128, 28, 28]               0\n",
      "          Conv2d-112          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-113          [-1, 128, 28, 28]             256\n",
      "            ReLU-114          [-1, 128, 28, 28]               0\n",
      "          Conv2d-115          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-116          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-117          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-118          [-1, 512, 28, 28]               0\n",
      "          Conv2d-119          [-1, 256, 28, 28]         131,072\n",
      "     BatchNorm2d-120          [-1, 256, 28, 28]             512\n",
      "            ReLU-121          [-1, 256, 28, 28]               0\n",
      "          Conv2d-122          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-123          [-1, 256, 14, 14]             512\n",
      "            ReLU-124          [-1, 256, 14, 14]               0\n",
      "          Conv2d-125         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-126         [-1, 1024, 14, 14]           2,048\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-142          [-1, 256, 14, 14]             512\n",
      "            ReLU-143          [-1, 256, 14, 14]               0\n",
      "          Conv2d-144          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-145          [-1, 256, 14, 14]             512\n",
      "            ReLU-146          [-1, 256, 14, 14]               0\n",
      "          Conv2d-147         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-149         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-150         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-151          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-152          [-1, 256, 14, 14]             512\n",
      "            ReLU-153          [-1, 256, 14, 14]               0\n",
      "          Conv2d-154          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-155          [-1, 256, 14, 14]             512\n",
      "            ReLU-156          [-1, 256, 14, 14]               0\n",
      "          Conv2d-157         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-159         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-160         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-161          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-162          [-1, 256, 14, 14]             512\n",
      "            ReLU-163          [-1, 256, 14, 14]               0\n",
      "          Conv2d-164          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-165          [-1, 256, 14, 14]             512\n",
      "            ReLU-166          [-1, 256, 14, 14]               0\n",
      "          Conv2d-167         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-169         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-170         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-171          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-172          [-1, 256, 14, 14]             512\n",
      "            ReLU-173          [-1, 256, 14, 14]               0\n",
      "          Conv2d-174          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-175          [-1, 256, 14, 14]             512\n",
      "            ReLU-176          [-1, 256, 14, 14]               0\n",
      "          Conv2d-177         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-179         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-180         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-181          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-182          [-1, 256, 14, 14]             512\n",
      "            ReLU-183          [-1, 256, 14, 14]               0\n",
      "          Conv2d-184          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-185          [-1, 256, 14, 14]             512\n",
      "            ReLU-186          [-1, 256, 14, 14]               0\n",
      "          Conv2d-187         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-189         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-190         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-191          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-192          [-1, 256, 14, 14]             512\n",
      "            ReLU-193          [-1, 256, 14, 14]               0\n",
      "          Conv2d-194          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-195          [-1, 256, 14, 14]             512\n",
      "            ReLU-196          [-1, 256, 14, 14]               0\n",
      "          Conv2d-197         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-199         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-200         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-201          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-202          [-1, 256, 14, 14]             512\n",
      "            ReLU-203          [-1, 256, 14, 14]               0\n",
      "          Conv2d-204          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-205          [-1, 256, 14, 14]             512\n",
      "            ReLU-206          [-1, 256, 14, 14]               0\n",
      "          Conv2d-207         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-209         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-210         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-211          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-212          [-1, 256, 14, 14]             512\n",
      "            ReLU-213          [-1, 256, 14, 14]               0\n",
      "          Conv2d-214          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-215          [-1, 256, 14, 14]             512\n",
      "            ReLU-216          [-1, 256, 14, 14]               0\n",
      "          Conv2d-217         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-219         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-220         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-221          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-222          [-1, 256, 14, 14]             512\n",
      "            ReLU-223          [-1, 256, 14, 14]               0\n",
      "          Conv2d-224          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-225          [-1, 256, 14, 14]             512\n",
      "            ReLU-226          [-1, 256, 14, 14]               0\n",
      "          Conv2d-227         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-229         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-230         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-231          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 14, 14]             512\n",
      "            ReLU-233          [-1, 256, 14, 14]               0\n",
      "          Conv2d-234          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 14, 14]             512\n",
      "            ReLU-236          [-1, 256, 14, 14]               0\n",
      "          Conv2d-237         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-240         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-241          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-242          [-1, 256, 14, 14]             512\n",
      "            ReLU-243          [-1, 256, 14, 14]               0\n",
      "          Conv2d-244          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-245          [-1, 256, 14, 14]             512\n",
      "            ReLU-246          [-1, 256, 14, 14]               0\n",
      "          Conv2d-247         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-249         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-250         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-251          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-252          [-1, 256, 14, 14]             512\n",
      "            ReLU-253          [-1, 256, 14, 14]               0\n",
      "          Conv2d-254          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-255          [-1, 256, 14, 14]             512\n",
      "            ReLU-256          [-1, 256, 14, 14]               0\n",
      "          Conv2d-257         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-259         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-260         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-261          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-262          [-1, 256, 14, 14]             512\n",
      "            ReLU-263          [-1, 256, 14, 14]               0\n",
      "          Conv2d-264          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-265          [-1, 256, 14, 14]             512\n",
      "            ReLU-266          [-1, 256, 14, 14]               0\n",
      "          Conv2d-267         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-269         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-270         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-271          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-272          [-1, 256, 14, 14]             512\n",
      "            ReLU-273          [-1, 256, 14, 14]               0\n",
      "          Conv2d-274          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-275          [-1, 256, 14, 14]             512\n",
      "            ReLU-276          [-1, 256, 14, 14]               0\n",
      "          Conv2d-277         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-279         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-280         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-281          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-282          [-1, 256, 14, 14]             512\n",
      "            ReLU-283          [-1, 256, 14, 14]               0\n",
      "          Conv2d-284          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-285          [-1, 256, 14, 14]             512\n",
      "            ReLU-286          [-1, 256, 14, 14]               0\n",
      "          Conv2d-287         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-289         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-290         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-291          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-292          [-1, 256, 14, 14]             512\n",
      "            ReLU-293          [-1, 256, 14, 14]               0\n",
      "          Conv2d-294          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-295          [-1, 256, 14, 14]             512\n",
      "            ReLU-296          [-1, 256, 14, 14]               0\n",
      "          Conv2d-297         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-299         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-300         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-301          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-302          [-1, 256, 14, 14]             512\n",
      "            ReLU-303          [-1, 256, 14, 14]               0\n",
      "          Conv2d-304          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-305          [-1, 256, 14, 14]             512\n",
      "            ReLU-306          [-1, 256, 14, 14]               0\n",
      "          Conv2d-307         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-309         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-310         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-311          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-312          [-1, 256, 14, 14]             512\n",
      "            ReLU-313          [-1, 256, 14, 14]               0\n",
      "          Conv2d-314          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-315          [-1, 256, 14, 14]             512\n",
      "            ReLU-316          [-1, 256, 14, 14]               0\n",
      "          Conv2d-317         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-318         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-319         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-320         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-321          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-322          [-1, 256, 14, 14]             512\n",
      "            ReLU-323          [-1, 256, 14, 14]               0\n",
      "          Conv2d-324          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-325          [-1, 256, 14, 14]             512\n",
      "            ReLU-326          [-1, 256, 14, 14]               0\n",
      "          Conv2d-327         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-328         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-329         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-330         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-331          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-332          [-1, 256, 14, 14]             512\n",
      "            ReLU-333          [-1, 256, 14, 14]               0\n",
      "          Conv2d-334          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-335          [-1, 256, 14, 14]             512\n",
      "            ReLU-336          [-1, 256, 14, 14]               0\n",
      "          Conv2d-337         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-338         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-339         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-340         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-341          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-342          [-1, 256, 14, 14]             512\n",
      "            ReLU-343          [-1, 256, 14, 14]               0\n",
      "          Conv2d-344          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-345          [-1, 256, 14, 14]             512\n",
      "            ReLU-346          [-1, 256, 14, 14]               0\n",
      "          Conv2d-347         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-348         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-349         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-350         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-351          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-352          [-1, 256, 14, 14]             512\n",
      "            ReLU-353          [-1, 256, 14, 14]               0\n",
      "          Conv2d-354          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-355          [-1, 256, 14, 14]             512\n",
      "            ReLU-356          [-1, 256, 14, 14]               0\n",
      "          Conv2d-357         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-358         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-359         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-360         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-361          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-362          [-1, 256, 14, 14]             512\n",
      "            ReLU-363          [-1, 256, 14, 14]               0\n",
      "          Conv2d-364          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-365          [-1, 256, 14, 14]             512\n",
      "            ReLU-366          [-1, 256, 14, 14]               0\n",
      "          Conv2d-367         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-368         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-369         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-370         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-371          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-372          [-1, 256, 14, 14]             512\n",
      "            ReLU-373          [-1, 256, 14, 14]               0\n",
      "          Conv2d-374          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-375          [-1, 256, 14, 14]             512\n",
      "            ReLU-376          [-1, 256, 14, 14]               0\n",
      "          Conv2d-377         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-378         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-379         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-380         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-381          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-382          [-1, 256, 14, 14]             512\n",
      "            ReLU-383          [-1, 256, 14, 14]               0\n",
      "          Conv2d-384          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-385          [-1, 256, 14, 14]             512\n",
      "            ReLU-386          [-1, 256, 14, 14]               0\n",
      "          Conv2d-387         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-388         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-389         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-390         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-391          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-392          [-1, 256, 14, 14]             512\n",
      "            ReLU-393          [-1, 256, 14, 14]               0\n",
      "          Conv2d-394          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-395          [-1, 256, 14, 14]             512\n",
      "            ReLU-396          [-1, 256, 14, 14]               0\n",
      "          Conv2d-397         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-398         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-399         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-400         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-401          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-402          [-1, 256, 14, 14]             512\n",
      "            ReLU-403          [-1, 256, 14, 14]               0\n",
      "          Conv2d-404          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-405          [-1, 256, 14, 14]             512\n",
      "            ReLU-406          [-1, 256, 14, 14]               0\n",
      "          Conv2d-407         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-408         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-409         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-410         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-411          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-412          [-1, 256, 14, 14]             512\n",
      "            ReLU-413          [-1, 256, 14, 14]               0\n",
      "          Conv2d-414          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-415          [-1, 256, 14, 14]             512\n",
      "            ReLU-416          [-1, 256, 14, 14]               0\n",
      "          Conv2d-417         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-418         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-419         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-420         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-421          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-422          [-1, 256, 14, 14]             512\n",
      "            ReLU-423          [-1, 256, 14, 14]               0\n",
      "          Conv2d-424          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-425          [-1, 256, 14, 14]             512\n",
      "            ReLU-426          [-1, 256, 14, 14]               0\n",
      "          Conv2d-427         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-428         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-429         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-430         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-431          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-432          [-1, 256, 14, 14]             512\n",
      "            ReLU-433          [-1, 256, 14, 14]               0\n",
      "          Conv2d-434          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-435          [-1, 256, 14, 14]             512\n",
      "            ReLU-436          [-1, 256, 14, 14]               0\n",
      "          Conv2d-437         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-438         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-439         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-440         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-441          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-442          [-1, 256, 14, 14]             512\n",
      "            ReLU-443          [-1, 256, 14, 14]               0\n",
      "          Conv2d-444          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-445          [-1, 256, 14, 14]             512\n",
      "            ReLU-446          [-1, 256, 14, 14]               0\n",
      "          Conv2d-447         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-448         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-449         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-450         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-451          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-452          [-1, 256, 14, 14]             512\n",
      "            ReLU-453          [-1, 256, 14, 14]               0\n",
      "          Conv2d-454          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-455          [-1, 256, 14, 14]             512\n",
      "            ReLU-456          [-1, 256, 14, 14]               0\n",
      "          Conv2d-457         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-458         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-459         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-460         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-461          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-462          [-1, 256, 14, 14]             512\n",
      "            ReLU-463          [-1, 256, 14, 14]               0\n",
      "          Conv2d-464          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-465          [-1, 256, 14, 14]             512\n",
      "            ReLU-466          [-1, 256, 14, 14]               0\n",
      "          Conv2d-467         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-468         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-469         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-470         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-471          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-472          [-1, 256, 14, 14]             512\n",
      "            ReLU-473          [-1, 256, 14, 14]               0\n",
      "          Conv2d-474          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-475          [-1, 256, 14, 14]             512\n",
      "            ReLU-476          [-1, 256, 14, 14]               0\n",
      "          Conv2d-477         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-478         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-479         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-480         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-481          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-482          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-483          [-1, 512, 14, 14]               0\n",
      "          Conv2d-484            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-485            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-486            [-1, 512, 7, 7]               0\n",
      "          Conv2d-487           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-488           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-489           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-490           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-491           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-492           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-493            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-494            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-495            [-1, 512, 7, 7]               0\n",
      "          Conv2d-496            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-497            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-498            [-1, 512, 7, 7]               0\n",
      "          Conv2d-499           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-500           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-501           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-502           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-503            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-504            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-505            [-1, 512, 7, 7]               0\n",
      "          Conv2d-506            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-507            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-508            [-1, 512, 7, 7]               0\n",
      "          Conv2d-509           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-510           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-511           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-512           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n",
      "          Linear-514                    [-1, 4]           8,196\n",
      "================================================================\n",
      "Total params: 58,152,004\n",
      "Trainable params: 58,152,004\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 606.58\n",
      "Params size (MB): 221.83\n",
      "Estimated Total Size (MB): 828.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary as Summary\n",
    "\n",
    "seed()\n",
    "model_resnet = models.resnet152(pretrained = True)\n",
    "num_ftrs = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(num_ftrs, 4)\n",
    "model_resnet.load_state_dict(torch.load('./best_model_cnn.pth'))\n",
    "net_cnn = model_resnet.to(device)\n",
    "net_cnn.eval()\n",
    "Summary(net_cnn.to(device), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c44a036",
   "metadata": {},
   "source": [
    "### 저장된 LSTM 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb8c5a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "skeleton_LSTM(\n",
       "  (lstm1): LSTM(8, 128, batch_first=True)\n",
       "  (lstm2): LSTM(128, 256, batch_first=True)\n",
       "  (lstm3): LSTM(256, 512, batch_first=True)\n",
       "  (dropout1): Dropout(p=0.3, inplace=False)\n",
       "  (lstm4): LSTM(512, 256, batch_first=True)\n",
       "  (lstm5): LSTM(256, 128, batch_first=True)\n",
       "  (lstm6): LSTM(128, 64, batch_first=True)\n",
       "  (dropout2): Dropout(p=0.3, inplace=False)\n",
       "  (lstm7): LSTM(64, 32, batch_first=True)\n",
       "  (fc): Linear(in_features=32, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class skeleton_LSTM(nn.Module) :\n",
    "    def __init__(self):\n",
    "        super(skeleton_LSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=8, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(input_size=128, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(input_size=256, hidden_size=512, num_layers=1, batch_first=True)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.lstm4 = nn.LSTM(input_size=512, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.lstm5 = nn.LSTM(input_size=256, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.lstm6 = nn.LSTM(input_size=128, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.lstm7 = nn.LSTM(input_size=64, hidden_size=32, num_layers=1, batch_first=True)\n",
    "        self.fc = nn.Linear(32,5)\n",
    "    def forward(self, x) :\n",
    "        x, _ = self.lstm1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x, _ = self.lstm5(x)\n",
    "        x, _ = self.lstm6(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, _ = self.lstm7(x)\n",
    "        x = self.fc(x[:,-1,:])\n",
    "        return x\n",
    "    \n",
    "net_lstm = skeleton_LSTM()\n",
    "net_lstm.load_state_dict(torch.load('./model_lstm_logit_and_bbox.pth'))\n",
    "net_lstm = net_lstm.to(device)\n",
    "net_lstm.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00eb5598",
   "metadata": {},
   "source": [
    "### 레이블링 된 Test 데이터 돌려보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27bd944b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "seed()\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "data_transforms = transforms.Compose([ToTensor(), Resize((224,224)), Normalize(mean, std)])\n",
    "class dataset_cnn(Dataset):\n",
    "    def __init__(self, img, label):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = data_transforms(img)\n",
    "        self.img = [img]\n",
    "        self.label = [label]\n",
    "    def __getitem__(self, index):\n",
    "        data = self.img[index]\n",
    "        label = self.label[index]\n",
    "        return data, label\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "class dataset_lstm(Dataset):\n",
    "    def __init__(self, seq_list):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for dic in seq_list :\n",
    "            self.y.append(dic['key'])\n",
    "            self.X.append(dic['value'])\n",
    "    def __getitem__(self, index):\n",
    "        data = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))\n",
    "    def __len__(self):\n",
    "        return len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68b3cd18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST_002.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_012.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_032.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_039.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_047.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_053.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_058.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_060.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_067.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_075.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_079.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_088.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_093.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_097.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_104.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_106.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_107.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_110.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_126.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_130.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_131.mp4 | GT: 0 | Pred: 3 | FP <-- 틀림\n",
      "TEST_136.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_139.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_140.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_141.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_150.mp4 | GT: 0 | Pred: 0 | TP\n",
      "TEST_000.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_008.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_014.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_017.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_019.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_026.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_029.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_031.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_049.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_054.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_066.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_071.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_080.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_083.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_090.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_095.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_102.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_109.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_111.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_114.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_115.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_117.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_118.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_122.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_123.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_128.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_143.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_145.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_151.mp4 | GT: 1 | Pred: 1 | TP\n",
      "TEST_003.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_005.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_009.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_010.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_011.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_020.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_021.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_022.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_024.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_036.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_038.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_040.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_057.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_063.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_065.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_068.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_082.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_085.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_089.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_091.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_092.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_098.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_100.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_105.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_116.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_127.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_133.mp4 | GT: 2 | Pred: 3 | FP <-- 틀림\n",
      "TEST_137.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_138.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_146.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_147.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_148.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_152.mp4 | GT: 2 | Pred: 2 | TP\n",
      "TEST_001.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_007.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_016.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_023.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_025.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_030.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_034.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_037.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_043.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_044.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_050.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_055.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_061.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_070.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_072.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_073.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_074.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_078.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_084.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_087.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_099.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_108.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_113.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_119.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_121.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_124.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_144.mp4 | GT: 3 | Pred: 3 | TP\n",
      "TEST_004.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_006.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_013.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_015.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_018.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_027.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_028.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_033.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_035.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_041.mp4 | GT: 4 | Pred: 2 | FP <-- 틀림\n",
      "TEST_042.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_045.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_046.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_048.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_051.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_052.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_056.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_059.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_062.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_064.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_069.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_076.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_077.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_081.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_086.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_094.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_096.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_101.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_103.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_112.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_120.mp4 | GT: 4 | Pred: 2 | FP <-- 틀림\n",
      "TEST_125.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_129.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_132.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_134.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_135.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_142.mp4 | GT: 4 | Pred: 4 | TP\n",
      "TEST_149.mp4 | GT: 4 | Pred: 4 | TP\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import natsort\n",
    "\n",
    "def list_augmentation(input_list, goal_len):\n",
    "    need_aug = goal_len - len(input_list)\n",
    "    aug_tempo = need_aug / len(input_list)\n",
    "    full_list, cnt = [], 0\n",
    "    for _input in input_list:\n",
    "        cnt += aug_tempo\n",
    "        full_list.append(_input)\n",
    "        while True:\n",
    "            if cnt < 1: break\n",
    "            full_list.append(_input)\n",
    "            cnt -= 1\n",
    "    while True:\n",
    "        if len(full_list) <= goal_len: break\n",
    "        del full_list[-1]\n",
    "    return full_list\n",
    "        \n",
    "video_path = './test_label'\n",
    "id_list, label_list = ['id'], ['label']\n",
    "tp, fp, status = 0, 0, 'None'\n",
    "folder_list = os.listdir(video_path)\n",
    "folder_list = natsort.natsorted(folder_list)\n",
    "for folder in folder_list:\n",
    "    video_list = os.listdir('{}/{}'.format(video_path, folder))\n",
    "    video_list = natsort.natsorted(video_list)\n",
    "    for video_name in video_list:\n",
    "        logit_and_bbox_list = []\n",
    "        cap = cv2.VideoCapture('{}/{}/{}'.format(video_path, folder, video_name))\n",
    "        if cap.isOpened():\n",
    "            while True:\n",
    "                ret, img = cap.read()\n",
    "                if ret == True:\n",
    "                    bbox, crop_img = net_yolo(img)\n",
    "                    if len(crop_img) == 0: continue\n",
    "                    dataset = dataset_cnn(crop_img, int(folder))\n",
    "                    dataset = DataLoader(dataset)\n",
    "                    for data, label in dataset:\n",
    "                        data = data.to(device)\n",
    "                        with torch.no_grad():\n",
    "                            cnn_result = net_cnn(data)\n",
    "                        cnn_logits = []\n",
    "                        for logit in cnn_result[0]:\n",
    "                            cnn_logits.append(logit.item())\n",
    "                        logit_and_bbox = cnn_logits + bbox\n",
    "                        logit_and_bbox_list.append(logit_and_bbox)\n",
    "                else: break\n",
    "        logit_and_bbox_list = list_augmentation(logit_and_bbox_list, 32)\n",
    "        dataset_dict_list = [{'key':int(folder), 'value':logit_and_bbox_list}]\n",
    "        dataset = dataset_lstm(dataset_dict_list)\n",
    "        dataset = DataLoader(dataset)\n",
    "        for data, label in dataset:\n",
    "            data = data.to(device)\n",
    "            with torch.no_grad():\n",
    "                result = net_lstm(data)\n",
    "            _, out = torch.max(result, 1)\n",
    "            pred_class = out.item()\n",
    "            id_list.append(video_name.split('.')[0])\n",
    "            label_list.append(pred_class)\n",
    "            if int(pred_class) == int(folder):\n",
    "                tp += 1\n",
    "                status = 'TP'\n",
    "            else:\n",
    "                fp += 1\n",
    "                status = 'FP <-- 틀림'\n",
    "            print('{} | GT: {} | Pred: {} | {}'.format(video_name, folder, pred_class, status))\n",
    "print('Acc: {}'.format(tp / (tp+fp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0695cb11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409a9b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a314cbcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f25dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18832b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79595f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0111c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
