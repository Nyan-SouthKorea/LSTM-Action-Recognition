{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27e8e67a",
   "metadata": {},
   "source": [
    "### 저장된 Yolo 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "288762f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\nyan/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2022-9-15 Python-3.8.15 torch-1.10.1 CUDA:0 (NVIDIA GeForce GTX 1080 Ti, 11264MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 322 layers, 86173414 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path = './yolov5-master/exp3/weights/best.pt')\n",
    "def net_yolo(img):\n",
    "    h, w, c = img.shape\n",
    "    pred_list = model(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    pred_list = pred_list.pandas().xyxy[0]\n",
    "    result_list = []\n",
    "    for cnt in range(len(pred_list)):\n",
    "        x1 = int(pred_list.loc[cnt]['xmin'])\n",
    "        y1 = int(pred_list.loc[cnt]['ymin'])\n",
    "        x2 = int(pred_list.loc[cnt]['xmax'])\n",
    "        y2 = int(pred_list.loc[cnt]['ymax'])\n",
    "        x1_nor = max(1, int(pred_list.loc[cnt]['xmin'])) / w\n",
    "        y1_nor = max(1, int(pred_list.loc[cnt]['ymin'])) / h\n",
    "        x2_nor = max(1, int(pred_list.loc[cnt]['xmax'])) / w\n",
    "        y2_nor = max(1, int(pred_list.loc[cnt]['ymax'])) / h\n",
    "        conf = round(float(pred_list.loc[cnt]['confidence']), 3)\n",
    "        pred = {'bbox' : [x1, y1, x2, y2], 'conf' : conf, 'bbox_nor' : [x1_nor, y1_nor, x2_nor, y2_nor]}\n",
    "        result_list.append(pred)\n",
    "    if len(result_list) > 0:\n",
    "        result_list.sort(key = lambda x:x['conf'], reverse = True)\n",
    "        result = result_list[0]                    \n",
    "        crop_img = img[result['bbox'][1]:result['bbox'][3], result['bbox'][0]:result['bbox'][2]]\n",
    "        return result['bbox_nor'], crop_img\n",
    "    else:\n",
    "        return [], []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b091862a",
   "metadata": {},
   "source": [
    "### 저장된 Resnet 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4ab25ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 가상환경 GPU 사용 가능상태\n"
     ]
    }
   ],
   "source": [
    "def seed(seed = 1234):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "if torch.cuda.is_available() == True:\n",
    "    device = 'cuda:0'\n",
    "    print('현재 가상환경 GPU 사용 가능상태')\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('GPU 사용 불가능 상태')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ae8e225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-80          [-1, 128, 28, 28]             256\n",
      "             ReLU-81          [-1, 128, 28, 28]               0\n",
      "           Conv2d-82          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-83          [-1, 128, 28, 28]             256\n",
      "             ReLU-84          [-1, 128, 28, 28]               0\n",
      "           Conv2d-85          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-86          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-87          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-88          [-1, 512, 28, 28]               0\n",
      "           Conv2d-89          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-90          [-1, 128, 28, 28]             256\n",
      "             ReLU-91          [-1, 128, 28, 28]               0\n",
      "           Conv2d-92          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-93          [-1, 128, 28, 28]             256\n",
      "             ReLU-94          [-1, 128, 28, 28]               0\n",
      "           Conv2d-95          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-96          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-97          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-98          [-1, 512, 28, 28]               0\n",
      "           Conv2d-99          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-100          [-1, 128, 28, 28]             256\n",
      "            ReLU-101          [-1, 128, 28, 28]               0\n",
      "          Conv2d-102          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
      "            ReLU-104          [-1, 128, 28, 28]               0\n",
      "          Conv2d-105          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-106          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-107          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-108          [-1, 512, 28, 28]               0\n",
      "          Conv2d-109          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-110          [-1, 128, 28, 28]             256\n",
      "            ReLU-111          [-1, 128, 28, 28]               0\n",
      "          Conv2d-112          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-113          [-1, 128, 28, 28]             256\n",
      "            ReLU-114          [-1, 128, 28, 28]               0\n",
      "          Conv2d-115          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-116          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-117          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-118          [-1, 512, 28, 28]               0\n",
      "          Conv2d-119          [-1, 256, 28, 28]         131,072\n",
      "     BatchNorm2d-120          [-1, 256, 28, 28]             512\n",
      "            ReLU-121          [-1, 256, 28, 28]               0\n",
      "          Conv2d-122          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-123          [-1, 256, 14, 14]             512\n",
      "            ReLU-124          [-1, 256, 14, 14]               0\n",
      "          Conv2d-125         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-126         [-1, 1024, 14, 14]           2,048\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-142          [-1, 256, 14, 14]             512\n",
      "            ReLU-143          [-1, 256, 14, 14]               0\n",
      "          Conv2d-144          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-145          [-1, 256, 14, 14]             512\n",
      "            ReLU-146          [-1, 256, 14, 14]               0\n",
      "          Conv2d-147         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-149         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-150         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-151          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-152          [-1, 256, 14, 14]             512\n",
      "            ReLU-153          [-1, 256, 14, 14]               0\n",
      "          Conv2d-154          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-155          [-1, 256, 14, 14]             512\n",
      "            ReLU-156          [-1, 256, 14, 14]               0\n",
      "          Conv2d-157         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-159         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-160         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-161          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-162          [-1, 256, 14, 14]             512\n",
      "            ReLU-163          [-1, 256, 14, 14]               0\n",
      "          Conv2d-164          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-165          [-1, 256, 14, 14]             512\n",
      "            ReLU-166          [-1, 256, 14, 14]               0\n",
      "          Conv2d-167         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-169         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-170         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-171          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-172          [-1, 256, 14, 14]             512\n",
      "            ReLU-173          [-1, 256, 14, 14]               0\n",
      "          Conv2d-174          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-175          [-1, 256, 14, 14]             512\n",
      "            ReLU-176          [-1, 256, 14, 14]               0\n",
      "          Conv2d-177         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-179         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-180         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-181          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-182          [-1, 256, 14, 14]             512\n",
      "            ReLU-183          [-1, 256, 14, 14]               0\n",
      "          Conv2d-184          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-185          [-1, 256, 14, 14]             512\n",
      "            ReLU-186          [-1, 256, 14, 14]               0\n",
      "          Conv2d-187         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-189         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-190         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-191          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-192          [-1, 256, 14, 14]             512\n",
      "            ReLU-193          [-1, 256, 14, 14]               0\n",
      "          Conv2d-194          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-195          [-1, 256, 14, 14]             512\n",
      "            ReLU-196          [-1, 256, 14, 14]               0\n",
      "          Conv2d-197         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-199         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-200         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-201          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-202          [-1, 256, 14, 14]             512\n",
      "            ReLU-203          [-1, 256, 14, 14]               0\n",
      "          Conv2d-204          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-205          [-1, 256, 14, 14]             512\n",
      "            ReLU-206          [-1, 256, 14, 14]               0\n",
      "          Conv2d-207         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-209         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-210         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-211          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-212          [-1, 256, 14, 14]             512\n",
      "            ReLU-213          [-1, 256, 14, 14]               0\n",
      "          Conv2d-214          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-215          [-1, 256, 14, 14]             512\n",
      "            ReLU-216          [-1, 256, 14, 14]               0\n",
      "          Conv2d-217         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-219         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-220         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-221          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-222          [-1, 256, 14, 14]             512\n",
      "            ReLU-223          [-1, 256, 14, 14]               0\n",
      "          Conv2d-224          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-225          [-1, 256, 14, 14]             512\n",
      "            ReLU-226          [-1, 256, 14, 14]               0\n",
      "          Conv2d-227         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-229         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-230         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-231          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 14, 14]             512\n",
      "            ReLU-233          [-1, 256, 14, 14]               0\n",
      "          Conv2d-234          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 14, 14]             512\n",
      "            ReLU-236          [-1, 256, 14, 14]               0\n",
      "          Conv2d-237         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-240         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-241          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-242          [-1, 256, 14, 14]             512\n",
      "            ReLU-243          [-1, 256, 14, 14]               0\n",
      "          Conv2d-244          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-245          [-1, 256, 14, 14]             512\n",
      "            ReLU-246          [-1, 256, 14, 14]               0\n",
      "          Conv2d-247         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-249         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-250         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-251          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-252          [-1, 256, 14, 14]             512\n",
      "            ReLU-253          [-1, 256, 14, 14]               0\n",
      "          Conv2d-254          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-255          [-1, 256, 14, 14]             512\n",
      "            ReLU-256          [-1, 256, 14, 14]               0\n",
      "          Conv2d-257         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-259         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-260         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-261          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-262          [-1, 256, 14, 14]             512\n",
      "            ReLU-263          [-1, 256, 14, 14]               0\n",
      "          Conv2d-264          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-265          [-1, 256, 14, 14]             512\n",
      "            ReLU-266          [-1, 256, 14, 14]               0\n",
      "          Conv2d-267         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-269         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-270         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-271          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-272          [-1, 256, 14, 14]             512\n",
      "            ReLU-273          [-1, 256, 14, 14]               0\n",
      "          Conv2d-274          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-275          [-1, 256, 14, 14]             512\n",
      "            ReLU-276          [-1, 256, 14, 14]               0\n",
      "          Conv2d-277         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-279         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-280         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-281          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-282          [-1, 256, 14, 14]             512\n",
      "            ReLU-283          [-1, 256, 14, 14]               0\n",
      "          Conv2d-284          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-285          [-1, 256, 14, 14]             512\n",
      "            ReLU-286          [-1, 256, 14, 14]               0\n",
      "          Conv2d-287         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-289         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-290         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-291          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-292          [-1, 256, 14, 14]             512\n",
      "            ReLU-293          [-1, 256, 14, 14]               0\n",
      "          Conv2d-294          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-295          [-1, 256, 14, 14]             512\n",
      "            ReLU-296          [-1, 256, 14, 14]               0\n",
      "          Conv2d-297         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-299         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-300         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-301          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-302          [-1, 256, 14, 14]             512\n",
      "            ReLU-303          [-1, 256, 14, 14]               0\n",
      "          Conv2d-304          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-305          [-1, 256, 14, 14]             512\n",
      "            ReLU-306          [-1, 256, 14, 14]               0\n",
      "          Conv2d-307         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-309         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-310         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-311          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-312          [-1, 256, 14, 14]             512\n",
      "            ReLU-313          [-1, 256, 14, 14]               0\n",
      "          Conv2d-314          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-315          [-1, 256, 14, 14]             512\n",
      "            ReLU-316          [-1, 256, 14, 14]               0\n",
      "          Conv2d-317         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-318         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-319         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-320         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-321          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-322          [-1, 256, 14, 14]             512\n",
      "            ReLU-323          [-1, 256, 14, 14]               0\n",
      "          Conv2d-324          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-325          [-1, 256, 14, 14]             512\n",
      "            ReLU-326          [-1, 256, 14, 14]               0\n",
      "          Conv2d-327         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-328         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-329         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-330         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-331          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-332          [-1, 256, 14, 14]             512\n",
      "            ReLU-333          [-1, 256, 14, 14]               0\n",
      "          Conv2d-334          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-335          [-1, 256, 14, 14]             512\n",
      "            ReLU-336          [-1, 256, 14, 14]               0\n",
      "          Conv2d-337         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-338         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-339         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-340         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-341          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-342          [-1, 256, 14, 14]             512\n",
      "            ReLU-343          [-1, 256, 14, 14]               0\n",
      "          Conv2d-344          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-345          [-1, 256, 14, 14]             512\n",
      "            ReLU-346          [-1, 256, 14, 14]               0\n",
      "          Conv2d-347         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-348         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-349         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-350         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-351          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-352          [-1, 256, 14, 14]             512\n",
      "            ReLU-353          [-1, 256, 14, 14]               0\n",
      "          Conv2d-354          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-355          [-1, 256, 14, 14]             512\n",
      "            ReLU-356          [-1, 256, 14, 14]               0\n",
      "          Conv2d-357         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-358         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-359         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-360         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-361          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-362          [-1, 256, 14, 14]             512\n",
      "            ReLU-363          [-1, 256, 14, 14]               0\n",
      "          Conv2d-364          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-365          [-1, 256, 14, 14]             512\n",
      "            ReLU-366          [-1, 256, 14, 14]               0\n",
      "          Conv2d-367         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-368         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-369         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-370         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-371          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-372          [-1, 256, 14, 14]             512\n",
      "            ReLU-373          [-1, 256, 14, 14]               0\n",
      "          Conv2d-374          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-375          [-1, 256, 14, 14]             512\n",
      "            ReLU-376          [-1, 256, 14, 14]               0\n",
      "          Conv2d-377         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-378         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-379         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-380         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-381          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-382          [-1, 256, 14, 14]             512\n",
      "            ReLU-383          [-1, 256, 14, 14]               0\n",
      "          Conv2d-384          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-385          [-1, 256, 14, 14]             512\n",
      "            ReLU-386          [-1, 256, 14, 14]               0\n",
      "          Conv2d-387         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-388         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-389         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-390         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-391          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-392          [-1, 256, 14, 14]             512\n",
      "            ReLU-393          [-1, 256, 14, 14]               0\n",
      "          Conv2d-394          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-395          [-1, 256, 14, 14]             512\n",
      "            ReLU-396          [-1, 256, 14, 14]               0\n",
      "          Conv2d-397         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-398         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-399         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-400         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-401          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-402          [-1, 256, 14, 14]             512\n",
      "            ReLU-403          [-1, 256, 14, 14]               0\n",
      "          Conv2d-404          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-405          [-1, 256, 14, 14]             512\n",
      "            ReLU-406          [-1, 256, 14, 14]               0\n",
      "          Conv2d-407         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-408         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-409         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-410         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-411          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-412          [-1, 256, 14, 14]             512\n",
      "            ReLU-413          [-1, 256, 14, 14]               0\n",
      "          Conv2d-414          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-415          [-1, 256, 14, 14]             512\n",
      "            ReLU-416          [-1, 256, 14, 14]               0\n",
      "          Conv2d-417         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-418         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-419         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-420         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-421          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-422          [-1, 256, 14, 14]             512\n",
      "            ReLU-423          [-1, 256, 14, 14]               0\n",
      "          Conv2d-424          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-425          [-1, 256, 14, 14]             512\n",
      "            ReLU-426          [-1, 256, 14, 14]               0\n",
      "          Conv2d-427         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-428         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-429         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-430         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-431          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-432          [-1, 256, 14, 14]             512\n",
      "            ReLU-433          [-1, 256, 14, 14]               0\n",
      "          Conv2d-434          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-435          [-1, 256, 14, 14]             512\n",
      "            ReLU-436          [-1, 256, 14, 14]               0\n",
      "          Conv2d-437         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-438         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-439         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-440         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-441          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-442          [-1, 256, 14, 14]             512\n",
      "            ReLU-443          [-1, 256, 14, 14]               0\n",
      "          Conv2d-444          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-445          [-1, 256, 14, 14]             512\n",
      "            ReLU-446          [-1, 256, 14, 14]               0\n",
      "          Conv2d-447         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-448         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-449         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-450         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-451          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-452          [-1, 256, 14, 14]             512\n",
      "            ReLU-453          [-1, 256, 14, 14]               0\n",
      "          Conv2d-454          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-455          [-1, 256, 14, 14]             512\n",
      "            ReLU-456          [-1, 256, 14, 14]               0\n",
      "          Conv2d-457         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-458         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-459         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-460         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-461          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-462          [-1, 256, 14, 14]             512\n",
      "            ReLU-463          [-1, 256, 14, 14]               0\n",
      "          Conv2d-464          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-465          [-1, 256, 14, 14]             512\n",
      "            ReLU-466          [-1, 256, 14, 14]               0\n",
      "          Conv2d-467         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-468         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-469         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-470         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-471          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-472          [-1, 256, 14, 14]             512\n",
      "            ReLU-473          [-1, 256, 14, 14]               0\n",
      "          Conv2d-474          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-475          [-1, 256, 14, 14]             512\n",
      "            ReLU-476          [-1, 256, 14, 14]               0\n",
      "          Conv2d-477         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-478         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-479         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-480         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-481          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-482          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-483          [-1, 512, 14, 14]               0\n",
      "          Conv2d-484            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-485            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-486            [-1, 512, 7, 7]               0\n",
      "          Conv2d-487           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-488           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-489           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-490           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-491           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-492           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-493            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-494            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-495            [-1, 512, 7, 7]               0\n",
      "          Conv2d-496            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-497            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-498            [-1, 512, 7, 7]               0\n",
      "          Conv2d-499           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-500           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-501           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-502           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-503            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-504            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-505            [-1, 512, 7, 7]               0\n",
      "          Conv2d-506            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-507            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-508            [-1, 512, 7, 7]               0\n",
      "          Conv2d-509           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-510           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-511           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-512           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n",
      "          Linear-514                    [-1, 4]           8,196\n",
      "================================================================\n",
      "Total params: 58,152,004\n",
      "Trainable params: 58,152,004\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 606.58\n",
      "Params size (MB): 221.83\n",
      "Estimated Total Size (MB): 828.99\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary as Summary\n",
    "\n",
    "seed()\n",
    "model_resnet = models.resnet152(pretrained = True)\n",
    "num_ftrs = model_resnet.fc.in_features\n",
    "model_resnet.fc = nn.Linear(num_ftrs, 4)\n",
    "model_resnet.load_state_dict(torch.load('./best_model_cnn.pth'))\n",
    "net_cnn = model_resnet.to(device)\n",
    "net_cnn.eval()\n",
    "Summary(net_cnn.to(device), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc20ee",
   "metadata": {},
   "source": [
    "### MediaPipe 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6e3d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "hands =  mp_hands.Hands(static_image_mode=True, max_num_hands=1, min_detection_confidence=0.3)\n",
    "def net_mediapipe(img):\n",
    "    results = hands.process(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    if not results.multi_hand_landmarks: return []\n",
    "    xy_list = []\n",
    "    for one_hand in results.multi_hand_landmarks:\n",
    "        for xy in one_hand.landmark:\n",
    "            xy_list.append(xy.x)\n",
    "            xy_list.append(xy.y)        \n",
    "    return xy_list # 42개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932bde7f",
   "metadata": {},
   "source": [
    "### LSTM을 위한 데이터 만들기(Yolo + Resnet + MediaPipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9136a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Resize, Normalize\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import natsort\n",
    "from tqdm import tqdm\n",
    "\n",
    "seed()\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "data_transforms = transforms.Compose([ToTensor(), Resize((224,224)), Normalize(mean, std)])\n",
    "class dataset_cnn(Dataset):\n",
    "    def __init__(self, img, label):\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = data_transforms(img)\n",
    "        self.img = [img]\n",
    "        self.label = [label]\n",
    "    def __getitem__(self, index):\n",
    "        data = self.img[index]\n",
    "        label = self.label[index]\n",
    "        return data, label\n",
    "    def __len__(self):\n",
    "        return len(self.label)\n",
    "    \n",
    "def list_augmentation(input_list, goal_len):\n",
    "    need_aug = goal_len - len(input_list)\n",
    "    aug_tempo = need_aug / len(input_list)\n",
    "    full_list, cnt = [], 0\n",
    "    for _input in input_list:\n",
    "        cnt += aug_tempo\n",
    "        full_list.append(_input)\n",
    "        while True:\n",
    "            if cnt < 1: break\n",
    "            full_list.append(_input)\n",
    "            cnt -= 1\n",
    "    while True:\n",
    "        if len(full_list) == goal_len: break\n",
    "        if len(full_list) > goal_len: del full_list[-1]\n",
    "        else: full_list.append(full_list[-1])    \n",
    "    return full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad39a512",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 113/113 [06:45<00:00,  3.58s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 129/129 [07:35<00:00,  3.53s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 121/121 [07:01<00:00,  3.48s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 133/133 [07:42<00:00,  3.48s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 114/114 [06:48<00:00,  3.58s/it]\n"
     ]
    }
   ],
   "source": [
    "last_mp_result = []\n",
    "for i in range(42):\n",
    "    last_mp_result.append(0.0)\n",
    "train_video_path = './train_video'\n",
    "folder_list = os.listdir(train_video_path)\n",
    "folder_list = natsort.natsorted(folder_list)\n",
    "dataset_dict_list = []\n",
    "for folder in folder_list:\n",
    "    video_list = os.listdir('{}/{}'.format(train_video_path, folder))\n",
    "    video_list = natsort.natsorted(video_list)\n",
    "    for video_name in tqdm(video_list):\n",
    "        logit_bbox_mp_list = []\n",
    "        cap = cv2.VideoCapture('{}/{}/{}'.format(train_video_path, folder, video_name))\n",
    "        if cap.isOpened():\n",
    "            while True:\n",
    "                ret, img = cap.read()\n",
    "                if ret == True:\n",
    "                    bbox, crop_img = net_yolo(img)\n",
    "                    if len(crop_img) == 0: continue\n",
    "                    dataset = dataset_cnn(crop_img, int(folder))\n",
    "                    dataset = DataLoader(dataset)\n",
    "                    for data, label in dataset:\n",
    "                        data = data.to(device)\n",
    "                        with torch.no_grad():\n",
    "                            cnn_result = net_cnn(data)\n",
    "                        cnn_logits = []\n",
    "                        for logit in cnn_result[0]:\n",
    "                            cnn_logits.append(logit.item())\n",
    "                        mp_result = net_mediapipe(img)\n",
    "                        if len(mp_result) == 0: mp_result = last_mp_result + []\n",
    "                        last_mp_result = mp_result + []\n",
    "                        logit_bbox_mp = cnn_logits + bbox + last_mp_result\n",
    "                        logit_bbox_mp_list.append(logit_bbox_mp)\n",
    "                else: break\n",
    "        logit_bbox_mp_list = list_augmentation(logit_bbox_mp_list, 30)\n",
    "        dataset_dict_list.append({'key':int(folder), 'value':logit_bbox_mp_list})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6292cfb4",
   "metadata": {},
   "source": [
    "### LSTM 설계 후 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f50f94ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 549, val: 61\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim import Adam\n",
    "import gc\n",
    "from torch.cuda import memory_allocated, empty_cache\n",
    "from IPython.display import clear_output\n",
    "\n",
    "class dataset_lstm(Dataset):\n",
    "    def __init__(self, seq_list):\n",
    "        self.X = []\n",
    "        self.y = []\n",
    "        for dic in seq_list :\n",
    "            self.y.append(dic['key'])\n",
    "            self.X.append(dic['value'])\n",
    "    def __getitem__(self, index):\n",
    "        data = self.X[index]\n",
    "        label = self.y[index]\n",
    "        return torch.Tensor(np.array(data)), torch.tensor(np.array(int(label)))\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "split_ratio = [0.9, 0.1]\n",
    "train_len = int(len(dataset_dict_list) * split_ratio[0])\n",
    "val_len = len(dataset_dict_list) - train_len\n",
    "print('train: {}, val: {}'.format(train_len, val_len))\n",
    "\n",
    "train_dataset = dataset_lstm(dataset_dict_list)\n",
    "train_data, valid_data = random_split(train_dataset, [train_len, val_len])\n",
    "train_loader = DataLoader(train_data, batch_size=32)\n",
    "val_loader = DataLoader(valid_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5808c2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class skeleton_LSTM(nn.Module) :\n",
    "    def __init__(self):\n",
    "        super(skeleton_LSTM, self).__init__()\n",
    "        self.lstm1 = nn.LSTM(input_size=50, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.batch1 = nn.BatchNorm1d(30)\n",
    "        self.lstm2 = nn.LSTM(input_size=128, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.batch2 = nn.BatchNorm1d(30)\n",
    "        self.lstm3 = nn.LSTM(input_size=256, hidden_size=512, num_layers=1, batch_first=True)\n",
    "        self.batch3 = nn.BatchNorm1d(30)\n",
    "        self.lstm4 = nn.LSTM(input_size=512, hidden_size=1024, num_layers=1, batch_first=True)\n",
    "        self.batch4 = nn.BatchNorm1d(30)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        self.lstm5 = nn.LSTM(input_size=1024, hidden_size=512, num_layers=1, batch_first=True)\n",
    "        self.batch5 = nn.BatchNorm1d(30)\n",
    "        self.lstm6 = nn.LSTM(input_size=512, hidden_size=256, num_layers=1, batch_first=True)\n",
    "        self.batch6 = nn.BatchNorm1d(30)\n",
    "        self.lstm7 = nn.LSTM(input_size=256, hidden_size=128, num_layers=1, batch_first=True)\n",
    "        self.batch7 = nn.BatchNorm1d(30)\n",
    "        self.lstm8 = nn.LSTM(input_size=128, hidden_size=64, num_layers=1, batch_first=True)\n",
    "        self.batch8 = nn.BatchNorm1d(30)\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        self.lstm9 = nn.LSTM(input_size=64, hidden_size=32, num_layers=1, batch_first=True)\n",
    "        self.batch9 = nn.BatchNorm1d(30)\n",
    "        self.fc = nn.Linear(32,5)\n",
    "    def forward(self, x) :\n",
    "        x, _ = self.lstm1(x)\n",
    "        x = self.batch1(x)\n",
    "        x, _ = self.lstm2(x)\n",
    "        x = self.batch2(x)\n",
    "        x, _ = self.lstm3(x)\n",
    "        x = self.batch3(x)\n",
    "        x, _ = self.lstm4(x)\n",
    "        x = self.batch4(x)\n",
    "        x = self.dropout1(x)\n",
    "        x, _ = self.lstm5(x)\n",
    "        x = self.batch5(x)\n",
    "        x, _ = self.lstm6(x)\n",
    "        x = self.batch6(x)\n",
    "        x, _ = self.lstm7(x)\n",
    "        x = self.batch7(x)\n",
    "        x, _ = self.lstm8(x)\n",
    "        x = self.batch8(x)\n",
    "        x = self.dropout2(x)\n",
    "        x, _ = self.lstm9(x)\n",
    "        x = self.batch9(x)\n",
    "        x = self.fc(x[:,-1,:])\n",
    "        return x\n",
    "    \n",
    "def init_model():\n",
    "    plt.rc('font', size = 10)\n",
    "    global net_lstm, loss_fn, optim\n",
    "    net_lstm = skeleton_LSTM().to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optim = Adam(net_lstm.parameters(), lr=0.0001)\n",
    "    \n",
    "def init_epoch():\n",
    "    global epoch_cnt\n",
    "    epoch_cnt = 0\n",
    "    \n",
    "def init_log():\n",
    "    plt.rc('font', size = 10)\n",
    "    global log_stack, iter_log, tloss_log, tacc_log, vloss_log, vacc_log, time_log\n",
    "    iter_log, tloss_log, tacc_log, vloss_log, vacc_log = [], [], [], [], []\n",
    "    time_log, log_stack = [], []\n",
    "    \n",
    "def clear_memory():\n",
    "    if device != 'cpu':\n",
    "        empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "def epoch(data_loader, mode = 'train'):\n",
    "    global epoch_cnt\n",
    "    iter_loss, iter_acc, last_grad_performed = [], [], False\n",
    "    for _data, _label in data_loader:\n",
    "        data, label = _data.to(device), _label.type(torch.LongTensor).to(device)\n",
    "        if mode == 'train':\n",
    "            net_lstm.train()\n",
    "        else:\n",
    "            net_lstm.eval()\n",
    "        result = net_lstm(data)\n",
    "        _, out = torch.max(result, 1)\n",
    "        loss = loss_fn(result, label)\n",
    "        iter_loss.append(loss.item())\n",
    "        if mode == 'train':\n",
    "            optim.zero_grad()\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            last_grad_performed = True\n",
    "        acc_partial = (out == label).float().sum()\n",
    "        acc_partial = acc_partial / len(label) \n",
    "        iter_acc.append(acc_partial.item())\n",
    "    if last_grad_performed:\n",
    "        epoch_cnt += 1\n",
    "    clear_memory()\n",
    "    return np.average(iter_loss), np.average(iter_acc)\n",
    "\n",
    "def epoch_not_finished():\n",
    "    return epoch_cnt < maximum_epoch\n",
    "\n",
    "def record_train_log(_tloss, _tacc, _time):\n",
    "    time_log.append(_time)\n",
    "    tloss_log.append(_tloss)\n",
    "    tacc_log.append(_tacc)\n",
    "    iter_log.append(epoch_cnt)\n",
    "    \n",
    "def record_valid_log(_vloss, _vacc):\n",
    "    vloss_log.append(_vloss)\n",
    "    vacc_log.append(_vacc)\n",
    "    \n",
    "def last(log_list):\n",
    "    if len(log_list) > 0:\n",
    "        return log_list[len(log_list) - 1]\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def print_log(memo):\n",
    "    train_loss = round(float(last(tloss_log)), 6)\n",
    "    train_acc = round(float(last(tacc_log)), 3)\n",
    "    val_loss = round(float(last(vloss_log)), 6)\n",
    "    val_acc = round(float(last(vacc_log)), 3)\n",
    "    time_spent = round(float(last(time_log)), 3)\n",
    "    log_str = 'Epoch: {:3} | T_Loss {:5} | T_acc {:5} | V_Loss {:5} | V_acc. {:5} | \\\n",
    "🕒 {:5} {}'.format(last(iter_log), train_loss, train_acc, val_loss, val_acc, time_spent, memo)\n",
    "    log_stack.append(log_str)\n",
    "    hist_fig, loss_axis = plt.subplots(figsize=(10, 3), dpi=99) # 그래프 사이즈 설정\n",
    "    hist_fig.patch.set_facecolor('white') # 그래프 배경색 설정\n",
    "    loss_t_line = plt.plot(iter_log, tloss_log, label='Train Loss', color='red', marker='o')\n",
    "    loss_v_line = plt.plot(iter_log, vloss_log, label='Valid Loss', color='blue', marker='s')\n",
    "    loss_axis.set_xlabel('epoch')\n",
    "    loss_axis.set_ylabel('loss')\n",
    "    acc_axis = loss_axis.twinx()\n",
    "    acc_t_line = acc_axis.plot(iter_log, tacc_log, label='Train Acc.', color='red', marker='+')\n",
    "    acc_v_line = acc_axis.plot(iter_log, vacc_log, label='Valid Acc.', color='blue', marker='x')\n",
    "    acc_axis.set_ylabel('accuracy')\n",
    "    hist_lines = loss_t_line + loss_v_line + acc_t_line + acc_v_line # 위에서 선언한 plt정보들 통합\n",
    "    loss_axis.legend(hist_lines, [l.get_label() for l in hist_lines]) # 순서대로 그려주기\n",
    "    loss_axis.grid() # 격자 설정\n",
    "    plt.title('Learning history until epoch {}'.format(last(iter_log)))\n",
    "    plt.draw()\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n",
    "    for idx in reversed(range(len(log_stack))): # 반대로 sort 시켜서 출력\n",
    "        print(log_stack[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aafb0fd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 300 | T_Loss 0.000714 | T_acc   1.0 | V_Loss 0.295248 | V_acc. 0.967 | 🕒 1.484 \n",
      "Epoch: 299 | T_Loss 0.000728 | T_acc   1.0 | V_Loss 0.294946 | V_acc. 0.967 | 🕒 1.469 \n",
      "Epoch: 298 | T_Loss 0.000727 | T_acc   1.0 | V_Loss 0.293537 | V_acc. 0.967 | 🕒   1.5 \n",
      "Epoch: 297 | T_Loss 0.000732 | T_acc   1.0 | V_Loss 0.293387 | V_acc. 0.967 | 🕒 1.516 \n",
      "Epoch: 296 | T_Loss 0.000743 | T_acc   1.0 | V_Loss 0.293461 | V_acc. 0.967 | 🕒 1.484 \n",
      "Epoch: 295 | T_Loss 0.000752 | T_acc   1.0 | V_Loss 0.293179 | V_acc. 0.967 | 🕒 1.469 \n",
      "Epoch: 294 | T_Loss 0.000772 | T_acc   1.0 | V_Loss 0.292393 | V_acc. 0.967 | 🕒 1.484 \n",
      "Epoch: 293 | T_Loss 0.000771 | T_acc   1.0 | V_Loss 0.291826 | V_acc. 0.967 | 🕒 1.547 \n",
      "Epoch: 292 | T_Loss 0.000773 | T_acc   1.0 | V_Loss 0.291787 | V_acc. 0.967 | 🕒 1.547 \n",
      "Epoch: 291 | T_Loss 0.000787 | T_acc   1.0 | V_Loss 0.291536 | V_acc. 0.967 | 🕒 1.469 \n",
      "Epoch: 290 | T_Loss 0.000793 | T_acc   1.0 | V_Loss 0.290762 | V_acc. 0.967 | 🕒 1.453 \n",
      "Epoch: 289 | T_Loss 0.000805 | T_acc   1.0 | V_Loss 0.291195 | V_acc. 0.967 | 🕒 1.531 \n",
      "Epoch: 288 | T_Loss 0.000816 | T_acc   1.0 | V_Loss 0.291163 | V_acc. 0.967 | 🕒   1.5 \n",
      "Epoch: 287 | T_Loss 0.000813 | T_acc   1.0 | V_Loss 0.289006 | V_acc. 0.967 | 🕒 1.469 \n",
      "Epoch: 286 | T_Loss 0.000834 | T_acc   1.0 | V_Loss 0.289845 | V_acc. 0.967 | 🕒 1.453 \n",
      "Epoch: 285 | T_Loss 0.000834 | T_acc   1.0 | V_Loss 0.28741 | V_acc. 0.967 | 🕒 1.484 \n",
      "Epoch: 284 | T_Loss 0.000853 | T_acc   1.0 | V_Loss 0.288978 | V_acc. 0.967 | 🕒 1.469 \n",
      "Epoch: 283 | T_Loss 0.000859 | T_acc   1.0 | V_Loss 0.288497 | V_acc. 0.967 | 🕒 1.453 \n",
      "Epoch: 282 | T_Loss 0.000863 | T_acc   1.0 | V_Loss 0.287645 | V_acc. 0.967 | 🕒 1.453 \n",
      "Epoch: 281 | T_Loss 0.00088 | T_acc   1.0 | V_Loss 0.287227 | V_acc. 0.967 | 🕒   1.5 \n",
      "Epoch: 280 | T_Loss 0.000897 | T_acc   1.0 | V_Loss 0.28768 | V_acc. 0.967 | 🕒 1.519 \n",
      "Epoch: 279 | T_Loss 0.000892 | T_acc   1.0 | V_Loss 0.288141 | V_acc. 0.967 | 🕒  1.63 \n",
      "Epoch: 278 | T_Loss 0.000907 | T_acc   1.0 | V_Loss 0.287003 | V_acc. 0.967 | 🕒 1.469 \n",
      "Epoch: 277 | T_Loss 0.000919 | T_acc   1.0 | V_Loss 0.287289 | V_acc. 0.967 | 🕒 1.484 \n",
      "Epoch: 276 | T_Loss 0.00093 | T_acc   1.0 | V_Loss 0.286032 | V_acc. 0.967 | 🕒 1.437 \n",
      "Epoch: 275 | T_Loss 0.000934 | T_acc   1.0 | V_Loss 0.284737 | V_acc. 0.967 | 🕒 1.484 \n",
      "Epoch: 274 | T_Loss 0.000949 | T_acc   1.0 | V_Loss 0.285381 | V_acc. 0.967 | 🕒 1.469 \n",
      "Epoch: 273 | T_Loss 0.00096 | T_acc   1.0 | V_Loss 0.286081 | V_acc. 0.967 | 🕒 1.437 \n",
      "Epoch: 272 | T_Loss 0.000973 | T_acc   1.0 | V_Loss 0.284973 | V_acc. 0.967 | 🕒 1.453 \n",
      "Epoch: 271 | T_Loss 0.000986 | T_acc   1.0 | V_Loss 0.285345 | V_acc. 0.967 | 🕒 1.484 \n",
      "Epoch: 270 | T_Loss 0.000993 | T_acc   1.0 | V_Loss 0.283399 | V_acc. 0.967 | 🕒 1.484 \n",
      "Epoch: 269 | T_Loss 0.001021 | T_acc   1.0 | V_Loss 0.28387 | V_acc. 0.967 | 🕒 1.453 \n",
      "Epoch: 268 | T_Loss 0.001024 | T_acc   1.0 | V_Loss 0.282951 | V_acc. 0.967 | 🕒 1.453 \n",
      "Epoch: 267 | T_Loss 0.001028 | T_acc   1.0 | V_Loss 0.282904 | V_acc. 0.967 | 🕒 1.453 \n",
      "Epoch: 266 | T_Loss 0.001039 | T_acc   1.0 | V_Loss 0.28227 | V_acc. 0.967 | 🕒 1.437 \n",
      "Epoch: 265 | T_Loss 0.001053 | T_acc   1.0 | V_Loss 0.282155 | V_acc. 0.967 | 🕒 1.422 \n",
      "Epoch: 264 | T_Loss 0.001065 | T_acc   1.0 | V_Loss 0.282257 | V_acc. 0.967 | 🕒 1.437 \n",
      "Epoch: 263 | T_Loss 0.001066 | T_acc   1.0 | V_Loss 0.280989 | V_acc. 0.967 | 🕒 1.422 \n",
      "Epoch: 262 | T_Loss 0.001095 | T_acc   1.0 | V_Loss 0.281037 | V_acc. 0.967 | 🕒 1.422 \n",
      "Epoch: 261 | T_Loss 0.001102 | T_acc   1.0 | V_Loss 0.280131 | V_acc. 0.967 | 🕒 1.391 \n",
      "Epoch: 260 | T_Loss 0.001112 | T_acc   1.0 | V_Loss 0.280733 | V_acc. 0.967 | 🕒 1.425 \n",
      "Epoch: 259 | T_Loss 0.00112 | T_acc   1.0 | V_Loss 0.280091 | V_acc. 0.967 | 🕒 1.437 \n",
      "Epoch: 258 | T_Loss 0.001147 | T_acc   1.0 | V_Loss 0.279305 | V_acc. 0.967 | 🕒 1.391 \n",
      "Epoch: 257 | T_Loss 0.001146 | T_acc   1.0 | V_Loss 0.278585 | V_acc. 0.967 | 🕒 1.437 \n",
      "Epoch: 256 | T_Loss 0.001162 | T_acc   1.0 | V_Loss 0.278962 | V_acc. 0.967 | 🕒 1.422 \n",
      "Epoch: 255 | T_Loss 0.001173 | T_acc   1.0 | V_Loss 0.277918 | V_acc. 0.967 | 🕒 1.391 \n",
      "Epoch: 254 | T_Loss 0.001188 | T_acc   1.0 | V_Loss 0.277837 | V_acc. 0.967 | 🕒 1.437 \n",
      "Epoch: 253 | T_Loss 0.001203 | T_acc   1.0 | V_Loss 0.2773 | V_acc. 0.967 | 🕒 1.391 \n",
      "Epoch: 252 | T_Loss 0.001223 | T_acc   1.0 | V_Loss 0.277511 | V_acc. 0.967 | 🕒 1.406 \n",
      "Epoch: 251 | T_Loss 0.001232 | T_acc   1.0 | V_Loss 0.27688 | V_acc. 0.967 | 🕒 1.422 \n",
      "Epoch: 250 | T_Loss 0.001247 | T_acc   1.0 | V_Loss 0.275578 | V_acc. 0.967 | 🕒 1.391 \n",
      "Epoch: 249 | T_Loss 0.001273 | T_acc   1.0 | V_Loss 0.275693 | V_acc. 0.967 | 🕒 1.406 \n",
      "Epoch: 248 | T_Loss 0.001271 | T_acc   1.0 | V_Loss 0.273916 | V_acc. 0.967 | 🕒 1.406 \n",
      "Epoch: 247 | T_Loss 0.001297 | T_acc   1.0 | V_Loss 0.274657 | V_acc. 0.967 | 🕒 1.414 \n",
      "Epoch: 246 | T_Loss 0.001316 | T_acc   1.0 | V_Loss 0.274104 | V_acc. 0.967 | 🕒 1.422 \n",
      "Epoch: 245 | T_Loss 0.001321 | T_acc   1.0 | V_Loss 0.274158 | V_acc. 0.967 | 🕒 1.406 \n",
      "Epoch: 244 | T_Loss 0.001343 | T_acc   1.0 | V_Loss 0.273966 | V_acc. 0.967 | 🕒 1.406 \n",
      "Epoch: 243 | T_Loss 0.001352 | T_acc   1.0 | V_Loss 0.273887 | V_acc. 0.967 | 🕒 1.406 \n",
      "Epoch: 242 | T_Loss 0.00137 | T_acc   1.0 | V_Loss 0.273735 | V_acc. 0.967 | 🕒 1.491 \n",
      "Epoch: 241 | T_Loss 0.001372 | T_acc   1.0 | V_Loss 0.273993 | V_acc. 0.967 | 🕒 1.437 \n",
      "Epoch: 240 | T_Loss 0.001404 | T_acc   1.0 | V_Loss 0.273634 | V_acc. 0.967 | 🕒  1.45 \n",
      "Epoch: 239 | T_Loss 0.001417 | T_acc   1.0 | V_Loss 0.272217 | V_acc. 0.967 | 🕒 1.492 \n",
      "Epoch: 238 | T_Loss 0.001422 | T_acc   1.0 | V_Loss 0.271052 | V_acc. 0.967 | 🕒   1.4 \n",
      "Epoch: 237 | T_Loss 0.001458 | T_acc   1.0 | V_Loss 0.271897 | V_acc. 0.967 | 🕒 1.377 \n",
      "Epoch: 236 | T_Loss 0.001485 | T_acc   1.0 | V_Loss 0.271416 | V_acc. 0.967 | 🕒 1.333 \n",
      "Epoch: 235 | T_Loss 0.001516 | T_acc   1.0 | V_Loss 0.270683 | V_acc. 0.967 | 🕒 1.401 \n",
      "Epoch: 234 | T_Loss 0.001495 | T_acc   1.0 | V_Loss 0.269002 | V_acc. 0.967 | 🕒   1.4 \n",
      "Epoch: 233 | T_Loss 0.001531 | T_acc   1.0 | V_Loss 0.268717 | V_acc. 0.967 | 🕒 1.384 \n",
      "Epoch: 232 | T_Loss 0.001548 | T_acc   1.0 | V_Loss 0.268404 | V_acc. 0.967 | 🕒 1.397 \n",
      "Epoch: 231 | T_Loss 0.001571 | T_acc   1.0 | V_Loss 0.268257 | V_acc. 0.967 | 🕒 1.375 \n",
      "Epoch: 230 | T_Loss 0.001583 | T_acc   1.0 | V_Loss 0.267992 | V_acc. 0.967 | 🕒 1.523 \n",
      "Epoch: 229 | T_Loss 0.00162 | T_acc   1.0 | V_Loss 0.268326 | V_acc. 0.967 | 🕒 1.352 \n",
      "Epoch: 228 | T_Loss 0.001615 | T_acc   1.0 | V_Loss 0.267985 | V_acc. 0.967 | 🕒 1.403 \n",
      "Epoch: 227 | T_Loss 0.001643 | T_acc   1.0 | V_Loss 0.268163 | V_acc. 0.967 | 🕒   1.4 \n",
      "Epoch: 226 | T_Loss 0.001641 | T_acc   1.0 | V_Loss 0.266955 | V_acc. 0.967 | 🕒 1.437 \n",
      "Epoch: 225 | T_Loss 0.001667 | T_acc   1.0 | V_Loss 0.267875 | V_acc. 0.967 | 🕒 1.376 \n",
      "Epoch: 224 | T_Loss 0.001695 | T_acc   1.0 | V_Loss 0.267367 | V_acc. 0.967 | 🕒 1.353 \n",
      "Epoch: 223 | T_Loss 0.001717 | T_acc   1.0 | V_Loss 0.266519 | V_acc. 0.967 | 🕒   1.5 \n",
      "Epoch: 222 | T_Loss 0.001733 | T_acc   1.0 | V_Loss 0.266159 | V_acc. 0.967 | 🕒 1.328 \n",
      "Epoch: 221 | T_Loss 0.001768 | T_acc   1.0 | V_Loss 0.265604 | V_acc. 0.967 | 🕒 1.375 \n",
      "Epoch: 220 | T_Loss 0.001766 | T_acc   1.0 | V_Loss 0.264208 | V_acc. 0.967 | 🕒  1.31 \n",
      "Epoch: 219 | T_Loss 0.001801 | T_acc   1.0 | V_Loss 0.264499 | V_acc. 0.967 | 🕒 1.387 \n",
      "Epoch: 218 | T_Loss 0.001839 | T_acc   1.0 | V_Loss 0.264668 | V_acc. 0.967 | 🕒 1.333 \n",
      "Epoch: 217 | T_Loss 0.001853 | T_acc   1.0 | V_Loss 0.26376 | V_acc. 0.967 | 🕒 1.464 \n",
      "Epoch: 216 | T_Loss 0.001887 | T_acc   1.0 | V_Loss 0.264149 | V_acc. 0.967 | 🕒 1.422 \n",
      "Epoch: 215 | T_Loss 0.001909 | T_acc   1.0 | V_Loss 0.261635 | V_acc. 0.967 | 🕒 1.398 \n",
      "Epoch: 214 | T_Loss 0.001921 | T_acc   1.0 | V_Loss 0.261866 | V_acc. 0.967 | 🕒 1.391 \n",
      "Epoch: 213 | T_Loss 0.001918 | T_acc   1.0 | V_Loss 0.2616 | V_acc. 0.967 | 🕒 1.336 \n",
      "Epoch: 212 | T_Loss 0.001965 | T_acc   1.0 | V_Loss 0.261759 | V_acc. 0.967 | 🕒 1.389 \n",
      "Epoch: 211 | T_Loss 0.001988 | T_acc   1.0 | V_Loss 0.261493 | V_acc. 0.967 | 🕒  1.33 \n",
      "Epoch: 210 | T_Loss 0.00202 | T_acc   1.0 | V_Loss 0.26117 | V_acc. 0.967 | 🕒 1.404 \n",
      "Epoch: 209 | T_Loss 0.002025 | T_acc   1.0 | V_Loss 0.259491 | V_acc. 0.967 | 🕒 1.364 \n",
      "Epoch: 208 | T_Loss 0.002041 | T_acc   1.0 | V_Loss 0.259683 | V_acc. 0.967 | 🕒 1.466 \n",
      "Epoch: 207 | T_Loss 0.002096 | T_acc   1.0 | V_Loss 0.258572 | V_acc. 0.967 | 🕒 1.338 \n",
      "Epoch: 206 | T_Loss 0.002101 | T_acc   1.0 | V_Loss 0.258032 | V_acc. 0.967 | 🕒 1.316 \n",
      "Epoch: 205 | T_Loss 0.002148 | T_acc   1.0 | V_Loss 0.258255 | V_acc. 0.967 | 🕒  1.34 \n",
      "Epoch: 204 | T_Loss 0.002167 | T_acc   1.0 | V_Loss 0.257401 | V_acc. 0.967 | 🕒 1.333 \n",
      "Epoch: 203 | T_Loss 0.002206 | T_acc   1.0 | V_Loss 0.256284 | V_acc. 0.967 | 🕒 1.319 \n",
      "Epoch: 202 | T_Loss 0.002239 | T_acc   1.0 | V_Loss 0.25696 | V_acc. 0.967 | 🕒 1.341 \n",
      "Epoch: 201 | T_Loss 0.002268 | T_acc   1.0 | V_Loss 0.255751 | V_acc. 0.967 | 🕒 1.385 \n",
      "Epoch: 200 | T_Loss 0.00228 | T_acc   1.0 | V_Loss 0.255223 | V_acc. 0.967 | 🕒 1.357 \n",
      "Epoch: 199 | T_Loss 0.002294 | T_acc   1.0 | V_Loss 0.254885 | V_acc. 0.967 | 🕒 1.318 \n",
      "Epoch: 198 | T_Loss 0.002328 | T_acc   1.0 | V_Loss 0.255884 | V_acc. 0.967 | 🕒 1.331 \n",
      "Epoch: 197 | T_Loss 0.002373 | T_acc   1.0 | V_Loss 0.255301 | V_acc. 0.967 | 🕒 1.271 \n",
      "Epoch: 196 | T_Loss 0.002391 | T_acc   1.0 | V_Loss 0.25479 | V_acc. 0.967 | 🕒 1.365 \n",
      "Epoch: 195 | T_Loss 0.002438 | T_acc   1.0 | V_Loss 0.254685 | V_acc. 0.967 | 🕒 1.332 \n",
      "Epoch: 194 | T_Loss 0.002467 | T_acc   1.0 | V_Loss 0.254303 | V_acc. 0.967 | 🕒  1.41 \n",
      "Epoch: 193 | T_Loss 0.002498 | T_acc   1.0 | V_Loss 0.251985 | V_acc. 0.967 | 🕒 1.296 \n",
      "Epoch: 192 | T_Loss 0.002528 | T_acc   1.0 | V_Loss 0.253431 | V_acc. 0.967 | 🕒 1.335 \n",
      "Epoch: 191 | T_Loss 0.002569 | T_acc   1.0 | V_Loss 0.251943 | V_acc. 0.967 | 🕒 1.299 \n",
      "Epoch: 190 | T_Loss 0.002588 | T_acc   1.0 | V_Loss 0.250971 | V_acc. 0.967 | 🕒 1.354 \n",
      "Epoch: 189 | T_Loss 0.002629 | T_acc   1.0 | V_Loss 0.250015 | V_acc. 0.967 | 🕒 1.333 \n",
      "Epoch: 188 | T_Loss 0.002667 | T_acc   1.0 | V_Loss 0.250657 | V_acc. 0.967 | 🕒 1.341 \n",
      "Epoch: 187 | T_Loss 0.002692 | T_acc   1.0 | V_Loss 0.250427 | V_acc. 0.967 | 🕒 1.294 \n",
      "Epoch: 186 | T_Loss 0.002752 | T_acc   1.0 | V_Loss 0.250165 | V_acc. 0.967 | 🕒 1.385 \n",
      "Epoch: 185 | T_Loss 0.002772 | T_acc   1.0 | V_Loss 0.24949 | V_acc. 0.967 | 🕒 1.259 \n",
      "Epoch: 184 | T_Loss 0.002842 | T_acc   1.0 | V_Loss 0.248987 | V_acc. 0.967 | 🕒 1.284 \n",
      "Epoch: 183 | T_Loss 0.002844 | T_acc   1.0 | V_Loss 0.249124 | V_acc. 0.967 | 🕒 1.248 \n",
      "Epoch: 182 | T_Loss 0.002897 | T_acc   1.0 | V_Loss 0.249489 | V_acc. 0.967 | 🕒 1.357 \n",
      "Epoch: 181 | T_Loss 0.002895 | T_acc   1.0 | V_Loss 0.247971 | V_acc. 0.967 | 🕒 1.416 \n",
      "Epoch: 180 | T_Loss 0.002947 | T_acc   1.0 | V_Loss 0.24772 | V_acc. 0.967 | 🕒 1.326 \n",
      "Epoch: 179 | T_Loss 0.003013 | T_acc   1.0 | V_Loss 0.247906 | V_acc. 0.967 | 🕒 1.334 \n",
      "Epoch: 178 | T_Loss 0.003016 | T_acc   1.0 | V_Loss 0.247346 | V_acc. 0.967 | 🕒 1.281 \n",
      "Epoch: 177 | T_Loss 0.00306 | T_acc   1.0 | V_Loss 0.246333 | V_acc. 0.967 | 🕒  1.29 \n",
      "Epoch: 176 | T_Loss 0.003134 | T_acc   1.0 | V_Loss 0.245394 | V_acc. 0.967 | 🕒 1.277 \n",
      "Epoch: 175 | T_Loss 0.003154 | T_acc   1.0 | V_Loss 0.246043 | V_acc. 0.967 | 🕒 1.326 \n",
      "Epoch: 174 | T_Loss 0.003234 | T_acc   1.0 | V_Loss 0.244764 | V_acc. 0.967 | 🕒 1.299 \n",
      "Epoch: 173 | T_Loss 0.003235 | T_acc   1.0 | V_Loss 0.244322 | V_acc. 0.967 | 🕒 1.266 \n",
      "Epoch: 172 | T_Loss 0.003291 | T_acc   1.0 | V_Loss 0.244161 | V_acc. 0.967 | 🕒 1.297 \n",
      "Epoch: 171 | T_Loss 0.003361 | T_acc   1.0 | V_Loss 0.243903 | V_acc. 0.967 | 🕒   1.3 \n",
      "Epoch: 170 | T_Loss 0.003438 | T_acc   1.0 | V_Loss 0.244658 | V_acc. 0.967 | 🕒 1.351 \n",
      "Epoch: 169 | T_Loss 0.003419 | T_acc   1.0 | V_Loss 0.242379 | V_acc. 0.967 | 🕒 1.268 \n",
      "Epoch: 168 | T_Loss 0.003502 | T_acc   1.0 | V_Loss 0.242173 | V_acc. 0.967 | 🕒 1.275 \n",
      "Epoch: 167 | T_Loss 0.003538 | T_acc   1.0 | V_Loss 0.242377 | V_acc. 0.967 | 🕒 1.282 \n",
      "Epoch: 166 | T_Loss 0.003561 | T_acc   1.0 | V_Loss 0.241668 | V_acc. 0.967 | 🕒 1.279 \n",
      "Epoch: 165 | T_Loss 0.00363 | T_acc   1.0 | V_Loss 0.241114 | V_acc. 0.967 | 🕒 1.274 \n",
      "Epoch: 164 | T_Loss 0.003671 | T_acc   1.0 | V_Loss 0.239459 | V_acc. 0.967 | 🕒 1.248 \n",
      "Epoch: 163 | T_Loss 0.003753 | T_acc   1.0 | V_Loss 0.240281 | V_acc. 0.967 | 🕒 1.257 \n",
      "Epoch: 162 | T_Loss 0.003763 | T_acc   1.0 | V_Loss 0.23958 | V_acc. 0.967 | 🕒 1.253 \n",
      "Epoch: 161 | T_Loss 0.003819 | T_acc   1.0 | V_Loss 0.240023 | V_acc. 0.967 | 🕒 1.249 \n",
      "Epoch: 160 | T_Loss 0.0039 | T_acc   1.0 | V_Loss 0.239728 | V_acc. 0.967 | 🕒  1.24 \n",
      "Epoch: 159 | T_Loss 0.003959 | T_acc   1.0 | V_Loss 0.237917 | V_acc. 0.967 | 🕒 1.313 \n",
      "Epoch: 158 | T_Loss 0.003997 | T_acc   1.0 | V_Loss 0.237902 | V_acc. 0.967 | 🕒 1.203 \n",
      "Epoch: 157 | T_Loss 0.004056 | T_acc   1.0 | V_Loss 0.236646 | V_acc. 0.967 | 🕒 1.242 \n",
      "Epoch: 156 | T_Loss 0.004188 | T_acc   1.0 | V_Loss 0.237538 | V_acc. 0.967 | 🕒 1.265 \n",
      "Epoch: 155 | T_Loss 0.00422 | T_acc   1.0 | V_Loss 0.236664 | V_acc. 0.967 | 🕒 1.187 \n",
      "Epoch: 154 | T_Loss 0.004301 | T_acc   1.0 | V_Loss 0.23516 | V_acc. 0.967 | 🕒 1.225 \n",
      "Epoch: 153 | T_Loss 0.004298 | T_acc   1.0 | V_Loss 0.235132 | V_acc. 0.967 | 🕒  1.27 \n",
      "Epoch: 152 | T_Loss 0.004379 | T_acc   1.0 | V_Loss 0.234861 | V_acc. 0.967 | 🕒 1.221 \n",
      "Epoch: 151 | T_Loss 0.004422 | T_acc   1.0 | V_Loss 0.235243 | V_acc. 0.967 | 🕒 1.253 \n",
      "Epoch: 150 | T_Loss 0.004508 | T_acc   1.0 | V_Loss 0.235456 | V_acc. 0.967 | 🕒 1.217 \n",
      "Epoch: 149 | T_Loss 0.004614 | T_acc   1.0 | V_Loss 0.234616 | V_acc. 0.967 | 🕒  1.19 \n",
      "Epoch: 148 | T_Loss 0.004661 | T_acc   1.0 | V_Loss 0.233862 | V_acc. 0.967 | 🕒 1.252 \n",
      "Epoch: 147 | T_Loss 0.004709 | T_acc   1.0 | V_Loss 0.232528 | V_acc. 0.967 | 🕒 1.231 \n",
      "Epoch: 146 | T_Loss 0.004777 | T_acc   1.0 | V_Loss 0.232047 | V_acc. 0.967 | 🕒 1.182 \n",
      "Epoch: 145 | T_Loss 0.004828 | T_acc   1.0 | V_Loss 0.231127 | V_acc. 0.967 | 🕒 1.359 \n",
      "Epoch: 144 | T_Loss 0.005018 | T_acc   1.0 | V_Loss 0.23169 | V_acc. 0.967 | 🕒 1.201 \n",
      "Epoch: 143 | T_Loss 0.004994 | T_acc   1.0 | V_Loss 0.230284 | V_acc. 0.967 | 🕒 1.208 \n",
      "Epoch: 142 | T_Loss 0.005098 | T_acc   1.0 | V_Loss 0.229163 | V_acc. 0.967 | 🕒 1.326 \n",
      "Epoch: 141 | T_Loss 0.005113 | T_acc   1.0 | V_Loss 0.229001 | V_acc. 0.967 | 🕒 1.212 \n",
      "Epoch: 140 | T_Loss 0.005186 | T_acc   1.0 | V_Loss 0.229669 | V_acc. 0.967 | 🕒 1.173 \n",
      "Epoch: 139 | T_Loss 0.005274 | T_acc   1.0 | V_Loss 0.22885 | V_acc. 0.967 | 🕒 1.234 \n",
      "Epoch: 138 | T_Loss 0.00539 | T_acc   1.0 | V_Loss 0.228438 | V_acc. 0.967 | 🕒 1.174 \n",
      "Epoch: 137 | T_Loss 0.005454 | T_acc   1.0 | V_Loss 0.226571 | V_acc. 0.967 | 🕒 1.163 \n",
      "Epoch: 136 | T_Loss 0.005555 | T_acc   1.0 | V_Loss 0.226493 | V_acc. 0.967 | 🕒 1.185 \n",
      "Epoch: 135 | T_Loss 0.005649 | T_acc   1.0 | V_Loss 0.226405 | V_acc. 0.967 | 🕒   1.2 \n",
      "Epoch: 134 | T_Loss 0.005731 | T_acc   1.0 | V_Loss 0.225647 | V_acc. 0.967 | 🕒 1.181 \n",
      "Epoch: 133 | T_Loss 0.005774 | T_acc   1.0 | V_Loss 0.224106 | V_acc. 0.967 | 🕒 1.154 \n",
      "Epoch: 132 | T_Loss 0.005899 | T_acc   1.0 | V_Loss 0.223575 | V_acc. 0.967 | 🕒 1.186 \n",
      "Epoch: 131 | T_Loss 0.006028 | T_acc   1.0 | V_Loss 0.223073 | V_acc. 0.967 | 🕒 1.244 \n",
      "Epoch: 130 | T_Loss 0.006078 | T_acc   1.0 | V_Loss 0.223464 | V_acc. 0.967 | 🕒 1.168 \n",
      "Epoch: 129 | T_Loss 0.006175 | T_acc   1.0 | V_Loss 0.222296 | V_acc. 0.967 | 🕒 1.197 \n",
      "Epoch: 128 | T_Loss 0.006277 | T_acc   1.0 | V_Loss 0.22189 | V_acc. 0.967 | 🕒 1.198 \n",
      "Epoch: 127 | T_Loss 0.006446 | T_acc   1.0 | V_Loss 0.221906 | V_acc. 0.967 | 🕒 1.194 \n",
      "Epoch: 126 | T_Loss 0.00644 | T_acc   1.0 | V_Loss 0.22093 | V_acc. 0.967 | 🕒 1.133 \n",
      "Epoch: 125 | T_Loss 0.00664 | T_acc   1.0 | V_Loss 0.220907 | V_acc. 0.967 | 🕒 1.134 \n",
      "Epoch: 124 | T_Loss 0.006728 | T_acc   1.0 | V_Loss 0.220881 | V_acc. 0.967 | 🕒 1.179 \n",
      "Epoch: 123 | T_Loss 0.006841 | T_acc   1.0 | V_Loss 0.220865 | V_acc. 0.967 | 🕒 1.155 \n",
      "Epoch: 122 | T_Loss 0.006946 | T_acc   1.0 | V_Loss 0.219175 | V_acc. 0.967 | 🕒   1.2 \n",
      "Epoch: 121 | T_Loss 0.007026 | T_acc   1.0 | V_Loss 0.219987 | V_acc. 0.967 | 🕒 1.137 \n",
      "Epoch: 120 | T_Loss 0.007176 | T_acc   1.0 | V_Loss 0.218689 | V_acc. 0.967 | 🕒 1.182 \n",
      "Epoch: 119 | T_Loss 0.007253 | T_acc   1.0 | V_Loss 0.218808 | V_acc. 0.967 | 🕒 1.247 \n",
      "Epoch: 118 | T_Loss 0.007475 | T_acc   1.0 | V_Loss 0.218434 | V_acc. 0.967 | 🕒 1.207 \n",
      "Epoch: 117 | T_Loss 0.007515 | T_acc   1.0 | V_Loss 0.219041 | V_acc. 0.967 | 🕒 1.123 \n",
      "Epoch: 116 | T_Loss 0.007584 | T_acc   1.0 | V_Loss 0.218511 | V_acc. 0.967 | 🕒 1.231 \n",
      "Epoch: 115 | T_Loss 0.007788 | T_acc   1.0 | V_Loss 0.218068 | V_acc. 0.967 | 🕒  1.15 \n",
      "Epoch: 114 | T_Loss 0.007953 | T_acc   1.0 | V_Loss 0.216678 | V_acc. 0.967 | 🕒 1.183 \n",
      "Epoch: 113 | T_Loss 0.008039 | T_acc   1.0 | V_Loss 0.215779 | V_acc. 0.967 | 🕒 1.126 \n",
      "Epoch: 112 | T_Loss 0.008246 | T_acc   1.0 | V_Loss 0.214083 | V_acc. 0.967 | 🕒 1.212 \n",
      "Epoch: 111 | T_Loss 0.008388 | T_acc   1.0 | V_Loss 0.213123 | V_acc. 0.967 | 🕒 1.171 \n",
      "Epoch: 110 | T_Loss 0.008486 | T_acc   1.0 | V_Loss 0.212621 | V_acc. 0.967 | 🕒 1.132 \n",
      "Epoch: 109 | T_Loss 0.008663 | T_acc   1.0 | V_Loss 0.212213 | V_acc. 0.967 | 🕒 1.143 \n",
      "Epoch: 108 | T_Loss 0.008791 | T_acc   1.0 | V_Loss 0.212278 | V_acc. 0.967 | 🕒 1.134 \n",
      "Epoch: 107 | T_Loss 0.009018 | T_acc   1.0 | V_Loss 0.209817 | V_acc. 0.967 | 🕒 1.215 \n",
      "Epoch: 106 | T_Loss 0.009094 | T_acc   1.0 | V_Loss 0.207902 | V_acc. 0.967 | 🕒  1.13 \n",
      "Epoch: 105 | T_Loss 0.009285 | T_acc   1.0 | V_Loss 0.207049 | V_acc. 0.967 | 🕒  1.17 \n",
      "Epoch: 104 | T_Loss 0.009407 | T_acc   1.0 | V_Loss 0.206096 | V_acc. 0.967 | 🕒 1.131 \n",
      "Epoch: 103 | T_Loss 0.009559 | T_acc   1.0 | V_Loss 0.206596 | V_acc. 0.967 | 🕒 1.132 \n",
      "Epoch: 102 | T_Loss 0.009881 | T_acc   1.0 | V_Loss 0.207651 | V_acc. 0.967 | 🕒 1.136 \n",
      "Epoch: 101 | T_Loss 0.010022 | T_acc   1.0 | V_Loss 0.205891 | V_acc. 0.967 | 🕒  1.25 \n",
      "Epoch: 100 | T_Loss 0.010171 | T_acc   1.0 | V_Loss 0.205074 | V_acc. 0.967 | 🕒 1.139 \n",
      "Epoch:  99 | T_Loss 0.010275 | T_acc   1.0 | V_Loss 0.204079 | V_acc. 0.967 | 🕒 1.104 \n",
      "Epoch:  98 | T_Loss 0.010497 | T_acc   1.0 | V_Loss 0.202631 | V_acc. 0.967 | 🕒 1.083 \n",
      "Epoch:  97 | T_Loss 0.010809 | T_acc   1.0 | V_Loss 0.203768 | V_acc. 0.967 | 🕒 1.162 \n",
      "Epoch:  96 | T_Loss 0.010988 | T_acc   1.0 | V_Loss 0.203178 | V_acc. 0.967 | 🕒 1.171 \n",
      "Epoch:  95 | T_Loss 0.011114 | T_acc   1.0 | V_Loss 0.201895 | V_acc. 0.967 | 🕒 1.062 \n",
      "Epoch:  94 | T_Loss 0.011406 | T_acc   1.0 | V_Loss 0.201714 | V_acc. 0.967 | 🕒 1.078 \n",
      "Epoch:  93 | T_Loss 0.011548 | T_acc   1.0 | V_Loss 0.198642 | V_acc. 0.967 | 🕒 1.069 \n",
      "Epoch:  92 | T_Loss 0.01189 | T_acc   1.0 | V_Loss 0.197881 | V_acc. 0.967 | 🕒 1.074 \n",
      "Epoch:  91 | T_Loss 0.012166 | T_acc   1.0 | V_Loss 0.196374 | V_acc. 0.967 | 🕒 1.152 \n",
      "Epoch:  90 | T_Loss 0.012345 | T_acc   1.0 | V_Loss 0.197778 | V_acc. 0.967 | 🕒 1.119 \n",
      "Epoch:  89 | T_Loss 0.01249 | T_acc   1.0 | V_Loss 0.196685 | V_acc. 0.967 | 🕒 1.085 \n",
      "Epoch:  88 | T_Loss 0.012934 | T_acc   1.0 | V_Loss 0.194925 | V_acc. 0.967 | 🕒 1.087 \n",
      "Epoch:  87 | T_Loss 0.013008 | T_acc   1.0 | V_Loss 0.192776 | V_acc. 0.967 | 🕒  1.12 \n",
      "Epoch:  86 | T_Loss 0.013431 | T_acc   1.0 | V_Loss 0.193073 | V_acc. 0.967 | 🕒 1.099 \n",
      "Epoch:  85 | T_Loss 0.013682 | T_acc   1.0 | V_Loss 0.193169 | V_acc. 0.967 | 🕒 1.058 \n",
      "Epoch:  84 | T_Loss 0.01387 | T_acc   1.0 | V_Loss 0.193705 | V_acc. 0.967 | 🕒 1.092 \n",
      "Epoch:  83 | T_Loss 0.014064 | T_acc   1.0 | V_Loss 0.191737 | V_acc. 0.967 | 🕒 1.078 \n",
      "Epoch:  82 | T_Loss 0.014554 | T_acc   1.0 | V_Loss 0.190022 | V_acc. 0.967 | 🕒  1.12 \n",
      "Epoch:  81 | T_Loss 0.014833 | T_acc   1.0 | V_Loss 0.190534 | V_acc. 0.967 | 🕒 1.083 \n",
      "Epoch:  80 | T_Loss 0.015212 | T_acc   1.0 | V_Loss 0.189086 | V_acc. 0.967 | 🕒 1.096 \n",
      "Epoch:  79 | T_Loss 0.015596 | T_acc   1.0 | V_Loss 0.187706 | V_acc. 0.967 | 🕒 1.102 \n",
      "Epoch:  78 | T_Loss 0.015776 | T_acc   1.0 | V_Loss 0.186841 | V_acc. 0.967 | 🕒 1.117 \n",
      "Epoch:  77 | T_Loss 0.016188 | T_acc   1.0 | V_Loss 0.187643 | V_acc. 0.967 | 🕒 1.047 \n",
      "Epoch:  76 | T_Loss 0.016441 | T_acc   1.0 | V_Loss 0.187105 | V_acc. 0.967 | 🕒 1.067 \n",
      "Epoch:  75 | T_Loss 0.016902 | T_acc   1.0 | V_Loss 0.184707 | V_acc. 0.967 | 🕒 1.083 \n",
      "Epoch:  74 | T_Loss 0.017192 | T_acc   1.0 | V_Loss 0.180957 | V_acc. 0.967 | 🕒 1.097 \n",
      "Epoch:  73 | T_Loss 0.017649 | T_acc   1.0 | V_Loss 0.182819 | V_acc. 0.967 | 🕒 1.088 \n",
      "Epoch:  72 | T_Loss 0.018198 | T_acc   1.0 | V_Loss 0.184502 | V_acc. 0.967 | 🕒  1.11 \n",
      "Epoch:  71 | T_Loss 0.018375 | T_acc   1.0 | V_Loss 0.183907 | V_acc. 0.967 | 🕒 1.093 \n",
      "Epoch:  70 | T_Loss 0.018686 | T_acc   1.0 | V_Loss 0.179947 | V_acc. 0.967 | 🕒 1.153 \n",
      "Epoch:  69 | T_Loss 0.019192 | T_acc   1.0 | V_Loss 0.176434 | V_acc. 0.967 | 🕒 1.065 \n",
      "Epoch:  68 | T_Loss 0.019925 | T_acc   1.0 | V_Loss 0.177582 | V_acc. 0.967 | 🕒 1.048 \n",
      "Epoch:  67 | T_Loss 0.020028 | T_acc   1.0 | V_Loss 0.17659 | V_acc. 0.967 | 🕒 1.075 \n",
      "Epoch:  66 | T_Loss 0.020538 | T_acc   1.0 | V_Loss 0.175056 | V_acc. 0.967 | 🕒 1.094 \n",
      "Epoch:  65 | T_Loss 0.020869 | T_acc   1.0 | V_Loss 0.173919 | V_acc. 0.967 | 🕒 1.047 \n",
      "Epoch:  64 | T_Loss 0.021603 | T_acc   1.0 | V_Loss 0.172812 | V_acc. 0.967 | 🕒 1.125 \n",
      "Epoch:  63 | T_Loss 0.022148 | T_acc   1.0 | V_Loss 0.16925 | V_acc. 0.967 | 🕒  1.03 \n",
      "Epoch:  62 | T_Loss 0.022562 | T_acc   1.0 | V_Loss 0.168326 | V_acc. 0.967 | 🕒 1.062 \n",
      "Epoch:  61 | T_Loss 0.023556 | T_acc   1.0 | V_Loss 0.171918 | V_acc. 0.967 | 🕒 1.047 \n",
      "Epoch:  60 | T_Loss 0.02385 | T_acc   1.0 | V_Loss 0.170037 | V_acc. 0.967 | 🕒 1.031 \n",
      "Epoch:  59 | T_Loss 0.024634 | T_acc   1.0 | V_Loss 0.167296 | V_acc. 0.967 | 🕒 1.016 \n",
      "Epoch:  58 | T_Loss 0.025049 | T_acc   1.0 | V_Loss 0.165092 | V_acc. 0.967 | 🕒 1.047 \n",
      "Epoch:  57 | T_Loss 0.025841 | T_acc   1.0 | V_Loss 0.162708 | V_acc. 0.967 | 🕒 1.079 \n",
      "Epoch:  56 | T_Loss 0.026471 | T_acc   1.0 | V_Loss 0.163288 | V_acc. 0.967 | 🕒 0.994 \n",
      "Epoch:  55 | T_Loss 0.027049 | T_acc   1.0 | V_Loss 0.162764 | V_acc. 0.967 | 🕒 0.999 \n",
      "Epoch:  54 | T_Loss 0.027831 | T_acc   1.0 | V_Loss 0.16219 | V_acc. 0.967 | 🕒 1.065 \n",
      "Epoch:  53 | T_Loss 0.028356 | T_acc   1.0 | V_Loss 0.161076 | V_acc. 0.967 | 🕒 1.035 \n",
      "Epoch:  52 | T_Loss 0.029257 | T_acc   1.0 | V_Loss 0.16066 | V_acc. 0.967 | 🕒 1.046 \n",
      "Epoch:  51 | T_Loss 0.030384 | T_acc   1.0 | V_Loss 0.161589 | V_acc. 0.967 | 🕒 1.054 \n",
      "Epoch:  50 | T_Loss 0.030952 | T_acc   1.0 | V_Loss 0.160267 | V_acc. 0.967 | 🕒 1.086 \n",
      "Epoch:  49 | T_Loss 0.032132 | T_acc   1.0 | V_Loss 0.158833 | V_acc. 0.967 | 🕒 1.017 \n",
      "Epoch:  48 | T_Loss 0.033195 | T_acc   1.0 | V_Loss 0.156846 | V_acc. 0.967 | 🕒 1.079 \n",
      "Epoch:  47 | T_Loss 0.034156 | T_acc   1.0 | V_Loss 0.158227 | V_acc. 0.967 | 🕒 1.094 \n",
      "Epoch:  46 | T_Loss 0.035213 | T_acc   1.0 | V_Loss 0.154799 | V_acc. 0.967 | 🕒 1.067 \n",
      "Epoch:  45 | T_Loss 0.035529 | T_acc   1.0 | V_Loss 0.148109 | V_acc. 0.967 | 🕒 1.018 \n",
      "Epoch:  44 | T_Loss 0.036754 | T_acc   1.0 | V_Loss 0.145609 | V_acc. 0.967 | 🕒  1.11 \n",
      "Epoch:  43 | T_Loss 0.038049 | T_acc   1.0 | V_Loss 0.147003 | V_acc. 0.967 | 🕒 1.047 \n",
      "Epoch:  42 | T_Loss 0.038886 | T_acc   1.0 | V_Loss 0.146802 | V_acc. 0.967 | 🕒 1.078 \n",
      "Epoch:  41 | T_Loss 0.040442 | T_acc   1.0 | V_Loss 0.146777 | V_acc. 0.967 | 🕒 1.016 \n",
      "Epoch:  40 | T_Loss 0.0422 | T_acc   1.0 | V_Loss 0.144175 | V_acc. 0.967 | 🕒 1.031 \n",
      "Epoch:  39 | T_Loss 0.043182 | T_acc   1.0 | V_Loss 0.142842 | V_acc. 0.967 | 🕒 1.047 \n",
      "Epoch:  38 | T_Loss 0.044235 | T_acc   1.0 | V_Loss 0.141466 | V_acc. 0.967 | 🕒 1.031 \n",
      "Epoch:  37 | T_Loss 0.045816 | T_acc   1.0 | V_Loss 0.138849 | V_acc. 0.967 | 🕒  0.97 \n",
      "Epoch:  36 | T_Loss 0.047675 | T_acc   1.0 | V_Loss 0.135848 | V_acc. 0.967 | 🕒 0.987 \n",
      "Epoch:  35 | T_Loss 0.048973 | T_acc   1.0 | V_Loss 0.136314 | V_acc. 0.967 | 🕒 1.003 \n",
      "Epoch:  34 | T_Loss 0.050455 | T_acc   1.0 | V_Loss 0.135017 | V_acc. 0.967 | 🕒 1.083 \n",
      "Epoch:  33 | T_Loss 0.052876 | T_acc   1.0 | V_Loss 0.132922 | V_acc. 0.967 | 🕒 0.998 \n",
      "Epoch:  32 | T_Loss 0.054155 | T_acc   1.0 | V_Loss 0.130769 | V_acc. 0.967 | 🕒 1.029 \n",
      "Epoch:  31 | T_Loss 0.056736 | T_acc   1.0 | V_Loss 0.13002 | V_acc. 0.967 | 🕒 0.985 \n",
      "Epoch:  30 | T_Loss 0.058581 | T_acc   1.0 | V_Loss 0.127741 | V_acc. 0.967 | 🕒 1.036 \n",
      "Epoch:  29 | T_Loss 0.060764 | T_acc   1.0 | V_Loss 0.124616 | V_acc. 0.983 | 🕒 1.001 \n",
      "Epoch:  28 | T_Loss 0.062969 | T_acc   1.0 | V_Loss 0.123763 | V_acc. 0.983 | 🕒 1.033 \n",
      "Epoch:  27 | T_Loss 0.065791 | T_acc   1.0 | V_Loss 0.123414 | V_acc. 0.983 | 🕒 0.986 \n",
      "Epoch:  26 | T_Loss 0.06819 | T_acc   1.0 | V_Loss 0.123675 | V_acc. 0.983 | 🕒 0.981 \n",
      "Epoch:  25 | T_Loss 0.071049 | T_acc   1.0 | V_Loss 0.120139 | V_acc. 0.983 | 🕒  0.98 \n",
      "Epoch:  24 | T_Loss 0.076072 | T_acc 0.998 | V_Loss 0.10731 | V_acc. 0.983 | 🕒 0.968 \n",
      "Epoch:  23 | T_Loss 0.081809 | T_acc   1.0 | V_Loss 0.072662 | V_acc. 0.984 | 🕒 0.932 \n",
      "Epoch:  22 | T_Loss 0.096002 | T_acc 0.995 | V_Loss 0.055802 | V_acc.   1.0 | 🕒 0.987 <-- 저장 포인트\n",
      "Epoch:  21 | T_Loss 0.096777 | T_acc 0.997 | V_Loss 0.108457 | V_acc. 0.984 | 🕒 0.983 <-- 저장 포인트\n",
      "Epoch:  20 | T_Loss 0.09978 | T_acc 0.995 | V_Loss 0.131149 | V_acc. 0.983 | 🕒 0.971 \n",
      "Epoch:  19 | T_Loss 0.118983 | T_acc  0.99 | V_Loss 0.1875 | V_acc.  0.95 | 🕒 0.995 \n",
      "Epoch:  18 | T_Loss 0.127645 | T_acc 0.988 | V_Loss 0.123925 | V_acc. 0.967 | 🕒 0.951 <-- 저장 포인트\n",
      "Epoch:  17 | T_Loss 0.137839 | T_acc 0.988 | V_Loss 0.212939 | V_acc.  0.95 | 🕒 0.932 \n",
      "Epoch:  16 | T_Loss 0.153786 | T_acc 0.979 | V_Loss 0.146157 | V_acc. 0.967 | 🕒 0.952 <-- 저장 포인트\n",
      "Epoch:  15 | T_Loss 0.130746 | T_acc 0.991 | V_Loss 0.186346 | V_acc. 0.967 | 🕒 0.932 \n",
      "Epoch:  14 | T_Loss 0.139139 | T_acc 0.993 | V_Loss 0.186413 | V_acc. 0.967 | 🕒 0.916 \n",
      "Epoch:  13 | T_Loss 0.158663 | T_acc 0.986 | V_Loss 0.177196 | V_acc. 0.967 | 🕒  0.92 <-- 저장 포인트\n",
      "Epoch:  12 | T_Loss 0.180904 | T_acc 0.981 | V_Loss 0.178464 | V_acc. 0.967 | 🕒 0.907 <-- 저장 포인트\n",
      "Epoch:  11 | T_Loss 0.193954 | T_acc 0.977 | V_Loss 0.193801 | V_acc. 0.967 | 🕒 0.918 <-- 저장 포인트\n",
      "Epoch:  10 | T_Loss 0.210495 | T_acc  0.97 | V_Loss 0.202227 | V_acc. 0.967 | 🕒 0.938 \n",
      "Epoch:   9 | T_Loss 0.222251 | T_acc 0.976 | V_Loss 0.198382 | V_acc. 0.967 | 🕒   0.9 <-- 저장 포인트\n",
      "Epoch:   8 | T_Loss 0.213761 | T_acc 0.979 | V_Loss 0.291097 | V_acc. 0.933 | 🕒 0.896 <-- 저장 포인트\n",
      "Epoch:   7 | T_Loss 0.220657 | T_acc 0.977 | V_Loss 0.301108 | V_acc. 0.933 | 🕒 0.916 <-- 저장 포인트\n",
      "Epoch:   6 | T_Loss 0.247253 | T_acc 0.976 | V_Loss 0.33684 | V_acc. 0.933 | 🕒 0.925 \n",
      "Epoch:   5 | T_Loss 0.276472 | T_acc 0.967 | V_Loss 0.319041 | V_acc.   0.9 | 🕒 0.952 <-- 저장 포인트\n",
      "Epoch:   4 | T_Loss 0.331147 | T_acc 0.941 | V_Loss 0.326977 | V_acc. 0.933 | 🕒 0.906 <-- 저장 포인트\n",
      "Epoch:   3 | T_Loss 0.389165 | T_acc 0.927 | V_Loss 0.485534 | V_acc. 0.834 | 🕒 0.952 <-- 저장 포인트\n",
      "Epoch:   2 | T_Loss 0.491507 | T_acc  0.87 | V_Loss 0.520951 | V_acc. 0.832 | 🕒  0.91 <-- 저장 포인트\n",
      "Epoch:   1 | T_Loss 0.748366 | T_acc 0.762 | V_Loss 1.497327 | V_acc. 0.265 | 🕒 1.314 \n",
      "\n",
      " Training completed!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "init_model()\n",
    "init_epoch()\n",
    "init_log()\n",
    "maximum_epoch = 300\n",
    "min_loss = 1\n",
    "memo = ''\n",
    "while epoch_not_finished():\n",
    "    start_time = time.time()\n",
    "    tloss, tacc = epoch(train_loader, mode = 'train')\n",
    "    end_time = time.time()\n",
    "    time_taken = end_time - start_time\n",
    "    record_train_log(tloss, tacc, time_taken)\n",
    "    with torch.no_grad():\n",
    "        vloss, vacc = epoch(val_loader, mode = 'val')\n",
    "        if vloss < min_loss:\n",
    "            print('최소 Loss 달성. 모델 저장: {}'.format(epoch_cnt))\n",
    "            min_loss = vloss\n",
    "            torch.save(net_lstm.state_dict(), './model_lstm_yolo_cnn_mediapipe.pth')\n",
    "            memo = '<-- 저장 포인트'\n",
    "        else: memo = ''\n",
    "        record_valid_log(vloss, vacc)\n",
    "    print_log(memo)\n",
    "print('\\n Training completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46728076",
   "metadata": {},
   "source": [
    "### Validation 없이 정해진 epoch 만큼 무대포 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79b68faf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▍                                                                                 | 1/200 [00:01<05:50,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.6772672839462757 | Train Acc.: 0.7671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▊                                                                                 | 2/200 [00:03<05:30,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.42971356213092804 | Train Acc.: 0.8875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▏                                                                                | 3/200 [00:05<05:26,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.3419212616980076 | Train Acc.: 0.93125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|█▋                                                                                | 4/200 [00:06<05:22,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.31663343235850333 | Train Acc.: 0.9390625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|██                                                                                | 5/200 [00:08<05:22,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.27219103276729584 | Train Acc.: 0.9578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|██▍                                                                               | 6/200 [00:09<05:17,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.2392079286277294 | Train Acc.: 0.9671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|██▊                                                                               | 7/200 [00:11<05:13,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.25684345737099645 | Train Acc.: 0.94375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▎                                                                              | 8/200 [00:13<05:12,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.22690495662391186 | Train Acc.: 0.9578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|███▋                                                                              | 9/200 [00:14<05:15,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.19671276919543743 | Train Acc.: 0.96875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|████                                                                             | 10/200 [00:16<05:14,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.18975648432970046 | Train Acc.: 0.9703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▍                                                                            | 11/200 [00:18<05:10,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.15302717126905918 | Train Acc.: 0.9828125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|████▊                                                                            | 12/200 [00:19<05:09,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.14039943143725395 | Train Acc.: 0.9859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|█████▎                                                                           | 13/200 [00:21<05:07,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.13425397984683513 | Train Acc.: 0.9859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|█████▋                                                                           | 14/200 [00:23<05:04,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.12371502555906773 | Train Acc.: 0.9875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████                                                                           | 15/200 [00:24<04:59,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1016280610114336 | Train Acc.: 0.9953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▍                                                                          | 16/200 [00:26<04:59,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.1030658308416605 | Train Acc.: 0.99375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|██████▉                                                                          | 17/200 [00:27<05:02,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0870423911139369 | Train Acc.: 0.996875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|███████▎                                                                         | 18/200 [00:29<04:59,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.08105713929980993 | Train Acc.: 0.9984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|███████▋                                                                         | 19/200 [00:31<04:55,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0789940694347024 | Train Acc.: 0.9984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████                                                                         | 20/200 [00:32<04:52,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.07235774472355842 | Train Acc.: 0.9984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|████████▌                                                                        | 21/200 [00:34<04:51,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06883940529078245 | Train Acc.: 0.9984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|████████▉                                                                        | 22/200 [00:36<04:48,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06638594456017018 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▎                                                                       | 23/200 [00:37<04:45,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06524905133992434 | Train Acc.: 0.9984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█████████▋                                                                       | 24/200 [00:39<04:43,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.06178545765578747 | Train Acc.: 0.9984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|██████████▏                                                                      | 25/200 [00:40<04:43,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.05721891932189464 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|██████████▌                                                                      | 26/200 [00:42<04:42,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.054361794143915176 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|██████████▉                                                                      | 27/200 [00:44<04:42,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.05234706606715918 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▎                                                                     | 28/200 [00:45<04:44,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.05001503694802523 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|███████████▋                                                                     | 29/200 [00:47<04:42,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.047849062457680704 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|████████████▏                                                                    | 30/200 [00:49<04:40,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.045882776379585266 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▌                                                                    | 31/200 [00:50<04:40,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.04490984156727791 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|████████████▉                                                                    | 32/200 [00:52<04:40,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.04318478740751743 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█████████████▎                                                                   | 33/200 [00:54<04:37,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.041664665564894676 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█████████████▊                                                                   | 34/200 [00:55<04:35,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.040087091457098725 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▏                                                                  | 35/200 [00:57<04:34,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.038889335840940474 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▌                                                                  | 36/200 [00:59<04:30,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03713843608275056 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|██████████████▉                                                                  | 37/200 [01:00<04:27,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.035965487267822026 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|███████████████▍                                                                 | 38/200 [01:02<04:25,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03551431018859148 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|███████████████▊                                                                 | 39/200 [01:04<04:23,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03395886346697807 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▏                                                                | 40/200 [01:05<04:20,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03293786002323031 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▌                                                                | 41/200 [01:07<04:16,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.03199233300983906 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|█████████████████                                                                | 42/200 [01:08<04:20,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.030720413941890002 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▍                                                               | 43/200 [01:10<04:17,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.02977253021672368 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|█████████████████▊                                                               | 44/200 [01:12<04:15,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.028952676709741353 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██████████████████▏                                                              | 45/200 [01:13<04:11,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.028065180219709874 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██████████████████▋                                                              | 46/200 [01:15<04:10,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.027250537555664776 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████                                                              | 47/200 [01:17<04:16,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.026370536629110576 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▍                                                             | 48/200 [01:18<04:12,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.02583373887464404 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|███████████████████▊                                                             | 49/200 [01:20<04:07,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.025164370145648717 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|████████████████████▎                                                            | 50/200 [01:22<04:04,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.02415646454319358 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|████████████████████▋                                                            | 51/200 [01:23<04:05,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.023491268511861563 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████                                                            | 52/200 [01:25<04:02,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.022713363636285067 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|█████████████████████▍                                                           | 53/200 [01:26<04:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.02206693505868316 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|█████████████████████▊                                                           | 54/200 [01:28<03:58,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.02159048179164529 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▎                                                          | 55/200 [01:30<03:57,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.020982051640748976 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██████████████████████▋                                                          | 56/200 [01:31<03:55,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0204498871229589 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|███████████████████████                                                          | 57/200 [01:33<03:54,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.019883003272116184 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|███████████████████████▍                                                         | 58/200 [01:35<03:51,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.019406783627346158 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|███████████████████████▉                                                         | 59/200 [01:36<03:49,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.018940863106399773 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▎                                                        | 60/200 [01:38<03:49,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.018250034470111132 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▋                                                        | 61/200 [01:40<03:46,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.017911554127931596 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|█████████████████████████                                                        | 62/200 [01:41<03:44,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.017563743190839885 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▌                                                       | 63/200 [01:43<03:41,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.016907233325764538 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|█████████████████████████▉                                                       | 64/200 [01:44<03:39,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.016618404584005476 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|██████████████████████████▎                                                      | 65/200 [01:46<03:39,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01596438242122531 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|██████████████████████████▋                                                      | 66/200 [01:48<03:37,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.015821396745741366 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▏                                                     | 67/200 [01:49<03:34,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.015443240804597736 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▌                                                     | 68/200 [01:51<03:34,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01506656464189291 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███████████████████████████▉                                                     | 69/200 [01:52<03:33,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.014644685713574291 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|████████████████████████████▎                                                    | 70/200 [01:54<03:32,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01449730950407684 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|████████████████████████████▊                                                    | 71/200 [01:56<03:29,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.013937255321070551 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▏                                                   | 72/200 [01:57<03:28,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.013626850629225373 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|█████████████████████████████▌                                                   | 73/200 [01:59<03:26,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.013259372301399707 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|█████████████████████████████▉                                                   | 74/200 [02:01<03:26,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01309210672043264 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▍                                                  | 75/200 [02:02<03:24,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.012843788508325816 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|██████████████████████████████▊                                                  | 76/200 [02:04<03:22,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.012463341187685727 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███████████████████████████████▏                                                 | 77/200 [02:06<03:20,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.012178278109058738 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███████████████████████████████▌                                                 | 78/200 [02:07<03:19,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.011911183781921863 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|███████████████████████████████▉                                                 | 79/200 [02:09<03:17,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.011682056589052081 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▍                                                | 80/200 [02:10<03:13,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.01140719335526228 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                | 81/200 [02:12<03:14,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.011196706863120198 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|█████████████████████████████████▏                                               | 82/200 [02:14<03:12,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.011059866147115826 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|█████████████████████████████████▌                                               | 83/200 [02:15<03:10,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.010563906119205057 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████                                               | 84/200 [02:17<03:07,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.010493280645459891 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|██████████████████████████████████▍                                              | 85/200 [02:19<03:05,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.010281312349252402 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|██████████████████████████████████▊                                              | 86/200 [02:20<03:04,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.010131343826651573 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▏                                             | 87/200 [02:22<03:03,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.009806827385909855 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|███████████████████████████████████▋                                             | 88/200 [02:23<03:02,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.009713978716172278 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████████████████████████████████████                                             | 89/200 [02:25<02:59,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.00947550085838884 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████████████████████████████████████▍                                            | 90/200 [02:27<02:57,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.00934059873688966 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|████████████████████████████████████▊                                            | 91/200 [02:28<02:55,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.009082646202296018 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▎                                           | 92/200 [02:30<02:55,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.008834172552451492 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|█████████████████████████████████████▋                                           | 93/200 [02:31<02:52,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.00880018132738769 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|██████████████████████████████████████                                           | 94/200 [02:33<02:51,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.008573799626901746 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▍                                          | 95/200 [02:35<02:51,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.008342544664628804 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|██████████████████████████████████████▉                                          | 96/200 [02:36<02:49,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.008261022577062248 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|███████████████████████████████████████▎                                         | 97/200 [02:38<02:47,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.008055968536064028 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|███████████████████████████████████████▋                                         | 98/200 [02:40<02:45,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0078962606145069 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████                                         | 99/200 [02:41<02:45,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.007805566675961018 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████                                        | 100/200 [02:43<02:44,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.007683624420315028 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|████████████████████████████████████████▍                                       | 101/200 [02:45<02:40,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.007596867438405752 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|████████████████████████████████████████▊                                       | 102/200 [02:46<02:37,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.007342035928741097 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▏                                      | 103/200 [02:48<02:36,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0072167164646089075 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████████████████████████████████████████▌                                      | 104/200 [02:49<02:35,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.007053476525470614 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|██████████████████████████████████████████                                      | 105/200 [02:51<02:33,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006989359692670405 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|██████████████████████████████████████████▍                                     | 106/200 [02:53<02:31,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006769707193598151 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|██████████████████████████████████████████▊                                     | 107/200 [02:54<02:30,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006682203151285648 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|███████████████████████████████████████████▏                                    | 108/200 [02:56<02:31,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006483500683680176 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|███████████████████████████████████████████▌                                    | 109/200 [02:58<02:28,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006434162543155253 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|████████████████████████████████████████████                                    | 110/200 [02:59<02:25,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0063505849102512 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▍                                   | 111/200 [03:01<02:25,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0062597865704447034 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|████████████████████████████████████████████▊                                   | 112/200 [03:02<02:23,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.006095395819284022 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████████████████████████████████████████████▏                                  | 113/200 [03:04<02:21,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005992914410308003 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|█████████████████████████████████████████████▌                                  | 114/200 [03:06<02:19,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0059085042448714375 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|██████████████████████████████████████████████                                  | 115/200 [03:07<02:18,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005780952260829508 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▍                                 | 116/200 [03:09<02:17,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005706856912001968 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|██████████████████████████████████████████████▊                                 | 117/200 [03:11<02:15,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005617506592534483 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|███████████████████████████████████████████████▏                                | 118/200 [03:12<02:12,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005507972976192832 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|███████████████████████████████████████████████▌                                | 119/200 [03:14<02:13,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0054406144889071585 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████                                | 120/200 [03:15<02:11,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005266939871944487 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|████████████████████████████████████████████████▍                               | 121/200 [03:17<02:09,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005190340848639607 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|████████████████████████████████████████████████▊                               | 122/200 [03:19<02:06,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005115093709900975 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▏                              | 123/200 [03:20<02:06,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.005050493241287768 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|█████████████████████████████████████████████████▌                              | 124/200 [03:22<02:04,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004989259387366473 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████████████████████████████████████████████████                              | 125/200 [03:24<02:02,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004885339050088078 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|██████████████████████████████████████████████████▍                             | 126/200 [03:25<02:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0047780195716768505 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████████████████████████████████████████████████▊                             | 127/200 [03:27<01:59,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004694490798283368 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▏                            | 128/200 [03:29<01:57,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004590831440873444 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|███████████████████████████████████████████████████▌                            | 129/200 [03:30<01:55,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004535062320064754 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|████████████████████████████████████████████████████                            | 130/200 [03:32<01:54,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004465533699840307 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▍                           | 131/200 [03:33<01:51,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004403107892721891 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|████████████████████████████████████████████████████▊                           | 132/200 [03:35<01:49,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004349080217070878 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|█████████████████████████████████████████████████████▏                          | 133/200 [03:37<01:48,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004247028275858611 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|█████████████████████████████████████████████████████▌                          | 134/200 [03:38<01:47,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004215801716782153 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████                          | 135/200 [03:40<01:45,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004089040926191956 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▍                         | 136/200 [03:41<01:42,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.00404594432329759 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|██████████████████████████████████████████████████████▊                         | 137/200 [03:43<01:42,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.004040341905783862 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|███████████████████████████████████████████████████████▏                        | 138/200 [03:45<01:41,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0039295741473324595 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████████████████████████████████████████████████████▌                        | 139/200 [03:46<01:38,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.003882657876238227 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████                        | 140/200 [03:48<01:37,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.003814284526742995 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████▍                       | 141/200 [03:50<01:35,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0037722769309766592 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|████████████████████████████████████████████████████████▊                       | 142/200 [03:51<01:34,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0037058168556541203 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▏                      | 143/200 [03:53<01:32,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.003647598484531045 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|█████████████████████████████████████████████████████████▌                      | 144/200 [03:54<01:30,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.003618771384935826 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|██████████████████████████████████████████████████████████                      | 145/200 [03:56<01:28,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0035232478636316954 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|██████████████████████████████████████████████████████████▍                     | 146/200 [03:58<01:27,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.003478458523750305 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|██████████████████████████████████████████████████████████▊                     | 147/200 [03:59<01:26,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.003430204384494573 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▏                    | 148/200 [04:01<01:24,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0033708825591020285 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|███████████████████████████████████████████████████████████▌                    | 149/200 [04:03<01:23,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0033022007206454872 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|████████████████████████████████████████████████████████████                    | 150/200 [04:04<01:22,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0032953153597190974 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▍                   | 151/200 [04:06<01:20,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0032171197701245545 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|████████████████████████████████████████████████████████████▊                   | 152/200 [04:08<01:18,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.003167624457273632 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|█████████████████████████████████████████████████████████████▏                  | 153/200 [04:09<01:16,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0031394913676194847 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|█████████████████████████████████████████████████████████████▌                  | 154/200 [04:11<01:15,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0031186144915409386 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████                  | 155/200 [04:12<01:13,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.003025676135439426 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▍                 | 156/200 [04:14<01:11,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0029953741352073847 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|██████████████████████████████████████████████████████████████▊                 | 157/200 [04:16<01:09,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.002946059312671423 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|███████████████████████████████████████████████████████████████▏                | 158/200 [04:17<01:08,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.002888344193343073 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████████████████████████████████████████████████████████████▌                | 159/200 [04:19<01:08,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0028550990740768612 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████                | 160/200 [04:21<01:05,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0028289777459576727 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████▍               | 161/200 [04:22<01:03,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.002791696018539369 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████████████████████████████████████████████████████████████▊               | 162/200 [04:24<01:01,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0027570064296014605 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▏              | 163/200 [04:26<01:00,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0026853246614336967 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|█████████████████████████████████████████████████████████████████▌              | 164/200 [04:27<00:58,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0026412405190058053 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|██████████████████████████████████████████████████████████████████              | 165/200 [04:29<00:57,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0026235016586724667 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|██████████████████████████████████████████████████████████████████▍             | 166/200 [04:30<00:55,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0025767937186174095 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|██████████████████████████████████████████████████████████████████▊             | 167/200 [04:32<00:54,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0025307859003078194 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▏            | 168/200 [04:34<00:52,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.002509268547873944 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|███████████████████████████████████████████████████████████████████▌            | 169/200 [04:35<00:50,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0024721248657442628 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|████████████████████████████████████████████████████████████████████            | 170/200 [04:37<00:49,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0024426055490039287 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▍           | 171/200 [04:39<00:47,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.002384290721965954 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████████████████████████████████████████████████████████████████▊           | 172/200 [04:40<00:45,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.002360955683980137 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|█████████████████████████████████████████████████████████████████████▏          | 173/200 [04:42<00:44,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.002331479929853231 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|█████████████████████████████████████████████████████████████████████▌          | 174/200 [04:44<00:42,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.002299957175273448 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████          | 175/200 [04:45<00:41,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0022670738690067083 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▍         | 176/200 [04:47<00:39,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0022520980448462067 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|██████████████████████████████████████████████████████████████████████▊         | 177/200 [04:48<00:37,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0022199783066753297 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|███████████████████████████████████████████████████████████████████████▏        | 178/200 [04:50<00:35,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0021742832264862954 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|███████████████████████████████████████████████████████████████████████▌        | 179/200 [04:52<00:34,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0021303466928657144 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████        | 180/200 [04:53<00:32,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.002117815858218819 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████▍       | 181/200 [04:55<00:30,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0020679208275396375 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|████████████████████████████████████████████████████████████████████████▊       | 182/200 [04:57<00:29,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.002037065365584567 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▏      | 183/200 [04:58<00:27,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.002027338993502781 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████████████████████████████████████████████████████████████████████▌      | 184/200 [05:00<00:26,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0020058744528796526 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|██████████████████████████████████████████████████████████████████████████      | 185/200 [05:02<00:24,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0019547201169189065 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|██████████████████████████████████████████████████████████████████████████▍     | 186/200 [05:03<00:22,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0019500206864904613 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|██████████████████████████████████████████████████████████████████████████▊     | 187/200 [05:05<00:21,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0019336028199177235 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▏    | 188/200 [05:06<00:19,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.001888834300916642 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|███████████████████████████████████████████████████████████████████████████▌    | 189/200 [05:08<00:17,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0018508520442992449 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|████████████████████████████████████████████████████████████████████████████    | 190/200 [05:10<00:16,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0018382455746177584 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▍   | 191/200 [05:11<00:14,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0018079903908073901 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|████████████████████████████████████████████████████████████████████████████▊   | 192/200 [05:13<00:12,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0017857468104921282 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|█████████████████████████████████████████████████████████████████████████████▏  | 193/200 [05:14<00:11,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0017676144314464181 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████████████████████████████████████████████████████████████████████████▌  | 194/200 [05:16<00:09,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0017338411416858435 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████  | 195/200 [05:18<00:08,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0017097139090765268 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▍ | 196/200 [05:19<00:06,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0016972394834738225 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|██████████████████████████████████████████████████████████████████████████████▊ | 197/200 [05:21<00:04,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0016780880687292665 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|███████████████████████████████████████████████████████████████████████████████▏| 198/200 [05:22<00:03,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.001659173733787611 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|███████████████████████████████████████████████████████████████████████████████▌| 199/200 [05:24<00:01,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.001628487603738904 | Train Acc.: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [05:26<00:00,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.0015903397696092724 | Train Acc.: 1.0\n",
      "\n",
      " Training completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import copy\n",
    "clear_memory()\n",
    "\n",
    "only_train = copy.deepcopy(dataset_dict_list)\n",
    "random.shuffle(only_train)\n",
    "train_dataset = dataset_lstm(only_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32)\n",
    "init_model()\n",
    "maximum_epoch = 200\n",
    "for i in tqdm(range(maximum_epoch)):\n",
    "    tloss, tacc = epoch(train_loader, mode = 'train')\n",
    "    print('Train Loss: {} | Train Acc.: {}'.format(tloss, tacc))\n",
    "torch.save(net_lstm.state_dict(), './model_lstm_yolo_cnn_mediapipe_wholetrain.pth')\n",
    "print('\\n Training completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b918af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc02848b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1ef6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313bbf1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c182982d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0c0167",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd57e069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb0111c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mldl",
   "language": "python",
   "name": "mldl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
